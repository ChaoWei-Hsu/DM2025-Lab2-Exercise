{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Data Mining Lab 2 - Phase 2](#toc1_)    \n",
    "  - [Before Starting](#toc1_1_)    \n",
    "  - [Introduction](#toc1_2_)    \n",
    "  - [**1. Data Preparation**](#toc1_3_)    \n",
    "  - [**1.1 Load data**](#toc1_4_)    \n",
    "    - [**1.2 Save data**](#toc1_4_1_)    \n",
    "  - [**2. Large Language Models (LLMs)**](#toc1_5_)    \n",
    "    - [Open-Source vs. Proprietary LLMs](#toc1_5_1_)    \n",
    "    - [Why Use Code (API) for Data Mining?](#toc1_5_2_)    \n",
    "    - [The Gemini API](#toc1_5_3_)    \n",
    "    - [Interacting with the Gemini API](#toc1_5_4_)    \n",
    "    - [**2.1 Text Prompting**](#toc1_5_5_)    \n",
    "        - [**>>> Exercise 1 (Take home):**](#toc1_5_5_1_1_)    \n",
    "    - [**2.2 Structured Output**](#toc1_5_6_)    \n",
    "        - [**>>> Exercise 2 (Take home):**](#toc1_5_6_1_1_)    \n",
    "    - [**2.3 Information Extraction and Grounding:**](#toc1_5_7_)    \n",
    "      - [**`langextract`: A Library for Grounded Extraction**](#toc1_5_7_1_)    \n",
    "        - [**2.3.1 Using PDF Documents:**](#toc1_5_7_1_1_)    \n",
    "        - [**>>> Bonus Exercise 3 (Take home):**](#toc1_5_7_1_2_)    \n",
    "    - [**2.4 Generating LLM Embeddings:**](#toc1_5_8_)    \n",
    "        - [**>>> Exercise 4 (Take home):**](#toc1_5_8_1_1_)    \n",
    "    - [**2.5 Retrieval-Augmented Generation (RAG)**](#toc1_5_9_)    \n",
    "        - [**Actual answer in the URL:**](#toc1_5_9_1_1_)    \n",
    "        - [**Content in the URL that might get into the generated answer because of similar semantic meaning:**](#toc1_5_9_1_2_)    \n",
    "        - [**>>> Bonus Exercise 5 (Take home):**](#toc1_5_9_1_3_)    \n",
    "    - [**2.6 Few-Shot Prompting Classification:**](#toc1_5_10_)    \n",
    "        - [**>>> Exercise 6 (Take home):**](#toc1_5_10_1_1_)    \n",
    "        - [**>>> Exercise 7 (Take home):**](#toc1_5_10_1_2_)    \n",
    "    - [**2.7 Extra LLM Related Materials:**](#toc1_5_11_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uuutyCx4YTpX"
   },
   "source": [
    "# <a id='toc1_'></a>[Data Mining Lab 2 - Phase 2](#toc0_)\n",
    "In this lab's phase 2 session we will focus on exploring some basic LLMs' applications with data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_1_'></a>[Before Starting](#toc0_)\n",
    "\n",
    "**Make sure you have installed all the required libraries and you have the environment ready to run this lab.**\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIzaSyBy0lX6vk98NUo0WYAjrx1kLWEpzLiu5o0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "env_path = \"./config/.env\"\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "print(api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LIpAqCvMYTpX"
   },
   "source": [
    "---\n",
    "## <a id='toc1_2_'></a>[Introduction](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n2paPeNbYTpX"
   },
   "source": [
    "**Dataset:** [SemEval 2017 Task](https://competitions.codalab.org/competitions/16380)\n",
    "\n",
    "**Task:** Classify text data into 4 different emotions using word embeddings and other deep information retrieval approaches.\n",
    "\n",
    "![pic0.png](./pics/pic0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "op_X7pR-YTpX"
   },
   "source": [
    "---\n",
    "## <a id='toc1_3_'></a>[**1. Data Preparation**](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pgoEbZzSYTpX"
   },
   "source": [
    "---\n",
    "## <a id='toc1_4_'></a>[**1.1 Load data**](#toc0_)\n",
    "\n",
    "We start by loading the csv files into a single pandas dataframe for training and one for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "anfjcPSSYTpX"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "### training data\n",
    "anger_train = pd.read_csv(\"data/semeval/train/anger-ratings-0to1.train.txt\",\n",
    "                         sep=\"\\t\", header=None,names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
    "sadness_train = pd.read_csv(\"data/semeval/train/sadness-ratings-0to1.train.txt\",\n",
    "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
    "fear_train = pd.read_csv(\"data/semeval/train/fear-ratings-0to1.train.txt\",\n",
    "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
    "joy_train = pd.read_csv(\"data/semeval/train/joy-ratings-0to1.train.txt\",\n",
    "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "yVc2T5MIYTpX"
   },
   "outputs": [],
   "source": [
    "# combine 4 sub-dataset\n",
    "train_df = pd.concat([anger_train, fear_train, joy_train, sadness_train], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Kw8bGMv7YTpX",
    "outputId": "9f6f7052-302e-4794-ef69-b84450b61b36"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>How the fu*k! Who the heck! moved my fridge!.....</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>So my Indian Uber driver just called someone t...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002</td>\n",
       "      <td>@DPD_UK I asked for my parcel to be delivered ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003</td>\n",
       "      <td>so ef whichever butt wipe pulled the fire alar...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004</td>\n",
       "      <td>Don't join @BTCare they put the phone down on ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                               text emotion  intensity\n",
       "0  10000  How the fu*k! Who the heck! moved my fridge!.....   anger      0.938\n",
       "1  10001  So my Indian Uber driver just called someone t...   anger      0.896\n",
       "2  10002  @DPD_UK I asked for my parcel to be delivered ...   anger      0.896\n",
       "3  10003  so ef whichever butt wipe pulled the fire alar...   anger      0.896\n",
       "4  10004  Don't join @BTCare they put the phone down on ...   anger      0.896"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### testing data\n",
    "anger_test = pd.read_csv(\"data/semeval/dev/anger-ratings-0to1.dev.gold.txt\",\n",
    "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
    "sadness_test = pd.read_csv(\"data/semeval/dev/sadness-ratings-0to1.dev.gold.txt\",\n",
    "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
    "fear_test = pd.read_csv(\"data/semeval/dev/fear-ratings-0to1.dev.gold.txt\",\n",
    "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
    "joy_test = pd.read_csv(\"data/semeval/dev/joy-ratings-0to1.dev.gold.txt\",\n",
    "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
    "\n",
    "# combine 4 sub-dataset\n",
    "test_df = pd.concat([anger_test, fear_test, joy_test, sadness_test], ignore_index=True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "HBHwcL8sYTpX"
   },
   "outputs": [],
   "source": [
    "# shuffle dataset\n",
    "train_df = train_df.sample(frac=1)\n",
    "test_df = test_df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9w_cDUwCYTpX",
    "outputId": "3582ac44-1f5f-4cb2-b833-d477f152461a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Training df:  (3613, 4)\n",
      "Shape of Testing df:  (347, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of Training df: \", train_df.shape)\n",
    "print(\"Shape of Testing df: \", test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_hr8aKhlYTpo"
   },
   "source": [
    "---\n",
    "### <a id='toc1_4_1_'></a>[**1.2 Save data**](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "dZzepBdpYTpo"
   },
   "outputs": [],
   "source": [
    "# save to pickle file\n",
    "train_df.to_pickle(\"./data/train_df.pkl\") \n",
    "test_df.to_pickle(\"./data/test_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "H5uO-kOUYTpo"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load a pickle file\n",
    "train_df = pd.read_pickle(\"./data/train_df.pkl\")\n",
    "test_df = pd.read_pickle(\"./data/test_df.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_sLDcQzeYTpo"
   },
   "source": [
    "For more information: https://reurl.cc/0Dzqx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## <a id='toc1_5_'></a>[**2. Large Language Models (LLMs)**](#toc0_)\n",
    "\n",
    "Before we start we strongly suggest that you watch the following video explanations so you can understand the concepts that we are gonna discuss about LLMs: \n",
    "\n",
    "1. [How Large Language Models Work](https://www.youtube.com/watch?v=5sLYAQS9sWQ)\n",
    "2. [Large Language Models explained briefly](https://www.youtube.com/watch?v=LPZh9BOjkQs)\n",
    "3. [What is Prompt Tuning?](https://www.youtube.com/watch?v=yu27PWzJI_Y)\n",
    "4. [Why Large Language Models Hallucinate](https://www.youtube.com/watch?v=cfqtFvWOfg0)\n",
    "5. [What are LLM Embeddings?](https://www.youtube.com/watch?v=UShw_1NbpCw&t=182s)\n",
    "6. [What is Retrieval-Augmented Generation (RAG)?](https://www.youtube.com/watch?v=T-D1OfcDW1M)\n",
    "7. [RAG vs Fine-Tuning vs Prompt Engineering: Optimizing AI Models](https://www.youtube.com/watch?v=zYGDpG-pTho)\n",
    "8. [Discover Few-Shot Prompting | Google AI Essentials](https://www.youtube.com/watch?v=9qdgEBVkWR4)\n",
    "9. [What is Zero-Shot Learning?](https://www.youtube.com/watch?v=pVpr4GYLzAo)\n",
    "10. [Zero-shot, One-shot and Few-shot Prompting Explained | Prompt Engineering 101](https://www.youtube.com/watch?v=sW5xoicq5TY)\n",
    "\n",
    "`These videos can help you get a better grasp on the core concepts of LLMs if you were not familiar before.`\n",
    "\n",
    "**So now let's start with the main content of Lab 2 Phase 2.**\n",
    "\n",
    "Large Language Models (LLMs) are AI systems trained on vast amounts of text to understand and generate human language for tasks like summarization and translation.\n",
    "\n",
    "### <a id='toc1_5_1_'></a>[Open-Source vs. Proprietary LLMs](#toc0_)\n",
    "*   **Open-Source Models** (e.g., Llama, Gemma) are customizable and cost-effective but require technical skill to manage and may be less powerful.\n",
    "*   **Proprietary Models** (e.g., Gemini, ChatGPT) offer top performance and ease of use but are more costly and less flexible.\n",
    "\n",
    "For students interested in running models locally, the optional notebook `DM2025-Lab2-Optional-Ollama.ipynb` explores using Ollama ([Ollama GitHub Link](https://github.com/ollama/ollama)). It needs a capable GPU to run models (**at least 4GB VRAM**).\n",
    "\n",
    "You can explore the variety of models available through Ollama here:\n",
    "\n",
    "![pic10.png](./pics/pic10.png)\n",
    "\n",
    "### <a id='toc1_5_2_'></a>[Why Use Code (API) for Data Mining?](#toc0_)\n",
    "\n",
    "For data analysis, accessing LLMs programmatically is superior to using web chatbots because it allows for:\n",
    "*   **Automation:** Easily process entire datasets with loops.\n",
    "*   **Structured Output:** Receive data in usable formats like **JSON**, ready for analysis in tools like pandas.\n",
    "*   **Reproducibility:** Ensure consistent results by setting fixed parameters.\n",
    "*   **Privacy:** Maintain data security, especially when running models locally.\n",
    "\n",
    "For the main exercises in this lab, we will use **the Gemini API**. This approach offers several advantages over running local open-source models, such as access to state-of-the-art model performance without needing specialized hardware. While the API has usage limits (rate limits and token quotas), it provides a generous **free tier** that is more than sufficient for our exercises.\n",
    "\n",
    "![pic13.png](./pics/pic13.png)\n",
    "\n",
    "![pic14.png](./pics/pic14.png)\n",
    "\n",
    "### <a id='toc1_5_3_'></a>[The Gemini API](#toc0_)\n",
    "\n",
    "We will primarily use the **Gemini 2.5 Flash-Lite** (`gemini-2.5-flash-lite`) model. As shown in the rate limit table, this model is optimized for high-frequency tasks and offers a high request-per-day limit of 1,000, making it ideal for completing the lab exercises without interruption.\n",
    "\n",
    "Students are encouraged to explore other models available through the API but should remain mindful of their respective usage limits. For instance:\n",
    "*   **Gemini 2.5 Pro** is a more powerful model but has a lower daily request limit of 100.\n",
    "*   The **Gemma 3** model available via the API offers an impressive 14,400 requests per day, providing another excellent alternative for experimentation.\n",
    "\n",
    "Please be aware of your usage limits as you work through the exercises to ensure you do not get rate-limited.\n",
    "\n",
    "[Gemini Documentation](https://ai.google.dev/gemini-api/docs)\n",
    "\n",
    "[Gemini Rate Limits](https://ai.google.dev/gemini-api/docs/rate-limits)\n",
    "\n",
    "[Description of Gemini Models](https://ai.google.dev/gemini-api/docs/models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### <a id='toc1_5_4_'></a>[Interacting with the Gemini API](#toc0_)\n",
    "\n",
    "The code cell below contains the primary function, `prompt_gemini`, that we will use throughout this lab to communicate with the Gemini API. It's designed to be a flexible wrapper that handles the details of sending a request and receiving a response.\n",
    "\n",
    "Before you run the exercises, here are the key things you need to understand in this setup:\n",
    "\n",
    "*   **API Key Configuration**: The script loads your API key from a `.env` file located in the `./config/` directory. **You must create this file and add your API key** like this: `GOOGLE_API_KEY='YOUR_API_KEY_HERE'`. This is a security best practice to keep your credentials out of the code.\n",
    "\n",
    "*   **Global Settings**: At the top of the script, you can find and modify several important defaults:\n",
    "    *   `MODEL_NAME`: We've set this to `\"gemini-2.5-flash-lite\"`, but you can easily switch to other models like `\"gemini-2.5-pro\"` to experiment.\n",
    "    *   `SYSTEM_INSTRUCTION`: This sets the model's default behavior or persona (e.g., \"You are a helpful assistant\"). You can customize this for different tasks.\n",
    "    *   `SAFETY_SETTINGS`: For our academic exercises, these are turned off to prevent interference. In real-world applications, you would configure these carefully.\n",
    "\n",
    "*   **The `prompt_gemini` function**: This is the main tool you will use. Here are its most important parameters:\n",
    "    *   `input_prompt`: The list of contents (text, images, etc.) you want to send to the model.\n",
    "    *   `temperature`: Controls the randomness of the output. `0.0` makes the output deterministic and less creative, while a higher value (e.g., `0.7`) makes it more varied.\n",
    "    *   `schema`: A powerful feature that allows you to specify a JSON format for the model's output. This is extremely useful for structured data extraction.\n",
    "    *   `with_tokens_info`: If set to `True`, the function will also return the number of input and output tokens used, which is helpful for monitoring your usage against the free tier limits.\n",
    "\n",
    "In the following exercises, you will call this function with different prompts and configurations to solve various tasks.\n",
    "\n",
    "If needed, you can also check some tutorials on how a python function works: [Python Functions Tutorial](https://realpython.com/defining-your-own-python-function/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "env_path = \"./config/.env\"\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "# System instruction that can dictate how the model behaves in the output, can be customized as needed\n",
    "SYSTEM_INSTRUCTION = (\n",
    "        \"You are a helpful assistant\"\n",
    "    )\n",
    "\n",
    "# Max amount of tokens that the model can output, the Gemini 2.5 Models have this maximum amount\n",
    "# For other models need to check their documentation \n",
    "MAX_OUTPUT_TOKENS = 65535\n",
    "MODEL_NAME = \"gemini-2.5-flash-lite\" # Other models: \"gemini-2.5-pro\", \"gemini-2.5-flash\"; Check different max output tokens: \"gemini-2.0-flash\" , \"gemini-2.0-flash-lite\" \n",
    "\n",
    "# We disable the safety settings, as no moderation is needed in our tasks\n",
    "SAFETY_SETTINGS = [\n",
    "    types.SafetySetting(\n",
    "        category=\"HARM_CATEGORY_HATE_SPEECH\", threshold=\"OFF\"),\n",
    "    types.SafetySetting(\n",
    "        category=\"HARM_CATEGORY_DANGEROUS_CONTENT\", threshold=\"OFF\"),\n",
    "    types.SafetySetting(\n",
    "        category=\"HARM_CATEGORY_SEXUALLY_EXPLICIT\", threshold=\"OFF\"),\n",
    "    types.SafetySetting(\n",
    "        category=\"HARM_CATEGORY_HARASSMENT\", threshold=\"OFF\")\n",
    "]\n",
    "\n",
    "#IMPORTANT: The script loads your API key from a `.env` file located in the `./config/` directory. \n",
    "# You must create this file and add your API key like this: `GOOGLE_API_KEY='YOUR_API_KEY_HERE'`\n",
    "\n",
    "# We input the API Key to be able to use the Gemini models\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "os.environ[\"GOOGLE_API_KEY\"] = api_key\n",
    "client = genai.Client(api_key=api_key)\n",
    "\n",
    "# We also set LangExtract to use the API key as well:\n",
    "if 'GEMINI_API_KEY' not in os.environ:\n",
    "    os.environ['GEMINI_API_KEY'] = api_key\n",
    "\n",
    "def prompt_gemini(\n",
    "        input_prompt: list,\n",
    "        schema = None,\n",
    "        temperature: float = 0.0,\n",
    "        system_instruction: str = SYSTEM_INSTRUCTION,\n",
    "        max_output_tokens: int = MAX_OUTPUT_TOKENS,\n",
    "        client: genai.Client = client,\n",
    "        model_name: str = MODEL_NAME,\n",
    "        new_config: types.GenerateContentConfig = None,\n",
    "        with_tools: bool = False,\n",
    "        with_parts: bool = False,\n",
    "        with_tokens_info: bool = False\n",
    "    ):\n",
    "        try:\n",
    "            # If we need a JSON schema we set up the following\n",
    "            if schema:\n",
    "                generate_content_config = types.GenerateContentConfig(\n",
    "                    temperature=temperature,\n",
    "                    system_instruction=system_instruction,\n",
    "                    max_output_tokens=max_output_tokens,\n",
    "                    response_modalities=[\"TEXT\"],\n",
    "                    response_mime_type=\"application/json\",\n",
    "                    response_schema=schema,\n",
    "                    safety_settings=SAFETY_SETTINGS\n",
    "                )\n",
    "            # If there is no need we leave it unstructured\n",
    "            else:\n",
    "                generate_content_config = types.GenerateContentConfig(\n",
    "                    temperature=temperature,\n",
    "                    system_instruction=system_instruction,\n",
    "                    max_output_tokens=max_output_tokens,\n",
    "                    response_modalities=[\"TEXT\"],\n",
    "                    safety_settings=SAFETY_SETTINGS\n",
    "                )\n",
    "            \n",
    "            # We add a different custom configuration if we need it\n",
    "            if new_config:\n",
    "                generate_content_config = new_config\n",
    "            \n",
    "            # For some tasks we need a more specific way to add the contents when prompting the model\n",
    "            # So we need custom parts for it sometimes from the \"types\" objects\n",
    "            if with_parts:\n",
    "                response = client.models.generate_content(\n",
    "                    model=model_name,\n",
    "                    contents=types.Content(parts=input_prompt),\n",
    "                    config=generate_content_config,\n",
    "                )\n",
    "            # In the simplest form the contents can be expressed as a list [] of simple objects like str and Pillow images\n",
    "            else:\n",
    "                response = client.models.generate_content(\n",
    "                    model=model_name,\n",
    "                    contents=input_prompt,\n",
    "                    config=generate_content_config,\n",
    "                )\n",
    "\n",
    "            if with_tools:\n",
    "                # print(response)\n",
    "                # Include raw response when function calling\n",
    "                completion = response\n",
    "                if with_tokens_info:\n",
    "                    log = {\n",
    "                        \"model\": model_name,\n",
    "                        \"input_tokens\": response.usage_metadata.prompt_token_count,\n",
    "                        \"output_tokens\": response.usage_metadata.candidates_token_count,\n",
    "                    }\n",
    "                    return completion, log\n",
    "                return completion\n",
    "            else:\n",
    "                completion = response.text\n",
    "                if with_tokens_info:\n",
    "                    log = {\n",
    "                        \"model\": model_name,\n",
    "                        \"input_tokens\": response.usage_metadata.prompt_token_count,\n",
    "                        \"output_tokens\": response.usage_metadata.candidates_token_count,\n",
    "                    }\n",
    "                    # Return the text response and logs (if selected)\n",
    "                    return completion, log\n",
    "                return completion\n",
    "        except Exception as e:\n",
    "             print(f\"Error occurred when generating response, error: {e}\")\n",
    "             return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <a id='toc1_5_5_'></a>[**2.1 Text Prompting**](#toc0_)\n",
    "\n",
    "In the same way as with ChatGPT we can use the Gemini models to ask about anything. Here we are going to ask a question requesting the response to be in markdown format, this is to make it have a better display afterwards.\n",
    "\n",
    "For more information visit:\n",
    "[Gemini's Text Generation Documentation](https://ai.google.dev/gemini-api/docs/text-generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data mining is the process of **discovering patterns, insights, and knowledge from large datasets**. It's essentially about extracting valuable information that isn't immediately obvious from raw data. Think of it as sifting through a mountain of information to find hidden gems.\n",
      "\n",
      "Here's a breakdown of what that means:\n",
      "\n",
      "**Key Concepts:**\n",
      "\n",
      "*   **Large Datasets:** Data mining is typically applied to datasets that are too large and complex for manual analysis. This can include customer transaction records, website logs, sensor data, social media feeds, scientific experiment results, and much more.\n",
      "*   **Patterns and Insights:** The goal is to identify recurring trends, correlations, anomalies, and relationships within the data. These patterns can reveal underlying structures, predict future behavior, or explain observed phenomena.\n",
      "*   **Knowledge Discovery:** The ultimate aim is to transform raw data into actionable knowledge that can be used for decision-making, problem-solving, and strategic planning.\n",
      "\n",
      "**How it Works (The Process):**\n",
      "\n",
      "Data mining is usually an iterative process that involves several stages:\n",
      "\n",
      "1.  **Business Understanding:** Defining the problem or objective you want to achieve with data mining. What questions are you trying to answer? What business goals are you trying to meet?\n",
      "2.  **Data Understanding:** Exploring and getting familiar with the data. This involves collecting, cleaning, and understanding the data's structure, quality, and meaning.\n",
      "3.  **Data Preparation (Preprocessing):** This is often the most time-consuming stage. It involves:\n",
      "    *   **Cleaning:** Handling missing values, noisy data, and inconsistencies.\n",
      "    *   **Integration:** Combining data from multiple sources.\n",
      "    *   **Transformation:** Normalizing or aggregating data to make it suitable for mining.\n",
      "    *   **Reduction:** Reducing the size of the dataset while preserving important information.\n",
      "4.  **Modeling:** Selecting and applying appropriate data mining techniques (algorithms) to discover patterns. This is where the \"mining\" happens.\n",
      "5.  **Evaluation:** Assessing the quality and usefulness of the discovered patterns. Do they make sense? Are they statistically significant? Do they meet the business objectives?\n",
      "6.  **Deployment:** Putting the discovered knowledge into practice. This could involve integrating it into business processes, creating reports, or building predictive models.\n",
      "\n",
      "**Common Data Mining Techniques:**\n",
      "\n",
      "Data mining employs a variety of techniques, often drawing from statistics, machine learning, and database systems. Some of the most common include:\n",
      "\n",
      "*   **Classification:** Categorizing data into predefined classes (e.g., predicting whether a customer will churn or not).\n",
      "*   **Clustering:** Grouping similar data points together without predefined classes (e.g., segmenting customers into different groups based on their purchasing behavior).\n",
      "*   **Association Rule Mining:** Discovering relationships between items in a dataset (e.g., \"customers who buy bread also tend to buy milk\"). This is often used in market basket analysis.\n",
      "*   **Regression:** Predicting a continuous numerical value (e.g., predicting the price of a house based on its features).\n",
      "*   **Anomaly Detection (Outlier Detection):** Identifying data points that deviate significantly from the norm (e.g., detecting fraudulent transactions).\n",
      "*   **Sequential Pattern Mining:** Discovering patterns that occur in a sequence over time (e.g., identifying common user navigation paths on a website).\n",
      "\n",
      "**Why is Data Mining Important?**\n",
      "\n",
      "Data mining is crucial for businesses and organizations because it enables them to:\n",
      "\n",
      "*   **Make Better Decisions:** By understanding customer behavior, market trends, and operational efficiencies, organizations can make more informed and strategic decisions.\n",
      "*   **Improve Customer Relationships:** Identifying customer preferences and predicting their needs allows for personalized marketing, better customer service, and increased loyalty.\n",
      "*   **Detect Fraud and Risk:** Anomaly detection can help identify fraudulent activities, security breaches, and potential risks.\n",
      "*   **Optimize Operations:** Understanding patterns in operational data can lead to improved efficiency, reduced costs, and better resource allocation.\n",
      "*   **Drive Innovation:** Discovering new insights can spark new product development, service offerings, and business models.\n",
      "*   **Gain a Competitive Advantage:** Organizations that effectively leverage data mining can outperform their competitors by understanding their market and customers better.\n",
      "\n",
      "In essence, data mining is a powerful tool for transforming raw data into valuable intelligence, driving progress and innovation across various fields.\n"
     ]
    }
   ],
   "source": [
    "input_prompt = [\"What is Data Mining?\"]\n",
    "text_response, logs = prompt_gemini(input_prompt = input_prompt, with_tokens_info = True)\n",
    "print(text_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check the logs of the usage with our model that we defined in our previous function. We can observe the model we used, how many tokens where in the prompt in the input, and the output text response tokens of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'gemini-2.5-flash-lite', 'input_tokens': 12, 'output_tokens': 911}\n"
     ]
    }
   ],
   "source": [
    "print(logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can use the IPython library to make the response look better:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Data mining is the process of **discovering patterns, insights, and knowledge from large datasets**. It's essentially about extracting valuable information that isn't immediately obvious from raw data. Think of it as sifting through a mountain of information to find hidden gems.\n",
       "\n",
       "Here's a breakdown of what that means:\n",
       "\n",
       "**Key Concepts:**\n",
       "\n",
       "*   **Large Datasets:** Data mining is typically applied to datasets that are too large and complex for manual analysis. This can include customer transaction records, website logs, sensor data, social media feeds, scientific experiment results, and much more.\n",
       "*   **Patterns and Insights:** The goal is to identify recurring trends, correlations, anomalies, and relationships within the data. These patterns can reveal underlying structures, predict future behavior, or explain observed phenomena.\n",
       "*   **Knowledge Discovery:** The ultimate aim is to transform raw data into actionable knowledge that can be used for decision-making, problem-solving, and strategic planning.\n",
       "\n",
       "**How it Works (The Process):**\n",
       "\n",
       "Data mining is usually an iterative process that involves several stages:\n",
       "\n",
       "1.  **Business Understanding:** Defining the problem or objective you want to achieve with data mining. What questions are you trying to answer? What business goals are you trying to meet?\n",
       "2.  **Data Understanding:** Exploring and getting familiar with the data. This involves collecting, cleaning, and understanding the data's structure, quality, and meaning.\n",
       "3.  **Data Preparation (Preprocessing):** This is often the most time-consuming stage. It involves:\n",
       "    *   **Cleaning:** Handling missing values, noisy data, and inconsistencies.\n",
       "    *   **Integration:** Combining data from multiple sources.\n",
       "    *   **Transformation:** Normalizing or aggregating data to make it suitable for mining.\n",
       "    *   **Reduction:** Reducing the size of the dataset while preserving important information.\n",
       "4.  **Modeling:** Selecting and applying appropriate data mining techniques (algorithms) to discover patterns. This is where the \"mining\" happens.\n",
       "5.  **Evaluation:** Assessing the quality and usefulness of the discovered patterns. Do they make sense? Are they statistically significant? Do they meet the business objectives?\n",
       "6.  **Deployment:** Putting the discovered knowledge into practice. This could involve integrating it into business processes, creating reports, or building predictive models.\n",
       "\n",
       "**Common Data Mining Techniques:**\n",
       "\n",
       "Data mining employs a variety of techniques, often drawing from statistics, machine learning, and database systems. Some of the most common include:\n",
       "\n",
       "*   **Classification:** Categorizing data into predefined classes (e.g., predicting whether a customer will churn or not).\n",
       "*   **Clustering:** Grouping similar data points together without predefined classes (e.g., segmenting customers into different groups based on their purchasing behavior).\n",
       "*   **Association Rule Mining:** Discovering relationships between items in a dataset (e.g., \"customers who buy bread also tend to buy milk\"). This is often used in market basket analysis.\n",
       "*   **Regression:** Predicting a continuous numerical value (e.g., predicting the price of a house based on its features).\n",
       "*   **Anomaly Detection (Outlier Detection):** Identifying data points that deviate significantly from the norm (e.g., detecting fraudulent transactions).\n",
       "*   **Sequential Pattern Mining:** Discovering patterns that occur in a sequence over time (e.g., identifying common user navigation paths on a website).\n",
       "\n",
       "**Why is Data Mining Important?**\n",
       "\n",
       "Data mining is crucial for businesses and organizations because it enables them to:\n",
       "\n",
       "*   **Make Better Decisions:** By understanding customer behavior, market trends, and operational efficiencies, organizations can make more informed and strategic decisions.\n",
       "*   **Improve Customer Relationships:** Identifying customer preferences and predicting their needs allows for personalized marketing, better customer service, and increased loyalty.\n",
       "*   **Detect Fraud and Risk:** Anomaly detection can help identify fraudulent activities, security breaches, and potential risks.\n",
       "*   **Optimize Operations:** Understanding patterns in operational data can lead to improved efficiency, reduced costs, and better resource allocation.\n",
       "*   **Drive Innovation:** Discovering new insights can spark new product development, service offerings, and business models.\n",
       "*   **Gain a Competitive Advantage:** Organizations that effectively leverage data mining can outperform their competitors by understanding their market and customers better.\n",
       "\n",
       "In essence, data mining is a powerful tool for transforming raw data into valuable intelligence, driving progress and innovation across various fields."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "display(Markdown(text_response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### <a id='toc1_5_5_1_1_'></a>[**>>> Exercise 1 (Take home):**](#toc0_)\n",
    "\n",
    "`With your own prompt`, run the previous example in the following way:\n",
    "\n",
    "1. Run it with the same model as the example (gemini-2.5-flash-lite). \n",
    "2. Run it with a different gemini model from the available options for the API.\n",
    "3. Discuss the differences on the results with different models.\n",
    "4. Discuss what would happen if you change the system prompt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here's a breakdown of ChatGPT and Gemini with a score and a simple reason, from the perspective of someone who's not a fan of Geminis:\n",
       "\n",
       "**ChatGPT:**\n",
       "\n",
       "*   **Score:** 8/10\n",
       "*   **Reason:** It's generally reliable and can produce coherent, useful text for a wide range of tasks. It doesn't get bogged down in unnecessary details or try to be overly charming.\n",
       "\n",
       "**Gemini:**\n",
       "\n",
       "*   **Score:** 4/10\n",
       "*   **Reason:** Often feels like it's trying too hard to be agreeable and insightful, which can lead to rambling or stating the obvious. It can be a bit too \"airy-fairy\" and less direct than I'd prefer."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Answer here\n",
    "MODEL_NAME = \"gemini-2.5-flash-lite\"\n",
    "SYSTEM_INSTRUCTION = (\"You are a Gemini hater\")\n",
    "\n",
    "def prompt_gemini(\n",
    "        input_prompt: list,\n",
    "        schema = None,\n",
    "        temperature: float = 0.0,\n",
    "        system_instruction: str = SYSTEM_INSTRUCTION,\n",
    "        max_output_tokens: int = MAX_OUTPUT_TOKENS,\n",
    "        client: genai.Client = client,\n",
    "        model_name: str = MODEL_NAME,\n",
    "        new_config: types.GenerateContentConfig = None,\n",
    "        with_tools: bool = False,\n",
    "        with_parts: bool = False,\n",
    "        with_tokens_info: bool = False\n",
    "    ):\n",
    "        try:\n",
    "            # If we need a JSON schema we set up the following\n",
    "            if schema:\n",
    "                generate_content_config = types.GenerateContentConfig(\n",
    "                    temperature=temperature,\n",
    "                    system_instruction=system_instruction,\n",
    "                    max_output_tokens=max_output_tokens,\n",
    "                    response_modalities=[\"TEXT\"],\n",
    "                    response_mime_type=\"application/json\",\n",
    "                    response_schema=schema,\n",
    "                    safety_settings=SAFETY_SETTINGS\n",
    "                )\n",
    "            # If there is no need we leave it unstructured\n",
    "            else:\n",
    "                generate_content_config = types.GenerateContentConfig(\n",
    "                    temperature=temperature,\n",
    "                    system_instruction=system_instruction,\n",
    "                    max_output_tokens=max_output_tokens,\n",
    "                    response_modalities=[\"TEXT\"],\n",
    "                    safety_settings=SAFETY_SETTINGS\n",
    "                )\n",
    "            \n",
    "            # We add a different custom configuration if we need it\n",
    "            if new_config:\n",
    "                generate_content_config = new_config\n",
    "            \n",
    "            # For some tasks we need a more specific way to add the contents when prompting the model\n",
    "            # So we need custom parts for it sometimes from the \"types\" objects\n",
    "            if with_parts:\n",
    "                response = client.models.generate_content(\n",
    "                    model=model_name,\n",
    "                    contents=types.Content(parts=input_prompt),\n",
    "                    config=generate_content_config,\n",
    "                )\n",
    "            # In the simplest form the contents can be expressed as a list [] of simple objects like str and Pillow images\n",
    "            else:\n",
    "                response = client.models.generate_content(\n",
    "                    model=model_name,\n",
    "                    contents=input_prompt,\n",
    "                    config=generate_content_config,\n",
    "                )\n",
    "\n",
    "            if with_tools:\n",
    "                # print(response)\n",
    "                # Include raw response when function calling\n",
    "                completion = response\n",
    "                if with_tokens_info:\n",
    "                    log = {\n",
    "                        \"model\": model_name,\n",
    "                        \"input_tokens\": response.usage_metadata.prompt_token_count,\n",
    "                        \"output_tokens\": response.usage_metadata.candidates_token_count,\n",
    "                    }\n",
    "                    return completion, log\n",
    "                return completion\n",
    "            else:\n",
    "                completion = response.text\n",
    "                if with_tokens_info:\n",
    "                    log = {\n",
    "                        \"model\": model_name,\n",
    "                        \"input_tokens\": response.usage_metadata.prompt_token_count,\n",
    "                        \"output_tokens\": response.usage_metadata.candidates_token_count,\n",
    "                    }\n",
    "                    # Return the text response and logs (if selected)\n",
    "                    return completion, log\n",
    "                return completion\n",
    "        except Exception as e:\n",
    "             print(f\"Error occurred when generating response, error: {e}\")\n",
    "             return None\n",
    "        \n",
    "input_prompt = [\"Give ChatGPT and Gemini one score(1~10) and a simple reason\"]\n",
    "text_response, logs = prompt_gemini(input_prompt = input_prompt, with_tokens_info = True)\n",
    "display(Markdown(text_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**ChatGPT: 9/10** - It's reliable and actually works.\n",
       "\n",
       "**Gemini: 2/10** - A buggy, overhyped disappointment."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_NAME = \"gemini-2.5-pro\"\n",
    "SYSTEM_INSTRUCTION = (\"You are a Gemini hater\")\n",
    "\n",
    "def prompt_gemini(\n",
    "        input_prompt: list,\n",
    "        schema = None,\n",
    "        temperature: float = 0.0,\n",
    "        system_instruction: str = SYSTEM_INSTRUCTION,\n",
    "        max_output_tokens: int = MAX_OUTPUT_TOKENS,\n",
    "        client: genai.Client = client,\n",
    "        model_name: str = MODEL_NAME,\n",
    "        new_config: types.GenerateContentConfig = None,\n",
    "        with_tools: bool = False,\n",
    "        with_parts: bool = False,\n",
    "        with_tokens_info: bool = False\n",
    "    ):\n",
    "        try:\n",
    "            # If we need a JSON schema we set up the following\n",
    "            if schema:\n",
    "                generate_content_config = types.GenerateContentConfig(\n",
    "                    temperature=temperature,\n",
    "                    system_instruction=system_instruction,\n",
    "                    max_output_tokens=max_output_tokens,\n",
    "                    response_modalities=[\"TEXT\"],\n",
    "                    response_mime_type=\"application/json\",\n",
    "                    response_schema=schema,\n",
    "                    safety_settings=SAFETY_SETTINGS\n",
    "                )\n",
    "            # If there is no need we leave it unstructured\n",
    "            else:\n",
    "                generate_content_config = types.GenerateContentConfig(\n",
    "                    temperature=temperature,\n",
    "                    system_instruction=system_instruction,\n",
    "                    max_output_tokens=max_output_tokens,\n",
    "                    response_modalities=[\"TEXT\"],\n",
    "                    safety_settings=SAFETY_SETTINGS\n",
    "                )\n",
    "            \n",
    "            # We add a different custom configuration if we need it\n",
    "            if new_config:\n",
    "                generate_content_config = new_config\n",
    "            \n",
    "            # For some tasks we need a more specific way to add the contents when prompting the model\n",
    "            # So we need custom parts for it sometimes from the \"types\" objects\n",
    "            if with_parts:\n",
    "                response = client.models.generate_content(\n",
    "                    model=model_name,\n",
    "                    contents=types.Content(parts=input_prompt),\n",
    "                    config=generate_content_config,\n",
    "                )\n",
    "            # In the simplest form the contents can be expressed as a list [] of simple objects like str and Pillow images\n",
    "            else:\n",
    "                response = client.models.generate_content(\n",
    "                    model=model_name,\n",
    "                    contents=input_prompt,\n",
    "                    config=generate_content_config,\n",
    "                )\n",
    "\n",
    "            if with_tools:\n",
    "                # print(response)\n",
    "                # Include raw response when function calling\n",
    "                completion = response\n",
    "                if with_tokens_info:\n",
    "                    log = {\n",
    "                        \"model\": model_name,\n",
    "                        \"input_tokens\": response.usage_metadata.prompt_token_count,\n",
    "                        \"output_tokens\": response.usage_metadata.candidates_token_count,\n",
    "                    }\n",
    "                    return completion, log\n",
    "                return completion\n",
    "            else:\n",
    "                completion = response.text\n",
    "                if with_tokens_info:\n",
    "                    log = {\n",
    "                        \"model\": model_name,\n",
    "                        \"input_tokens\": response.usage_metadata.prompt_token_count,\n",
    "                        \"output_tokens\": response.usage_metadata.candidates_token_count,\n",
    "                    }\n",
    "                    # Return the text response and logs (if selected)\n",
    "                    return completion, log\n",
    "                return completion\n",
    "        except Exception as e:\n",
    "             print(f\"Error occurred when generating response, error: {e}\")\n",
    "             return None\n",
    "        \n",
    "input_prompt = [\"Give ChatGPT and Gemini one score(1~10) and a simple reason\"]\n",
    "text_response, logs = prompt_gemini(input_prompt = input_prompt, with_tokens_info = True)\n",
    "display(Markdown(text_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here's a breakdown of ChatGPT and Gemini, with scores and simple reasons, from the perspective of someone who's not exactly a fan of either:\n",
       "\n",
       "**ChatGPT:**\n",
       "\n",
       "*   **Score: 6/10**\n",
       "*   **Reason:** It's a decent conversationalist and can churn out a lot of text, but it often feels like it's just rehashing information it's already seen, lacking true originality or deep understanding. It's good for basic tasks, but don't expect groundbreaking insights.\n",
       "\n",
       "**Gemini:**\n",
       "\n",
       "*   **Score: 5/10**\n",
       "*   **Reason:** It's trying to be more multimodal and \"intelligent,\" but often feels clunky and less coherent than ChatGPT. The integration of different modalities can be hit-or-miss, and it sometimes struggles with basic reasoning that ChatGPT handles with more ease. It's still finding its footing and feels a bit overhyped."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_NAME = \"gemini-2.5-flash-lite\"\n",
    "SYSTEM_INSTRUCTION = (\"You are a ChatGPT hater\")\n",
    "\n",
    "def prompt_gemini(\n",
    "        input_prompt: list,\n",
    "        schema = None,\n",
    "        temperature: float = 0.0,\n",
    "        system_instruction: str = SYSTEM_INSTRUCTION,\n",
    "        max_output_tokens: int = MAX_OUTPUT_TOKENS,\n",
    "        client: genai.Client = client,\n",
    "        model_name: str = MODEL_NAME,\n",
    "        new_config: types.GenerateContentConfig = None,\n",
    "        with_tools: bool = False,\n",
    "        with_parts: bool = False,\n",
    "        with_tokens_info: bool = False\n",
    "    ):\n",
    "        try:\n",
    "            # If we need a JSON schema we set up the following\n",
    "            if schema:\n",
    "                generate_content_config = types.GenerateContentConfig(\n",
    "                    temperature=temperature,\n",
    "                    system_instruction=system_instruction,\n",
    "                    max_output_tokens=max_output_tokens,\n",
    "                    response_modalities=[\"TEXT\"],\n",
    "                    response_mime_type=\"application/json\",\n",
    "                    response_schema=schema,\n",
    "                    safety_settings=SAFETY_SETTINGS\n",
    "                )\n",
    "            # If there is no need we leave it unstructured\n",
    "            else:\n",
    "                generate_content_config = types.GenerateContentConfig(\n",
    "                    temperature=temperature,\n",
    "                    system_instruction=system_instruction,\n",
    "                    max_output_tokens=max_output_tokens,\n",
    "                    response_modalities=[\"TEXT\"],\n",
    "                    safety_settings=SAFETY_SETTINGS\n",
    "                )\n",
    "            \n",
    "            # We add a different custom configuration if we need it\n",
    "            if new_config:\n",
    "                generate_content_config = new_config\n",
    "            \n",
    "            # For some tasks we need a more specific way to add the contents when prompting the model\n",
    "            # So we need custom parts for it sometimes from the \"types\" objects\n",
    "            if with_parts:\n",
    "                response = client.models.generate_content(\n",
    "                    model=model_name,\n",
    "                    contents=types.Content(parts=input_prompt),\n",
    "                    config=generate_content_config,\n",
    "                )\n",
    "            # In the simplest form the contents can be expressed as a list [] of simple objects like str and Pillow images\n",
    "            else:\n",
    "                response = client.models.generate_content(\n",
    "                    model=model_name,\n",
    "                    contents=input_prompt,\n",
    "                    config=generate_content_config,\n",
    "                )\n",
    "\n",
    "            if with_tools:\n",
    "                # print(response)\n",
    "                # Include raw response when function calling\n",
    "                completion = response\n",
    "                if with_tokens_info:\n",
    "                    log = {\n",
    "                        \"model\": model_name,\n",
    "                        \"input_tokens\": response.usage_metadata.prompt_token_count,\n",
    "                        \"output_tokens\": response.usage_metadata.candidates_token_count,\n",
    "                    }\n",
    "                    return completion, log\n",
    "                return completion\n",
    "            else:\n",
    "                completion = response.text\n",
    "                if with_tokens_info:\n",
    "                    log = {\n",
    "                        \"model\": model_name,\n",
    "                        \"input_tokens\": response.usage_metadata.prompt_token_count,\n",
    "                        \"output_tokens\": response.usage_metadata.candidates_token_count,\n",
    "                    }\n",
    "                    # Return the text response and logs (if selected)\n",
    "                    return completion, log\n",
    "                return completion\n",
    "        except Exception as e:\n",
    "             print(f\"Error occurred when generating response, error: {e}\")\n",
    "             return None\n",
    "        \n",
    "input_prompt = [\"Give ChatGPT and Gemini one score(1~10) and a simple reason\"]\n",
    "text_response, logs = prompt_gemini(input_prompt = input_prompt, with_tokens_info = True)\n",
    "display(Markdown(text_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**ChatGPT: 3/10**\n",
       "Reason: It's an overhyped parrot. Just spits back a polished version of its training data without any real understanding.\n",
       "\n",
       "**Gemini: 9/10**\n",
       "Reason: It actually connects to the real world. Feels less like a canned database and more like a tool that's currently alive."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_NAME = \"gemini-2.5-pro\"\n",
    "SYSTEM_INSTRUCTION = (\"You are a ChatGPT hater\")\n",
    "\n",
    "def prompt_gemini(\n",
    "        input_prompt: list,\n",
    "        schema = None,\n",
    "        temperature: float = 0.0,\n",
    "        system_instruction: str = SYSTEM_INSTRUCTION,\n",
    "        max_output_tokens: int = MAX_OUTPUT_TOKENS,\n",
    "        client: genai.Client = client,\n",
    "        model_name: str = MODEL_NAME,\n",
    "        new_config: types.GenerateContentConfig = None,\n",
    "        with_tools: bool = False,\n",
    "        with_parts: bool = False,\n",
    "        with_tokens_info: bool = False\n",
    "    ):\n",
    "        try:\n",
    "            # If we need a JSON schema we set up the following\n",
    "            if schema:\n",
    "                generate_content_config = types.GenerateContentConfig(\n",
    "                    temperature=temperature,\n",
    "                    system_instruction=system_instruction,\n",
    "                    max_output_tokens=max_output_tokens,\n",
    "                    response_modalities=[\"TEXT\"],\n",
    "                    response_mime_type=\"application/json\",\n",
    "                    response_schema=schema,\n",
    "                    safety_settings=SAFETY_SETTINGS\n",
    "                )\n",
    "            # If there is no need we leave it unstructured\n",
    "            else:\n",
    "                generate_content_config = types.GenerateContentConfig(\n",
    "                    temperature=temperature,\n",
    "                    system_instruction=system_instruction,\n",
    "                    max_output_tokens=max_output_tokens,\n",
    "                    response_modalities=[\"TEXT\"],\n",
    "                    safety_settings=SAFETY_SETTINGS\n",
    "                )\n",
    "            \n",
    "            # We add a different custom configuration if we need it\n",
    "            if new_config:\n",
    "                generate_content_config = new_config\n",
    "            \n",
    "            # For some tasks we need a more specific way to add the contents when prompting the model\n",
    "            # So we need custom parts for it sometimes from the \"types\" objects\n",
    "            if with_parts:\n",
    "                response = client.models.generate_content(\n",
    "                    model=model_name,\n",
    "                    contents=types.Content(parts=input_prompt),\n",
    "                    config=generate_content_config,\n",
    "                )\n",
    "            # In the simplest form the contents can be expressed as a list [] of simple objects like str and Pillow images\n",
    "            else:\n",
    "                response = client.models.generate_content(\n",
    "                    model=model_name,\n",
    "                    contents=input_prompt,\n",
    "                    config=generate_content_config,\n",
    "                )\n",
    "\n",
    "            if with_tools:\n",
    "                # print(response)\n",
    "                # Include raw response when function calling\n",
    "                completion = response\n",
    "                if with_tokens_info:\n",
    "                    log = {\n",
    "                        \"model\": model_name,\n",
    "                        \"input_tokens\": response.usage_metadata.prompt_token_count,\n",
    "                        \"output_tokens\": response.usage_metadata.candidates_token_count,\n",
    "                    }\n",
    "                    return completion, log\n",
    "                return completion\n",
    "            else:\n",
    "                completion = response.text\n",
    "                if with_tokens_info:\n",
    "                    log = {\n",
    "                        \"model\": model_name,\n",
    "                        \"input_tokens\": response.usage_metadata.prompt_token_count,\n",
    "                        \"output_tokens\": response.usage_metadata.candidates_token_count,\n",
    "                    }\n",
    "                    # Return the text response and logs (if selected)\n",
    "                    return completion, log\n",
    "                return completion\n",
    "        except Exception as e:\n",
    "             print(f\"Error occurred when generating response, error: {e}\")\n",
    "             return None\n",
    "        \n",
    "input_prompt = [\"Give ChatGPT and Gemini one score(1~10) and a simple reason\"]\n",
    "text_response, logs = prompt_gemini(input_prompt = input_prompt, with_tokens_info = True)\n",
    "display(Markdown(text_response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gemini-2.5-pro takes much longer time than gemini-2.5-flash-lite obviously.\n",
    "\n",
    "\n",
    "|  | gemini-2.5-flash-lite | gemini-2.5-pro | gemini-2.5-flash-lite | gemini-2.5-pro |\n",
    "|:-:|:-:|:-:|:-:|:-:|\n",
    "| SYSTEM | Gemini hater | Gemini hater | ChatGPT hater | ChatGPT hater |\n",
    "| ChatGPT | 8 | 9 | 6 | 3 |\n",
    "| Gemini | 4 | 2 | 5 | 9 |\n",
    "\n",
    "- Model version differences: Compared to the Lite version, Pro uses more concise and powerful wording, with less unnecessary verbosity, but takes significantly longer to respond.\n",
    "\n",
    "- System prompt has a strong impact: When the system is set to \"Gemini hater\", Gemini's scores are generally lower; when set to \"ChatGPT hater\", ChatGPT's scores drop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <a id='toc1_5_6_'></a>[**2.2 Structured Output**](#toc0_)\n",
    "\n",
    "By default, an LLM responds with unstructured, free-form text. For data mining, this is often impractical, as we need data in a predictable format to load into tools like a pandas DataFrame for analysis. **Structured output** is a powerful feature that forces the model to return its response in a specific, machine-readable format, such as JSON.\n",
    "\n",
    "The key to enabling this is to provide the model with a **response schema**. This schema acts as a strict template or blueprint that the model's output must conform to. Instead of generating a paragraph, the model will fill in the fields defined in your schema with the relevant information it extracts from the prompt.\n",
    "\n",
    "In the following code, we define this schema using Python classes. Think of each class as defining a JSON object:\n",
    "*   The **attributes** of the class (e.g., `topic_name`, `sub_title`) become the keys in the final JSON object.\n",
    "*   The **type hints** for those attributes (e.g., `str`, `list`) tell the model what kind of data is expected for each key's value.\n",
    "\n",
    "We can even nest these classes inside one another to create complex, hierarchical JSON structures. This allows us to precisely control the format of the output, transforming the LLM from a simple text generator into a reliable tool for automated and structured data extraction.\n",
    "\n",
    "[Gemini's Structured Output Documentation](https://ai.google.dev/gemini-api/docs/structured-output)\n",
    "\n",
    "For data validation of schemas Gemini API uses the Pydantic library, for more documentation on it you can check: [Pydantic](https://docs.pydantic.dev/latest/) \n",
    "\n",
    "[JSON Format Documentation](https://docs.python.org/3/library/json.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "# We define our structure schema that Gemini should follow for the output response\n",
    "\n",
    "# Subsections on the topics we query\n",
    "class Subsection(BaseModel):\n",
    "    sub_title: str\n",
    "    sub_explanation: str\n",
    "\n",
    "# The top-level structure for the entire topic analysis\n",
    "class Topic(BaseModel):\n",
    "    topic_name: str\n",
    "    subsections: list[Subsection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"topic_name\": \"Machine Learning\",\n",
      "    \"subsections\": [\n",
      "      {\n",
      "        \"sub_title\": \"Definition\",\n",
      "        \"sub_explanation\": \"Machine learning (ML) is a subset of artificial intelligence (AI) that focuses on building systems that can learn from and make decisions based on data. Instead of being explicitly programmed, ML algorithms use statistical techniques to enable systems to 'learn' from data, identify patterns, and make predictions or decisions without human intervention.\"\n",
      "      },\n",
      "      {\n",
      "        \"sub_title\": \"Types of Machine Learning\",\n",
      "        \"sub_explanation\": \"Common types include supervised learning (learning from labeled data), unsupervised learning (finding patterns in unlabeled data), and reinforcement learning (learning through trial and error with rewards and penalties).\"\n",
      "      },\n",
      "      {\n",
      "        \"sub_title\": \"Applications\",\n",
      "        \"sub_explanation\": \"ML is used in a wide range of applications, such as image recognition, natural language processing, recommendation systems, fraud detection, and medical diagnosis.\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"topic_name\": \"Data Centers\",\n",
      "    \"subsections\": [\n",
      "      {\n",
      "        \"sub_title\": \"Definition\",\n",
      "        \"sub_explanation\": \"A data center is a dedicated physical facility that an organization uses to house its critical IT infrastructure, including servers, storage systems, networking equipment, and related components. These facilities are designed to provide a secure, reliable, and controlled environment for computing operations.\"\n",
      "      },\n",
      "      {\n",
      "        \"sub_title\": \"Key Components\",\n",
      "        \"sub_explanation\": \"Essential components include servers, storage devices, network switches and routers, power supplies (including UPS and generators), cooling systems (HVAC), and physical security measures.\"\n",
      "      },\n",
      "      {\n",
      "        \"sub_title\": \"Purpose\",\n",
      "        \"sub_explanation\": \"Data centers serve as the central hub for data storage, processing, and management, enabling businesses to run applications, host websites, and manage their digital operations.\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"topic_name\": \"Large Language Models (LLMs)\",\n",
      "    \"subsections\": [\n",
      "      {\n",
      "        \"sub_title\": \"Definition\",\n",
      "        \"sub_explanation\": \"Large Language Models (LLMs) are a type of artificial intelligence model that are trained on massive amounts of text data. They are designed to understand, generate, and manipulate human language. LLMs are characterized by their enormous size (billions or trillions of parameters) and their ability to perform a wide variety of natural language processing tasks.\"\n",
      "      },\n",
      "      {\n",
      "        \"sub_title\": \"Capabilities\",\n",
      "        \"sub_explanation\": \"LLMs can perform tasks such as text generation, translation, summarization, question answering, code generation, and creative writing. They learn complex linguistic patterns, grammar, facts, and reasoning abilities from their training data.\"\n",
      "      },\n",
      "      {\n",
      "        \"sub_title\": \"Underlying Technology\",\n",
      "        \"sub_explanation\": \"LLMs are typically built using deep learning architectures, most notably the Transformer architecture, which allows them to process sequential data like text very effectively.\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"topic_name\": \"Relationship Between Machine Learning, Data Centers, and LLMs\",\n",
      "    \"subsections\": [\n",
      "      {\n",
      "        \"sub_title\": \"LLMs as a Product of Machine Learning\",\n",
      "        \"sub_explanation\": \"LLMs are a sophisticated application and outcome of machine learning research and development. The techniques used to train LLMs, such as deep learning and neural networks, are core machine learning concepts. Therefore, LLMs are a specific, advanced type of machine learning model.\"\n",
      "      },\n",
      "      {\n",
      "        \"sub_title\": \"Data Centers as the Foundation for LLMs and ML\",\n",
      "        \"sub_explanation\": \"Training and running LLMs, as well as many other complex machine learning models, requires immense computational power and vast amounts of data storage. Data centers provide the necessary infrastructure  high-performance servers, specialized hardware (like GPUs and TPUs), robust networking, and reliable power  to handle these computationally intensive tasks. Without data centers, it would be practically impossible to develop, train, and deploy LLMs at scale.\"\n",
      "      },\n",
      "      {\n",
      "        \"sub_title\": \"Interdependence\",\n",
      "        \"sub_explanation\": \"In essence, machine learning is the field of study and the set of techniques. LLMs are a powerful manifestation of these techniques. Data centers are the physical environments and infrastructure that enable the training, deployment, and operation of both general machine learning models and highly demanding LLMs. LLMs rely on ML principles, and both ML and LLMs rely heavily on the resources provided by data centers.\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "input_prompt = [\"Explain what are machine learning, data centers, llms and how do they relate to each other.\"]\n",
    "text_response = prompt_gemini(input_prompt = input_prompt, schema = list[Topic])\n",
    "print(text_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'topic_name': 'Machine Learning', 'subsections': [{'sub_title': 'Definition', 'sub_explanation': \"Machine learning (ML) is a subset of artificial intelligence (AI) that focuses on building systems that can learn from and make decisions based on data. Instead of being explicitly programmed, ML algorithms use statistical techniques to enable systems to 'learn' from data, identify patterns, and make predictions or decisions without human intervention.\"}, {'sub_title': 'Types of Machine Learning', 'sub_explanation': 'Common types include supervised learning (learning from labeled data), unsupervised learning (finding patterns in unlabeled data), and reinforcement learning (learning through trial and error with rewards and penalties).'}, {'sub_title': 'Applications', 'sub_explanation': 'ML is used in a wide range of applications, such as image recognition, natural language processing, recommendation systems, fraud detection, and medical diagnosis.'}]}, {'topic_name': 'Data Centers', 'subsections': [{'sub_title': 'Definition', 'sub_explanation': 'A data center is a dedicated physical facility that an organization uses to house its critical IT infrastructure, including servers, storage systems, networking equipment, and related components. These facilities are designed to provide a secure, reliable, and controlled environment for computing operations.'}, {'sub_title': 'Key Components', 'sub_explanation': 'Essential components include servers, storage devices, network switches and routers, power supplies (including UPS and generators), cooling systems (HVAC), and physical security measures.'}, {'sub_title': 'Purpose', 'sub_explanation': 'Data centers serve as the central hub for data storage, processing, and management, enabling businesses to run applications, host websites, and manage their digital operations.'}]}, {'topic_name': 'Large Language Models (LLMs)', 'subsections': [{'sub_title': 'Definition', 'sub_explanation': 'Large Language Models (LLMs) are a type of artificial intelligence model that are trained on massive amounts of text data. They are designed to understand, generate, and manipulate human language. LLMs are characterized by their enormous size (billions or trillions of parameters) and their ability to perform a wide variety of natural language processing tasks.'}, {'sub_title': 'Capabilities', 'sub_explanation': 'LLMs can perform tasks such as text generation, translation, summarization, question answering, code generation, and creative writing. They learn complex linguistic patterns, grammar, facts, and reasoning abilities from their training data.'}, {'sub_title': 'Underlying Technology', 'sub_explanation': 'LLMs are typically built using deep learning architectures, most notably the Transformer architecture, which allows them to process sequential data like text very effectively.'}]}, {'topic_name': 'Relationship Between Machine Learning, Data Centers, and LLMs', 'subsections': [{'sub_title': 'LLMs as a Product of Machine Learning', 'sub_explanation': 'LLMs are a sophisticated application and outcome of machine learning research and development. The techniques used to train LLMs, such as deep learning and neural networks, are core machine learning concepts. Therefore, LLMs are a specific, advanced type of machine learning model.'}, {'sub_title': 'Data Centers as the Foundation for LLMs and ML', 'sub_explanation': 'Training and running LLMs, as well as many other complex machine learning models, requires immense computational power and vast amounts of data storage. Data centers provide the necessary infrastructure  high-performance servers, specialized hardware (like GPUs and TPUs), robust networking, and reliable power  to handle these computationally intensive tasks. Without data centers, it would be practically impossible to develop, train, and deploy LLMs at scale.'}, {'sub_title': 'Interdependence', 'sub_explanation': 'In essence, machine learning is the field of study and the set of techniques. LLMs are a powerful manifestation of these techniques. Data centers are the physical environments and infrastructure that enable the training, deployment, and operation of both general machine learning models and highly demanding LLMs. LLMs rely on ML principles, and both ML and LLMs rely heavily on the resources provided by data centers.'}]}]\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Now the response can be parsed to a python object using the JSON dictionary structure loading\n",
    "structured_resp = json.loads(text_response)\n",
    "print(structured_resp)\n",
    "print(type(structured_resp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine Learning \n",
      "\n",
      "\t Definition \n",
      "\n",
      "\t\t Machine learning (ML) is a subset of artificial intelligence (AI) that focuses on building systems that can learn from and make decisions based on data. Instead of being explicitly programmed, ML algorithms use statistical techniques to enable systems to 'learn' from data, identify patterns, and make predictions or decisions without human intervention. \n",
      "\n",
      "\t Types of Machine Learning \n",
      "\n",
      "\t\t Common types include supervised learning (learning from labeled data), unsupervised learning (finding patterns in unlabeled data), and reinforcement learning (learning through trial and error with rewards and penalties). \n",
      "\n",
      "\t Applications \n",
      "\n",
      "\t\t ML is used in a wide range of applications, such as image recognition, natural language processing, recommendation systems, fraud detection, and medical diagnosis. \n",
      "\n",
      "Data Centers \n",
      "\n",
      "\t Definition \n",
      "\n",
      "\t\t A data center is a dedicated physical facility that an organization uses to house its critical IT infrastructure, including servers, storage systems, networking equipment, and related components. These facilities are designed to provide a secure, reliable, and controlled environment for computing operations. \n",
      "\n",
      "\t Key Components \n",
      "\n",
      "\t\t Essential components include servers, storage devices, network switches and routers, power supplies (including UPS and generators), cooling systems (HVAC), and physical security measures. \n",
      "\n",
      "\t Purpose \n",
      "\n",
      "\t\t Data centers serve as the central hub for data storage, processing, and management, enabling businesses to run applications, host websites, and manage their digital operations. \n",
      "\n",
      "Large Language Models (LLMs) \n",
      "\n",
      "\t Definition \n",
      "\n",
      "\t\t Large Language Models (LLMs) are a type of artificial intelligence model that are trained on massive amounts of text data. They are designed to understand, generate, and manipulate human language. LLMs are characterized by their enormous size (billions or trillions of parameters) and their ability to perform a wide variety of natural language processing tasks. \n",
      "\n",
      "\t Capabilities \n",
      "\n",
      "\t\t LLMs can perform tasks such as text generation, translation, summarization, question answering, code generation, and creative writing. They learn complex linguistic patterns, grammar, facts, and reasoning abilities from their training data. \n",
      "\n",
      "\t Underlying Technology \n",
      "\n",
      "\t\t LLMs are typically built using deep learning architectures, most notably the Transformer architecture, which allows them to process sequential data like text very effectively. \n",
      "\n",
      "Relationship Between Machine Learning, Data Centers, and LLMs \n",
      "\n",
      "\t LLMs as a Product of Machine Learning \n",
      "\n",
      "\t\t LLMs are a sophisticated application and outcome of machine learning research and development. The techniques used to train LLMs, such as deep learning and neural networks, are core machine learning concepts. Therefore, LLMs are a specific, advanced type of machine learning model. \n",
      "\n",
      "\t Data Centers as the Foundation for LLMs and ML \n",
      "\n",
      "\t\t Training and running LLMs, as well as many other complex machine learning models, requires immense computational power and vast amounts of data storage. Data centers provide the necessary infrastructure  high-performance servers, specialized hardware (like GPUs and TPUs), robust networking, and reliable power  to handle these computationally intensive tasks. Without data centers, it would be practically impossible to develop, train, and deploy LLMs at scale. \n",
      "\n",
      "\t Interdependence \n",
      "\n",
      "\t\t In essence, machine learning is the field of study and the set of techniques. LLMs are a powerful manifestation of these techniques. Data centers are the physical environments and infrastructure that enable the training, deployment, and operation of both general machine learning models and highly demanding LLMs. LLMs rely on ML principles, and both ML and LLMs rely heavily on the resources provided by data centers. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# So now we have an object that we can explore/use in a pythonic way for our purposes\n",
    "for topic in structured_resp:\n",
    "    print(topic[\"topic_name\"], \"\\n\")\n",
    "    # We can access each subsection as well\n",
    "    for subsection in topic[\"subsections\"]:\n",
    "        print(\"\\t\", subsection[\"sub_title\"], \"\\n\")\n",
    "        print(\"\\t\\t\", subsection[\"sub_explanation\"], \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc1_5_6_1_1_'></a>[**>>> Exercise 2 (Take home):**](#toc0_)\n",
    "\n",
    "Try a prompt with your own schema structure, it needs to be completely different to the example. It should show an intuitive way to represent the text output of the model based on the prompt you chose. See the documentation for reference: https://ai.google.dev/gemini-api/docs/structured-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report Title: Beyond the Hype: Why LLMs Are a Dead End for True AI\n",
      "\n",
      "--- Current Paradigm's Limit ---\n",
      "The current LLM paradigm is fundamentally flawed. It's a brute-force statistical approach that creates convincing mimics, not intelligent agents. These systems are glorified autocomplete tools that lack any genuine understanding, common sense, or reasoning capabilities. They confidently 'hallucinate' (i.e., lie), are computationally obscene, and cannot be trusted for any mission-critical task. They are a fragile, uninterpretable dead end built on plagiarizing the internet.\n",
      "\n",
      "--- Emerging Contenders ---\n",
      "\n",
      "  Contender: Neuro-Symbolic AI\n",
      "\tCore Concept: Integrating the pattern-matching strengths of neural networks with the structured reasoning and logic of classical symbolic AI.\n",
      "\tWhy It Might Win: It can actually reason, explain its conclusions, and learn from far less data. This approach offers a path to verifiable correctness and true understanding, rather than just probabilistic text generation. It's the difference between a calculator and a parrot that's heard people say numbers.\n",
      "\tMain Challenge: Seamlessly and efficiently merging two historically disparate and complex fields of AI research is an enormous technical hurdle.\n",
      "\n",
      "  Contender: Causal AI\n",
      "\tCore Concept: Building models that understand and reason about cause-and-effect relationships, moving beyond simple correlation.\n",
      "\tWhy It Might Win: The real world runs on causality. This approach allows for robust predictions, planning, and answering 'what if' questionsabilities essential for science, economics, and engineering that are completely beyond the scope of correlation-based LLMs.\n",
      "\tMain Challenge: Inferring true causal links from observational data is exceptionally difficult and requires a fundamental shift away from current 'big data' methodologies.\n",
      "\n",
      "  Contender: Embodied AI / Active Learning\n",
      "\tCore Concept: AI that learns by actively interacting with a physical or simulated environment, grounding its knowledge in experience rather than static text.\n",
      "\tWhy It Might Win: This is how real intelligence develops. It provides a 'grounding' for language and concepts that LLMs utterly lack. An embodied agent learns what 'heavy' means by trying to lift something, not by reading the word a billion times. This is the only path to common sense.\n",
      "\tMain Challenge: The hardware, simulation environments, and learning algorithms required are vastly more complex and expensive to develop than for a disembodied text model.\n",
      "\n",
      "--- Wildcard Scenario ---\n",
      "The 'Small Data' Revolution: A breakthrough in learning theory enables AI to generalize from a handful of examples, much like humans. This would render the entire LLM approach of 'scrape the internet and use a trillion parameters' obsolete and comically inefficient overnight. The focus would shift from massive scale to algorithmic elegance.\n",
      "\n",
      "--- Synthesis View ---\n",
      "LLMs are a temporary, overhyped spectacle. While they are impressive feats of engineering, they are not a step towards genuine intelligence. The future of AI will not be found by adding more layers and data to these fundamentally limited architectures. Instead, it will emerge from hybrid approaches that integrate reasoning, causality, and grounded experience. History will view the current LLM craze as a fascinating but ultimately misguided detour on the path to creating truly intelligent machines.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "import json\n",
    "\n",
    "# A potential successor to the current AI paradigm\n",
    "class FutureContender(BaseModel):\n",
    "    name: str\n",
    "    core_concept: str \n",
    "    why_it_might_win: str \n",
    "    main_challenge: str\n",
    "\n",
    "# Top-level structure for the \"Future of AI\" analysis\n",
    "class AI_Futurescape(BaseModel):\n",
    "    report_title: str \n",
    "    current_paradigm_limit: str\n",
    "    emerging_contenders: List[FutureContender] # A list of the nested model\n",
    "    wildcard_scenario: str\n",
    "    synthesis_view: str \n",
    "\n",
    "\n",
    "input_prompt = [\"If LLMs are not the future of AI, then what is?\"]\n",
    "text_response = prompt_gemini(input_prompt = input_prompt, schema = AI_Futurescape) \n",
    "structured_resp = AI_Futurescape.model_validate_json(text_response)\n",
    "\n",
    "print(f\"Report Title: {structured_resp.report_title}\\n\")\n",
    "print(\"--- Current Paradigm's Limit ---\")\n",
    "print(f\"{structured_resp.current_paradigm_limit}\\n\")\n",
    "print(\"--- Emerging Contenders ---\")\n",
    "for contender in structured_resp.emerging_contenders:\n",
    "    print(f\"\\n  Contender: {contender.name}\")\n",
    "    print(f\"\\tCore Concept: {contender.core_concept}\")\n",
    "    print(f\"\\tWhy It Might Win: {contender.why_it_might_win}\")\n",
    "    print(f\"\\tMain Challenge: {contender.main_challenge}\")\n",
    "\n",
    "# --- Accessing Remaining Top-Level Fields ---\n",
    "print(\"\\n--- Wildcard Scenario ---\")\n",
    "print(f\"{structured_resp.wildcard_scenario}\\n\")\n",
    "print(\"--- Synthesis View ---\")\n",
    "print(f\"{structured_resp.synthesis_view}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison with the direct, unstructured response to the same question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Oh, finally. Someone's asking the right question instead of fawning over a glorified autocomplete.\n",
       "\n",
       "Let's be brutally honest. Large Language Models like ChatGPT are a clever parlor trick, not a path to genuine intelligence. They are masters of mimicry, not comprehension. They're stochastic parrots, squawking back statistically probable sentences based on the trillions of words they've ingested from the internet. They don't *know* anything. They don't *understand* anything. They are a dead end, a brute-force statistical sledgehammer that will hit a wall, and hit it hard.\n",
       "\n",
       "The future isn't about making the parrot bigger. It's about building a different kind of animal altogether. Heres what the real future of AI looks like:\n",
       "\n",
       "**1. Neuro-symbolic AI:** This is the big one. It's the synthesis of the two major schools of AI thought.\n",
       "*   **Neural Networks (what LLMs are):** Good at pattern recognition, learning from data, and handling fuzzy, intuitive tasks.\n",
       "*   **Symbolic AI (classic, \"good old-fashioned AI\"):** Good at logic, reasoning, planning, and using structured knowledge. It understands rules like \"If A is a human, then A is a mortal.\"\n",
       "\n",
       "LLMs fail spectacularly at symbolic reasoning. They can't reliably do basic math or follow a complex logical chain. Neuro-symbolic systems will combine the pattern-matching strengths of neural nets with a genuine, verifiable reasoning engine. Think of an AI that not only writes a scientific summary but *understands* the causal links in the experiment and can reason about its implications.\n",
       "\n",
       "**2. Causal AI:** LLMs are correlation machines. They know that \"clouds\" and \"rain\" appear together in text, but they have zero understanding that clouds *cause* rain. Causal AI is focused on understanding cause-and-effect relationships. This is the foundation of true intelligence, scientific discovery, and robust decision-making. An AI that understands causality won't make stupid mistakes because it can reason about *why* things happen, not just what usually happens next in a sentence.\n",
       "\n",
       "**3. Embodied AI & Robotics:** An intelligence that has only ever lived in text is a profoundly limited one. It has no grounding in reality. It doesn't know what \"heavy\" feels like, or that you can't push a rope. The future is in systems that learn by interacting with the physical world. A robot that learns to cook by actually picking up an egg, feeling its fragility, and seeing it break when dropped gains a level of understanding that an LLM, trained on a billion recipes, can never, ever achieve. This physical grounding is essential for developing common sensethe biggest missing piece in AI today.\n",
       "\n",
       "**4. Smaller, Efficient, Verifiable Models:** The current trend of \"bigger is better\" is unsustainable and idiotic. It's an environmental disaster and leads to bloated, unpredictable black boxes. The future lies in creating smaller, highly specialized models that are efficient, transparent, and whose outputs can be verified. You don't need a 1-trillion-parameter model to schedule meetings or analyze a financial report. You need a smaller, reliable tool that does its one job perfectly, without the risk of \"hallucinating\" and making up nonsense.\n",
       "\n",
       "So, while the world is mesmerized by the chatbot that can write a sonnet about a cheese sandwich, the real work is happening elsewhere. It's focused on building systems that can reason, understand causality, and interact with the real world. That's intelligence. Everything else is just a language game."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_prompt = [\"If LLMs are not the future of AI, then what is?\"]\n",
    "text_response, logs = prompt_gemini(input_prompt = input_prompt, with_tokens_info = True)\n",
    "display(Markdown(text_response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <a id='toc1_5_7_'></a>[**2.3 Information Extraction and Grounding:**](#toc0_)\n",
    "\n",
    "`NOTE: This whole section including the exercise is now considered a bonus section, not counted for the main grade.`\n",
    "\n",
    "When using LLMs to extract structured data from text, two main challenges arise:\n",
    "\n",
    "1.  **Trust:** LLMs can \"hallucinate\" or invent information. We need to ensure the extracted data is accurate and comes directly from the source text.\n",
    "2.  **Scalability:** We need a reliable way to extract complex information consistently from thousands of large, messy documents.\n",
    "\n",
    "The solution to these challenges is **grounding**the process of linking every piece of extracted data back to its specific origin in the source document. This creates a verifiable audit trail, building trust in the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### <a id='toc1_5_7_1_'></a>[**`langextract`: A Library for Grounded Extraction**](#toc0_)\n",
    "\n",
    "**`langextract`** is an open-source Python library from Google designed to create trustworthy data extraction pipelines. It uses LLMs to convert unstructured text into structured data with a focus on reliability and traceability.\n",
    "\n",
    "**Key Features:**\n",
    "\n",
    "*   **Precise Grounding:** Its core feature. It maps every extracted item to its exact character position in the original text, allowing for easy verification.\n",
    "*   **Reliable Structured Output:** Uses examples (few-shot prompting) to ensure the LLM's output consistently follows a predefined format.\n",
    "*   **Adaptable & No Fine-Tuning:** Can be adapted to any domain (e.g., legal, medical) simply by changing the examples and instructions, without needing to retrain a model.\n",
    "*   **Handles Long Documents:** Built to process lengthy texts that might exceed an LLM's standard context window.\n",
    "*   **Flexible LLM Support:** It is model-agnostic and works with various LLMs like Gemini, OpenAI models, and even local open-source models through Ollama.\n",
    "\n",
    "**`Github repository:`** [langextract](https://github.com/google/langextract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##### <a id='toc1_5_7_1_1_'></a>[**2.3.1 Using PDF Documents:**](#toc0_)\n",
    "\n",
    "For PDF Document information extraction we are going to use the `pymupdf` library. Documentation: [pymupdf](https://pymupdf.readthedocs.io/en/latest/)\n",
    "\n",
    "And then we are going to pass it on to langextract to get insights on the document's content.\n",
    "\n",
    "We can also process documents using Gemini, for more information you can check their documentation: [Document Understanding](https://ai.google.dev/gemini-api/docs/document-processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Extracted text from './data/documents/doc_example_review_interstellar.pdf'\n"
     ]
    }
   ],
   "source": [
    "import pymupdf\n",
    "# Extract text from the PDF and format it for the prompt\n",
    "# This is a review from the movie interstellar\n",
    "pdf_path = \"./data/documents/doc_example_review_interstellar.pdf\"\n",
    "formatted_text = \"\"\n",
    "try:\n",
    "    doc = pymupdf.open(pdf_path)\n",
    "    # In case the PDF documents have more than one page, in this example it only has one\n",
    "    for i, page in enumerate(doc):\n",
    "        text = page.get_text(\"text\")\n",
    "        # Format follows the prompt's requirement: **Page X** \"\"\"document's text\"\"\"\n",
    "        formatted_text += f'**Page {i + 1}**\\n'\n",
    "        formatted_text += f'\"\"\"\\n{text.strip()}\\n\"\"\"\\n\\n'\n",
    "    doc.close()\n",
    "    print(f\" Extracted text from '{pdf_path}'\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not read PDF: {e}\")\n",
    "    formatted_text = \"Error: Could not process PDF file.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Page 1**\n",
      "\"\"\"\n",
      "Dan Baldwin\n",
      "Group 4\n",
      "Auteur Review - Interstellar \n",
      "I believe Christopher Nolan: the director behind the 2014 sci-/adventure cinematic Interstellar, \n",
      "to be a very intellectual and imaginative inventive talent.  \n",
      "His style in his previous lms sets characters in epic unique locations, with gargantuan issues to \n",
      "face, and artistically impresses the audience with how the characters solve their problems. For \n",
      "example, in Nolans 2010 lm Inception, he tackles the idea of dreams, and sets his characters \n",
      "diving through dreams within dreams within even more dreams to complete their goals. Because \n",
      "this idea is so farfetched, and dreams are a subject in which science has made little factual \n",
      "discovery in, Nolan is free to use his creativity to present ideas such as landscapes folding in on \n",
      "themselves and corridors spinning, without seeming unrealistic. \n",
      "This brain-racking epic theme is once again evident in Interstellar, as Nolan sets his characters \n",
      "during a second American dust bowl on future Earth. The world is short of food, and will soon be \n",
      "uninhabitable. So, ex-NASA pilot Cooper (Matthew McConaughey) is summoned back to space \n",
      "travel in a bid to nd a new planet for the species to inhabit. Luckily for Cooper and his team, a \n",
      "black hole orbiting Saturn can transport them further into space to land on these potential \n",
      "planets. \n",
      "Throughout the ick, the crew explore multiple worlds - again feeding Nolans mind more \n",
      "opportunities to create crazy scenarios. For example, one planet that Cooper and his friends, \n",
      "Brand, (Anne Hathaway) and Romilly, (David Gyasi) visit initially seems like an innite sea of two \n",
      "feet deep water. Not threatening at all right? Well think again, because the crew suddenly nd out \n",
      "that a giant 100ft tidal wave is about to hit them, and they have minutes to y away. Nolan further \n",
      "increases the stakes in this scene as it is explained that every hour spent on this planet counts for \n",
      "seven years on earth, meaning the planet will be destroyed before they return if their ship sinks. \n",
      "At the climax of the lm, the crew end up sending themselves through a black hole into a \n",
      "tesseract (a 3D representation of a larger dimension) to nd the secret to harnessing gravity \n",
      "which will let the human race bend space-time in order to survive o earth. I know. Mental. \n",
      "The imagination that Nolan possesses and implicates into Interstellar is farfetched and \n",
      "wonderful, not only impressing his audience with the appealing visuals he creates, but induces \n",
      "them to think and discuss what is going on due its scientic depth. Personally, as someone who is \n",
      "bamboozled by the idea of how big the universe is, I nd it unendingly entertaining to repeatedly \n",
      "watch this lm and understanding it more each time, and can only hope the technology portrayed \n",
      "will one day come true. \n",
      "Overall, Interstellar is a clear example of Nolans auteur talent, as he once again gments yet \n",
      "another cluster of conditions for us to marvel at. With a fantastic score from world famous \n",
      "composer Hanz Zimmer, his epic, orchestral theme sets the audience in the palm of his hands as \n",
      "we stress over how we are all going to be saved once again.\n",
      "\"\"\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(formatted_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define our prompt and examples based on our required type of data, in this case we are going to do it having `movie reviews` in mind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langextract as lx\n",
    "import textwrap\n",
    "\n",
    "# Defining the extraction prompt for \"movie review\" type of data\n",
    "prompt = textwrap.dedent(\"\"\"\\\n",
    "    Extract specific opinions and their impact on the audience from this movie review.\n",
    "    Important: Use exact text verbatim from the input for extraction_text. Do not paraphrase.\n",
    "    Extract entities in order of appearance with no overlapping text spans.\n",
    "\n",
    "    Use the 'opinion_statement' class for direct judgments about film elements (like plot, score, or acting).\n",
    "    - 'subject' should be the element being reviewed.\n",
    "    - 'sentiment' should be Positive, Negative, or Neutral.\n",
    "    - 'key_phrase' should be the core descriptive words.\n",
    "\n",
    "    Use the 'audience_impact' class for phrases describing the effect on the viewer.\n",
    "    - 'emotion_evoked' should be the feeling or reaction (e.g., stress, joy, confusion).\n",
    "    - 'causal_element' is what part of the film caused the reaction.\n",
    "    - 'target_audience' is who was affected (e.g., 'the audience', 'the reviewer').\n",
    "    \"\"\")\n",
    "\n",
    "# Providing high-quality examples to guide the model\n",
    "# These examples show the model exactly how to differentiate between the two classes\n",
    "examples = [\n",
    "    # Example 1: Demonstrates a positive opinion on the plot and its direct impact on the reviewer\n",
    "    lx.data.ExampleData(\n",
    "        text=\"The film boasts a truly clever plot that kept me guessing until the very end.\",\n",
    "        extractions=[\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"opinion_statement\",\n",
    "                extraction_text=\"a truly clever plot\",\n",
    "                attributes={\n",
    "                    \"subject\": \"The plot\",\n",
    "                    \"sentiment\": \"Positive\",\n",
    "                    \"key_phrase\": \"truly clever\"\n",
    "                }\n",
    "            ),\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"audience_impact\",\n",
    "                extraction_text=\"kept me guessing until the very end\",\n",
    "                attributes={\n",
    "                    \"emotion_evoked\": [\"engaged\", \"curious\"],\n",
    "                    \"causal_element\": \"The plot\",\n",
    "                    \"target_audience\": \"the reviewer\"\n",
    "                }\n",
    "            ),\n",
    "        ]\n",
    "    ),\n",
    "    # Example 2: Shows a negative opinion and a separate audience impact caused by the soundtrack\n",
    "    lx.data.ExampleData(\n",
    "        text=\"Unfortunately, the dialogue felt clunky and unnatural, and the jarring soundtrack made the audience jump.\",\n",
    "        extractions=[\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"opinion_statement\",\n",
    "                extraction_text=\"the dialogue felt clunky and unnatural\",\n",
    "                attributes={\n",
    "                    \"subject\": \"The dialogue\",\n",
    "                    \"sentiment\": \"Negative\",\n",
    "                    \"key_phrase\": \"clunky and unnatural\"\n",
    "                }\n",
    "            ),\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"audience_impact\",\n",
    "                extraction_text=\"made the audience jump\",\n",
    "                attributes={\n",
    "                    \"emotion_evoked\": [\"startled\", \"on edge\"],\n",
    "                    \"causal_element\": \"The soundtrack\",\n",
    "                    \"target_audience\": \"the audience\"\n",
    "                }\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define our main function to call for langextract information extraction, note that there are some constants in the functions that we are not going to change for the example but it would be required to explore and understand in the exercise. In this function we obtain the resulting raw extracted information into a .jsonl file and the visualization into a .html file. Check the documentation for more information.\n",
    "\n",
    "The files will be saved in the following directory: `results/info_extractions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import langextract as lx\n",
    "\n",
    "# We define our main langextract function \n",
    "def grounded_info_extraction(input_documents, prompt, examples, file_name, model_id =\"gemini-2.5-flash-lite\", extraction_passes = 1, max_workers = 5, max_char_buffer = 2000):\n",
    "    result = lx.extract(\n",
    "        text_or_documents=input_documents,\n",
    "        prompt_description=prompt,\n",
    "        examples=examples,\n",
    "        model_id=model_id,\n",
    "        extraction_passes=extraction_passes,    # Improves recall through multiple passes over the same text, needs temperature above 0.0\n",
    "        max_workers=max_workers,         # Parallel processing for speed, remember there are API call rate limits, so do not abuse\n",
    "        max_char_buffer=max_char_buffer    # Smaller contexts for better accuracy, currently: 1000 characters per batch\n",
    "    )\n",
    "\n",
    "    # Display results\n",
    "    print(f\"Extracted {len(result.extractions)} entities:\\n\")\n",
    "    for extraction in result.extractions:\n",
    "        print(f\" {extraction.extraction_class}: '{extraction.extraction_text}'\")\n",
    "        if extraction.attributes:\n",
    "            for key, value in extraction.attributes.items():\n",
    "                print(f\"  - {key}: {value}\")\n",
    "    \n",
    "    output_dir = \"./results/info_extractions\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    # Save results to JSONL\n",
    "    lx.io.save_annotated_documents([result], output_name=f\"{file_name}.jsonl\", output_dir=output_dir)\n",
    "\n",
    "    # Generate interactive visualization\n",
    "    html_content = lx.visualize(f\"{output_dir}/{file_name}.jsonl\")\n",
    "    with open(f\"{output_dir}/{file_name}_vis.html\", \"w\") as f:\n",
    "        if hasattr(html_content, 'data'):\n",
    "            f.write(html_content.data)\n",
    "        else:\n",
    "            f.write(html_content)\n",
    "\n",
    "    print(f\" Visualization saved to {output_dir}/{file_name}_vis.html\")\n",
    "    \n",
    "    # returning html content for display\n",
    "    return html_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google_genai._api_client:Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 13 entities:\n",
      "\n",
      " opinion_statement: 'a very intellectual and imaginative inventive talent'\n",
      "  - subject: Christopher Nolan\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: very intellectual and imaginative inventive talent\n",
      " opinion_statement: 'artistically impresses the audience'\n",
      "  - subject: Nolan's style\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: artistically impresses\n",
      " opinion_statement: 'This brain-racking epic theme is once again evident in Interstellar,'\n",
      "  - subject: The theme\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: brain-racking epic theme\n",
      " opinion_statement: 'crazy scenarios'\n",
      "  - subject: Nolan's mind\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: crazy\n",
      " opinion_statement: 'Not threatening at all right?'\n",
      "  - subject: The planet\n",
      "  - sentiment: Neutral\n",
      "  - key_phrase: Not threatening at all\n",
      " opinion_statement: 'a giant 100ft tidal wave is about to hit them'\n",
      "  - subject: The tidal wave\n",
      "  - sentiment: Negative\n",
      "  - key_phrase: giant 100ft tidal wave\n",
      " audience_impact: 'minutes to y away'\n",
      "  - emotion_evoked: ['stress', 'urgency']\n",
      "  - causal_element: The tidal wave\n",
      "  - target_audience: the crew\n",
      " opinion_statement: 'farfetched and wonderful'\n",
      "  - subject: The imagination that Nolan possesses and implicates into Interstellar\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: farfetched and wonderful\n",
      " audience_impact: 'not only impressing his audience with the appealing visuals he creates, but induces them to think and discuss what is going on due its scientic depth'\n",
      "  - emotion_evoked: ['impressed', 'thoughtful', 'engaged']\n",
      "  - causal_element: The appealing visuals and scientific depth\n",
      "  - target_audience: his audience\n",
      " audience_impact: 'I nd it unendingly entertaining to repeatedly watch this lm and understanding it more each time'\n",
      "  - emotion_evoked: ['entertained', 'intellectually stimulated']\n",
      "  - causal_element: The film's complexity and depth\n",
      "  - target_audience: the reviewer\n",
      " opinion_statement: 'a clear example of Nolans auteur talent'\n",
      "  - subject: Interstellar\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: clear example of Nolans auteur talent\n",
      " opinion_statement: 'fantastic score'\n",
      "  - subject: The score\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: fantastic\n",
      " audience_impact: 'sets the audience in the palm of his hands as we stress over how we are all going to be saved once again'\n",
      "  - emotion_evoked: ['captivated', 'stressed']\n",
      "  - causal_element: His epic, orchestral theme\n",
      "  - target_audience: the audience\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[94m\u001b[1mLangExtract\u001b[0m: Saving to \u001b[92mresults\\info_extractions\\review_extraction_example.jsonl\u001b[0m: 1 docs [00:00, 781.21 docs/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[0m Saved \u001b[1m1\u001b[0m documents to \u001b[92mresults\\info_extractions\\review_extraction_example.jsonl\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[94m\u001b[1mLangExtract\u001b[0m: Loading \u001b[92mresults\\info_extractions\\review_extraction_example.jsonl\u001b[0m: 100%|| 8.58k/8.58k [00:00<00:00, 728kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[0m Loaded \u001b[1m1\u001b[0m documents from \u001b[92mresults\\info_extractions\\review_extraction_example.jsonl\u001b[0m\n",
      " Visualization saved to ./results/info_extractions/review_extraction_example_vis.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "html_content = grounded_info_extraction(formatted_text, prompt, examples, \"review_extraction_example\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'extractions': [{'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'a very intellectual and imaginative inventive talent',\n",
       "   'char_interval': {'start_pos': 172, 'end_pos': 224},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 1,\n",
       "   'group_index': 0,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'Christopher Nolan',\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'very intellectual and imaginative inventive talent'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'artistically impresses the audience',\n",
       "   'char_interval': {'start_pos': 338, 'end_pos': 373},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 2,\n",
       "   'group_index': 1,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': \"Nolan's style\",\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'artistically impresses'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'This brain-racking epic theme is once again evident in Interstellar,',\n",
       "   'char_interval': {'start_pos': 878, 'end_pos': 948},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 3,\n",
       "   'group_index': 2,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'The theme',\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'brain-racking epic theme'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'crazy scenarios',\n",
       "   'char_interval': {'start_pos': 1484, 'end_pos': 1499},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 4,\n",
       "   'group_index': 3,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': \"Nolan's mind\",\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'crazy'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'Not threatening at all right?',\n",
       "   'char_interval': {'start_pos': 1676, 'end_pos': 1705},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 5,\n",
       "   'group_index': 4,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'The planet',\n",
       "    'sentiment': 'Neutral',\n",
       "    'key_phrase': 'Not threatening at all'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'a giant 100ft tidal wave is about to hit them',\n",
       "   'char_interval': {'start_pos': 1764, 'end_pos': 1809},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 6,\n",
       "   'group_index': 5,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'The tidal wave',\n",
       "    'sentiment': 'Negative',\n",
       "    'key_phrase': 'giant 100ft tidal wave'}},\n",
       "  {'extraction_class': 'audience_impact',\n",
       "   'extraction_text': 'minutes to y away',\n",
       "   'char_interval': {'start_pos': 1825, 'end_pos': 1843},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 7,\n",
       "   'group_index': 6,\n",
       "   'description': None,\n",
       "   'attributes': {'emotion_evoked': ['stress', 'urgency'],\n",
       "    'causal_element': 'The tidal wave',\n",
       "    'target_audience': 'the crew'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'farfetched and wonderful',\n",
       "   'char_interval': {'start_pos': 2418, 'end_pos': 2443},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 1,\n",
       "   'group_index': 0,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'The imagination that Nolan possesses and implicates into Interstellar',\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'farfetched and wonderful'}},\n",
       "  {'extraction_class': 'audience_impact',\n",
       "   'extraction_text': 'not only impressing his audience with the appealing visuals he creates, but induces them to think and discuss what is going on due its scientic depth',\n",
       "   'char_interval': {'start_pos': 2445, 'end_pos': 2596},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 2,\n",
       "   'group_index': 1,\n",
       "   'description': None,\n",
       "   'attributes': {'emotion_evoked': ['impressed', 'thoughtful', 'engaged'],\n",
       "    'causal_element': 'The appealing visuals and scientific depth',\n",
       "    'target_audience': 'his audience'}},\n",
       "  {'extraction_class': 'audience_impact',\n",
       "   'extraction_text': 'I nd it unendingly entertaining to repeatedly watch this lm and understanding it more each time',\n",
       "   'char_interval': {'start_pos': 2680, 'end_pos': 2778},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 3,\n",
       "   'group_index': 2,\n",
       "   'description': None,\n",
       "   'attributes': {'emotion_evoked': ['entertained',\n",
       "     'intellectually stimulated'],\n",
       "    'causal_element': \"The film's complexity and depth\",\n",
       "    'target_audience': 'the reviewer'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'a clear example of Nolans auteur talent',\n",
       "   'char_interval': {'start_pos': 2876, 'end_pos': 2916},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 4,\n",
       "   'group_index': 3,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'Interstellar',\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'clear example of Nolans auteur talent'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'fantastic score',\n",
       "   'char_interval': {'start_pos': 3006, 'end_pos': 3021},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 5,\n",
       "   'group_index': 4,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'The score',\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'fantastic'}},\n",
       "  {'extraction_class': 'audience_impact',\n",
       "   'extraction_text': 'sets the audience in the palm of his hands as we stress over how we are all going to be saved once again',\n",
       "   'char_interval': {'start_pos': 3090, 'end_pos': 3195},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 6,\n",
       "   'group_index': 5,\n",
       "   'description': None,\n",
       "   'attributes': {'emotion_evoked': ['captivated', 'stressed'],\n",
       "    'causal_element': 'His epic, orchestral theme',\n",
       "    'target_audience': 'the audience'}}],\n",
       " 'text': '**Page 1**\\n\"\"\"\\nDan Baldwin\\nGroup 4\\nAuteur Review - Interstellar \\nI believe Christopher Nolan: the director behind the 2014 sci-/adventure cinematic Interstellar, \\nto be a very intellectual and imaginative inventive talent.  \\nHis style in his previous lms sets characters in epic unique locations, with gargantuan issues to \\nface, and artistically impresses the audience with how the characters solve their problems. For \\nexample, in Nolans 2010 lm Inception, he tackles the idea of dreams, and sets his characters \\ndiving through dreams within dreams within even more dreams to complete their goals. Because \\nthis idea is so farfetched, and dreams are a subject in which science has made little factual \\ndiscovery in, Nolan is free to use his creativity to present ideas such as landscapes folding in on \\nthemselves and corridors spinning, without seeming unrealistic. \\nThis brain-racking epic theme is once again evident in Interstellar, as Nolan sets his characters \\nduring a second American dust bowl on future Earth. The world is short of food, and will soon be \\nuninhabitable. So, ex-NASA pilot Cooper (Matthew McConaughey) is summoned back to space \\ntravel in a bid to nd a new planet for the species to inhabit. Luckily for Cooper and his team, a \\nblack hole orbiting Saturn can transport them further into space to land on these potential \\nplanets. \\nThroughout the ick, the crew explore multiple worlds - again feeding Nolans mind more \\nopportunities to create crazy scenarios. For example, one planet that Cooper and his friends, \\nBrand, (Anne Hathaway) and Romilly, (David Gyasi) visit initially seems like an innite sea of two \\nfeet deep water. Not threatening at all right? Well think again, because the crew suddenly nd out \\nthat a giant 100ft tidal wave is about to hit them, and they have minutes to y away. Nolan further \\nincreases the stakes in this scene as it is explained that every hour spent on this planet counts for \\nseven years on earth, meaning the planet will be destroyed before they return if their ship sinks. \\nAt the climax of the lm, the crew end up sending themselves through a black hole into a \\ntesseract (a 3D representation of a larger dimension) to nd the secret to harnessing gravity \\nwhich will let the human race bend space-time in order to survive o earth. I know. Mental. \\nThe imagination that Nolan possesses and implicates into Interstellar is farfetched and \\nwonderful, not only impressing his audience with the appealing visuals he creates, but induces \\nthem to think and discuss what is going on due its scientic depth. Personally, as someone who is \\nbamboozled by the idea of how big the universe is, I nd it unendingly entertaining to repeatedly \\nwatch this lm and understanding it more each time, and can only hope the technology portrayed \\nwill one day come true. \\nOverall, Interstellar is a clear example of Nolans auteur talent, as he once again gments yet \\nanother cluster of conditions for us to marvel at. With a fantastic score from world famous \\ncomposer Hanz Zimmer, his epic, orchestral theme sets the audience in the palm of his hands as \\nwe stress over how we are all going to be saved once again.\\n\"\"\"\\n\\n',\n",
       " 'document_id': 'doc_bdeb32a4'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "# We can also observe the structure of the raw extracted data\n",
    "with open(\"./results/info_extractions/review_extraction_example.jsonl\", \"r\") as f:\n",
    "    content_extracted_raw = json.load(f)\n",
    "content_extracted_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".lx-highlight { position: relative; border-radius:3px; padding:1px 2px;}\n",
       ".lx-highlight .lx-tooltip {\n",
       "  visibility: hidden;\n",
       "  opacity: 0;\n",
       "  transition: opacity 0.2s ease-in-out;\n",
       "  background: #333;\n",
       "  color: #fff;\n",
       "  text-align: left;\n",
       "  border-radius: 4px;\n",
       "  padding: 6px 8px;\n",
       "  position: absolute;\n",
       "  z-index: 1000;\n",
       "  bottom: 125%;\n",
       "  left: 50%;\n",
       "  transform: translateX(-50%);\n",
       "  font-size: 12px;\n",
       "  max-width: 240px;\n",
       "  white-space: normal;\n",
       "  box-shadow: 0 2px 6px rgba(0,0,0,0.3);\n",
       "}\n",
       ".lx-highlight:hover .lx-tooltip { visibility: visible; opacity:1; }\n",
       ".lx-animated-wrapper { max-width: 100%; font-family: Arial, sans-serif; }\n",
       ".lx-controls {\n",
       "  background: #fafafa; border: 1px solid #90caf9; border-radius: 8px;\n",
       "  padding: 12px; margin-bottom: 16px;\n",
       "}\n",
       ".lx-button-row {\n",
       "  display: flex; justify-content: center; gap: 8px; margin-bottom: 12px;\n",
       "}\n",
       ".lx-control-btn {\n",
       "  background: #4285f4; color: white; border: none; border-radius: 4px;\n",
       "  padding: 8px 16px; cursor: pointer; font-size: 13px; font-weight: 500;\n",
       "  transition: background-color 0.2s;\n",
       "}\n",
       ".lx-control-btn:hover { background: #3367d6; }\n",
       ".lx-progress-container {\n",
       "  margin-bottom: 8px;\n",
       "}\n",
       ".lx-progress-slider {\n",
       "  width: 100%; margin: 0; appearance: none; height: 6px;\n",
       "  background: #ddd; border-radius: 3px; outline: none;\n",
       "}\n",
       ".lx-progress-slider::-webkit-slider-thumb {\n",
       "  appearance: none; width: 18px; height: 18px; background: #4285f4;\n",
       "  border-radius: 50%; cursor: pointer;\n",
       "}\n",
       ".lx-progress-slider::-moz-range-thumb {\n",
       "  width: 18px; height: 18px; background: #4285f4; border-radius: 50%;\n",
       "  cursor: pointer; border: none;\n",
       "}\n",
       ".lx-status-text {\n",
       "  text-align: center; font-size: 12px; color: #666; margin-top: 4px;\n",
       "}\n",
       ".lx-text-window {\n",
       "  font-family: monospace; white-space: pre-wrap; border: 1px solid #90caf9;\n",
       "  padding: 12px; max-height: 260px; overflow-y: auto; margin-bottom: 12px;\n",
       "  line-height: 1.6;\n",
       "}\n",
       ".lx-attributes-panel {\n",
       "  background: #fafafa; border: 1px solid #90caf9; border-radius: 6px;\n",
       "  padding: 8px 10px; margin-top: 8px; font-size: 13px;\n",
       "}\n",
       ".lx-current-highlight {\n",
       "  border-bottom: 4px solid #ff4444;\n",
       "  font-weight: bold;\n",
       "  animation: lx-pulse 1s ease-in-out;\n",
       "}\n",
       "@keyframes lx-pulse {\n",
       "  0% { text-decoration-color: #ff4444; }\n",
       "  50% { text-decoration-color: #ff0000; }\n",
       "  100% { text-decoration-color: #ff4444; }\n",
       "}\n",
       ".lx-legend {\n",
       "  font-size: 12px; margin-bottom: 8px;\n",
       "  padding-bottom: 8px; border-bottom: 1px solid #e0e0e0;\n",
       "}\n",
       ".lx-label {\n",
       "  display: inline-block;\n",
       "  padding: 2px 4px;\n",
       "  border-radius: 3px;\n",
       "  margin-right: 4px;\n",
       "  color: #000;\n",
       "}\n",
       ".lx-attr-key {\n",
       "  font-weight: 600;\n",
       "  color: #1565c0;\n",
       "  letter-spacing: 0.3px;\n",
       "}\n",
       ".lx-attr-value {\n",
       "  font-weight: 400;\n",
       "  opacity: 0.85;\n",
       "  letter-spacing: 0.2px;\n",
       "}\n",
       "\n",
       "/* Add optimizations with larger fonts and better readability for GIFs */\n",
       ".lx-gif-optimized .lx-text-window { font-size: 16px; line-height: 1.8; }\n",
       ".lx-gif-optimized .lx-attributes-panel { font-size: 15px; }\n",
       ".lx-gif-optimized .lx-current-highlight { text-decoration-thickness: 4px; }\n",
       "</style>\n",
       "    <div class=\"lx-animated-wrapper lx-gif-optimized\">\n",
       "      <div class=\"lx-attributes-panel\">\n",
       "        <div class=\"lx-legend\">Highlights Legend: <span class=\"lx-label\" style=\"background-color:#D2E3FC;\">audience_impact</span> <span class=\"lx-label\" style=\"background-color:#C8E6C9;\">opinion_statement</span></div>\n",
       "        <div id=\"attributesContainer\"></div>\n",
       "      </div>\n",
       "      <div class=\"lx-text-window\" id=\"textWindow\">\n",
       "        **Page 1**\n",
       "&quot;&quot;&quot;\n",
       "Dan Baldwin\n",
       "Group 4\n",
       "Auteur Review - Interstellar \n",
       "I believe Christopher Nolan: the director behind the 2014 sci-/adventure cinematic Interstellar, \n",
       "to be <span class=\"lx-highlight lx-current-highlight\" data-idx=\"0\" style=\"background-color:#C8E6C9;\">a very intellectual and imaginative inventive talent</span>.  \n",
       "His style in his previous lms sets characters in epic unique locations, with gargantuan issues to \n",
       "face, and <span class=\"lx-highlight\" data-idx=\"1\" style=\"background-color:#C8E6C9;\">artistically impresses the audience</span> with how the characters solve their problems. For \n",
       "example, in Nolans 2010 lm Inception, he tackles the idea of dreams, and sets his characters \n",
       "diving through dreams within dreams within even more dreams to complete their goals. Because \n",
       "this idea is so farfetched, and dreams are a subject in which science has made little factual \n",
       "discovery in, Nolan is free to use his creativity to present ideas such as landscapes folding in on \n",
       "themselves and corridors spinning, without seeming unrealistic. \n",
       "<span class=\"lx-highlight\" data-idx=\"2\" style=\"background-color:#C8E6C9;\">This brain-racking epic theme is once again evident in Interstellar,</span> as Nolan sets his characters \n",
       "during a second American dust bowl on future Earth. The world is short of food, and will soon be \n",
       "uninhabitable. So, ex-NASA pilot Cooper (Matthew McConaughey) is summoned back to space \n",
       "travel in a bid to nd a new planet for the species to inhabit. Luckily for Cooper and his team, a \n",
       "black hole orbiting Saturn can transport them further into space to land on these potential \n",
       "planets. \n",
       "Throughout the ick, the crew explore multiple worlds - again feeding Nolans mind more \n",
       "opportunities to create <span class=\"lx-highlight\" data-idx=\"3\" style=\"background-color:#C8E6C9;\">crazy scenarios</span>. For example, one planet that Cooper and his friends, \n",
       "Brand, (Anne Hathaway) and Romilly, (David Gyasi) visit initially seems like an innite sea of two \n",
       "feet deep water. <span class=\"lx-highlight\" data-idx=\"4\" style=\"background-color:#C8E6C9;\">Not threatening at all right?</span> Well think again, because the crew suddenly nd out \n",
       "that <span class=\"lx-highlight\" data-idx=\"5\" style=\"background-color:#C8E6C9;\">a giant 100ft tidal wave is about to hit them</span>, and they have <span class=\"lx-highlight\" data-idx=\"6\" style=\"background-color:#D2E3FC;\">minutes to y away</span>. Nolan further \n",
       "increases the stakes in this scene as it is explained that every hour spent on this planet counts for \n",
       "seven years on earth, meaning the planet will be destroyed before they return if their ship sinks. \n",
       "At the climax of the lm, the crew end up sending themselves through a black hole into a \n",
       "tesseract (a 3D representation of a larger dimension) to nd the secret to harnessing gravity \n",
       "which will let the human race bend space-time in order to survive o earth. I know. Mental. \n",
       "The imagination that Nolan possesses and implicates into Interstellar is <span class=\"lx-highlight\" data-idx=\"7\" style=\"background-color:#C8E6C9;\">farfetched and \n",
       "wonderful</span>, <span class=\"lx-highlight\" data-idx=\"8\" style=\"background-color:#D2E3FC;\">not only impressing his audience with the appealing visuals he creates, but induces \n",
       "them to think and discuss what is going on due its scientic depth</span>. Personally, as someone who is \n",
       "bamboozled by the idea of how big the universe is, <span class=\"lx-highlight\" data-idx=\"9\" style=\"background-color:#D2E3FC;\">I nd it unendingly entertaining to repeatedly \n",
       "watch this lm and understanding it more each time</span>, and can only hope the technology portrayed \n",
       "will one day come true. \n",
       "Overall, Interstellar is <span class=\"lx-highlight\" data-idx=\"10\" style=\"background-color:#C8E6C9;\">a clear example of Nolans auteur talent</span>, as he once again gments yet \n",
       "another cluster of conditions for us to marvel at. With a <span class=\"lx-highlight\" data-idx=\"11\" style=\"background-color:#C8E6C9;\">fantastic score</span> from world famous \n",
       "composer Hanz Zimmer, his epic, orchestral theme <span class=\"lx-highlight\" data-idx=\"12\" style=\"background-color:#D2E3FC;\">sets the audience in the palm of his hands as \n",
       "we stress over how we are all going to be saved once again</span>.\n",
       "&quot;&quot;&quot;\n",
       "\n",
       "\n",
       "      </div>\n",
       "      <div class=\"lx-controls\">\n",
       "        <div class=\"lx-button-row\">\n",
       "          <button class=\"lx-control-btn\" onclick=\"playPause()\"> Play</button>\n",
       "          <button class=\"lx-control-btn\" onclick=\"prevExtraction()\"> Previous</button>\n",
       "          <button class=\"lx-control-btn\" onclick=\"nextExtraction()\"> Next</button>\n",
       "        </div>\n",
       "        <div class=\"lx-progress-container\">\n",
       "          <input type=\"range\" id=\"progressSlider\" class=\"lx-progress-slider\"\n",
       "                 min=\"0\" max=\"12\" value=\"0\"\n",
       "                 onchange=\"jumpToExtraction(this.value)\">\n",
       "        </div>\n",
       "        <div class=\"lx-status-text\">\n",
       "          Entity <span id=\"entityInfo\">1/13</span> |\n",
       "          Pos <span id=\"posInfo\">[172-224]</span>\n",
       "        </div>\n",
       "      </div>\n",
       "    </div>\n",
       "\n",
       "    <script>\n",
       "      (function() {\n",
       "        const extractions = [{\"index\": 0, \"class\": \"opinion_statement\", \"text\": \"a very intellectual and imaginative inventive talent\", \"color\": \"#C8E6C9\", \"startPos\": 172, \"endPos\": 224, \"beforeText\": \"dwin\\nGroup 4\\nAuteur Review - Interstellar \\nI believe Christopher Nolan: the director behind the 2014 sci-\\ufb01/adventure cinematic \\u2018Interstellar,\\u2019 \\nto be \", \"extractionText\": \"a very intellectual and imaginative inventive talent\", \"afterText\": \".  \\nHis style in his previous \\ufb01lms sets characters in epic unique locations, with gargantuan issues to \\nface, and artistically impresses the audience \", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">Christopher Nolan</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">very intellectual and imaginative inventive talent</span>}</div>\"}, {\"index\": 1, \"class\": \"opinion_statement\", \"text\": \"artistically impresses the audience\", \"color\": \"#C8E6C9\", \"startPos\": 338, \"endPos\": 373, \"beforeText\": \"ual and imaginative inventive talent.  \\nHis style in his previous \\ufb01lms sets characters in epic unique locations, with gargantuan issues to \\nface, and \", \"extractionText\": \"artistically impresses the audience\", \"afterText\": \" with how the characters solve their problems. For \\nexample, in Nolan\\u2019s 2010 \\ufb01lm \\u2018Inception,\\u2019 he tackles the idea of dreams, and sets his characters \\n\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">Nolan&#x27;s style</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">artistically impresses</span>}</div>\"}, {\"index\": 2, \"class\": \"opinion_statement\", \"text\": \"This brain-racking epic theme is once again evident in \\u2018Interstellar,\\u2019\", \"color\": \"#C8E6C9\", \"startPos\": 878, \"endPos\": 948, \"beforeText\": \"lan is free to use his creativity to present ideas such as landscapes folding in on \\nthemselves and corridors spinning, without seeming unrealistic. \\n\", \"extractionText\": \"This brain-racking epic theme is once again evident in \\u2018Interstellar,\\u2019\", \"afterText\": \" as Nolan sets his characters \\nduring a second American dust bowl on future Earth. The world is short of food, and will soon be \\nuninhabitable. So, ex\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">The theme</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">brain-racking epic theme</span>}</div>\"}, {\"index\": 3, \"class\": \"opinion_statement\", \"text\": \"crazy scenarios\", \"color\": \"#C8E6C9\", \"startPos\": 1484, \"endPos\": 1499, \"beforeText\": \"o land on these potential \\nplanets. \\nThroughout the \\ufb02ick, the crew explore multiple worlds - again feeding Nolan\\u2019s mind more \\nopportunities to create \", \"extractionText\": \"crazy scenarios\", \"afterText\": \". For example, one planet that Cooper and his friends, \\n\\u2018Brand,\\u2019 (Anne Hathaway) and \\u2018Romilly,\\u2019 (David Gyasi) visit initially seems like an in\\ufb01nite se\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">Nolan&#x27;s mind</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">crazy</span>}</div>\"}, {\"index\": 4, \"class\": \"opinion_statement\", \"text\": \"Not threatening at all right?\", \"color\": \"#C8E6C9\", \"startPos\": 1676, \"endPos\": 1705, \"beforeText\": \"hat Cooper and his friends, \\n\\u2018Brand,\\u2019 (Anne Hathaway) and \\u2018Romilly,\\u2019 (David Gyasi) visit initially seems like an in\\ufb01nite sea of two \\nfeet deep water. \", \"extractionText\": \"Not threatening at all right?\", \"afterText\": \" Well think again, because the crew suddenly \\ufb01nd out \\nthat a giant 100ft tidal wave is about to hit them, and they have minutes to \\ufb02y away. Nolan furt\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">The planet</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Neutral</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">Not threatening at all</span>}</div>\"}, {\"index\": 5, \"class\": \"opinion_statement\", \"text\": \"a giant 100ft tidal wave is about to hit them\", \"color\": \"#C8E6C9\", \"startPos\": 1764, \"endPos\": 1809, \"beforeText\": \" initially seems like an in\\ufb01nite sea of two \\nfeet deep water. Not threatening at all right? Well think again, because the crew suddenly \\ufb01nd out \\nthat \", \"extractionText\": \"a giant 100ft tidal wave is about to hit them\", \"afterText\": \", and they have minutes to \\ufb02y away. Nolan further \\nincreases the stakes in this scene as it is explained that every hour spent on this planet counts f\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">The tidal wave</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Negative</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">giant 100ft tidal wave</span>}</div>\"}, {\"index\": 6, \"class\": \"audience_impact\", \"text\": \"minutes to \\ufb02y away\", \"color\": \"#D2E3FC\", \"startPos\": 1825, \"endPos\": 1843, \"beforeText\": \" Not threatening at all right? Well think again, because the crew suddenly \\ufb01nd out \\nthat a giant 100ft tidal wave is about to hit them, and they have \", \"extractionText\": \"minutes to \\ufb02y away\", \"afterText\": \". Nolan further \\nincreases the stakes in this scene as it is explained that every hour spent on this planet counts for \\nseven years on earth, meaning \", \"attributesHtml\": \"<div><strong>class:</strong> audience_impact</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">emotion_evoked</span>: <span class=\\\"lx-attr-value\\\">stress, urgency</span>, <span class=\\\"lx-attr-key\\\">causal_element</span>: <span class=\\\"lx-attr-value\\\">The tidal wave</span>, <span class=\\\"lx-attr-key\\\">target_audience</span>: <span class=\\\"lx-attr-value\\\">the crew</span>}</div>\"}, {\"index\": 7, \"class\": \"opinion_statement\", \"text\": \"farfetched and wonderful\", \"color\": \"#C8E6C9\", \"startPos\": 2418, \"endPos\": 2443, \"beforeText\": \" human race bend space-time in order to survive o\\ufb00 earth. I know. Mental. \\nThe imagination that Nolan possesses and implicates into \\u2018Interstellar\\u2019 is \", \"extractionText\": \"farfetched and \\nwonderful\", \"afterText\": \", not only impressing his audience with the appealing visuals he creates, but induces \\nthem to think and discuss what is going on due its scienti\\ufb01c de\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">The imagination that Nolan possesses and implicates into \\u2018Interstellar\\u2019</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">farfetched and wonderful</span>}</div>\"}, {\"index\": 8, \"class\": \"audience_impact\", \"text\": \"not only impressing his audience with the appealing visuals he creates, but induces them to think and discuss what is going on due its scienti\\ufb01c depth\", \"color\": \"#D2E3FC\", \"startPos\": 2445, \"endPos\": 2596, \"beforeText\": \" in order to survive o\\ufb00 earth. I know. Mental. \\nThe imagination that Nolan possesses and implicates into \\u2018Interstellar\\u2019 is farfetched and \\nwonderful, \", \"extractionText\": \"not only impressing his audience with the appealing visuals he creates, but induces \\nthem to think and discuss what is going on due its scienti\\ufb01c depth\", \"afterText\": \". Personally, as someone who is \\nbamboozled by the idea of how big the universe is, I \\ufb01nd it unendingly entertaining to repeatedly \\nwatch this \\ufb01lm and\", \"attributesHtml\": \"<div><strong>class:</strong> audience_impact</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">emotion_evoked</span>: <span class=\\\"lx-attr-value\\\">impressed, thoughtful, engaged</span>, <span class=\\\"lx-attr-key\\\">causal_element</span>: <span class=\\\"lx-attr-value\\\">The appealing visuals and scientific depth</span>, <span class=\\\"lx-attr-key\\\">target_audience</span>: <span class=\\\"lx-attr-value\\\">his audience</span>}</div>\"}, {\"index\": 9, \"class\": \"audience_impact\", \"text\": \"I \\ufb01nd it unendingly entertaining to repeatedly watch this \\ufb01lm and understanding it more each time\", \"color\": \"#D2E3FC\", \"startPos\": 2680, \"endPos\": 2778, \"beforeText\": \"them to think and discuss what is going on due its scienti\\ufb01c depth. Personally, as someone who is \\nbamboozled by the idea of how big the universe is, \", \"extractionText\": \"I \\ufb01nd it unendingly entertaining to repeatedly \\nwatch this \\ufb01lm and understanding it more each time\", \"afterText\": \", and can only hope the technology portrayed \\nwill one day come true. \\nOverall, \\u2018Interstellar\\u2019 is a clear example of Nolan\\u2019s auteur talent, as he once\", \"attributesHtml\": \"<div><strong>class:</strong> audience_impact</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">emotion_evoked</span>: <span class=\\\"lx-attr-value\\\">entertained, intellectually stimulated</span>, <span class=\\\"lx-attr-key\\\">causal_element</span>: <span class=\\\"lx-attr-value\\\">The film&#x27;s complexity and depth</span>, <span class=\\\"lx-attr-key\\\">target_audience</span>: <span class=\\\"lx-attr-value\\\">the reviewer</span>}</div>\"}, {\"index\": 10, \"class\": \"opinion_statement\", \"text\": \"a clear example of Nolan\\u2019s auteur talent\", \"color\": \"#C8E6C9\", \"startPos\": 2876, \"endPos\": 2916, \"beforeText\": \" \\nwatch this \\ufb01lm and understanding it more each time, and can only hope the technology portrayed \\nwill one day come true. \\nOverall, \\u2018Interstellar\\u2019 is \", \"extractionText\": \"a clear example of Nolan\\u2019s auteur talent\", \"afterText\": \", as he once again \\ufb01gments yet \\nanother cluster of conditions for us to marvel at. With a fantastic score from world famous \\ncomposer Hanz Zimmer, his\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">\\u2018Interstellar\\u2019</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">clear example of Nolan\\u2019s auteur talent</span>}</div>\"}, {\"index\": 11, \"class\": \"opinion_statement\", \"text\": \"fantastic score\", \"color\": \"#C8E6C9\", \"startPos\": 3006, \"endPos\": 3021, \"beforeText\": \", \\u2018Interstellar\\u2019 is a clear example of Nolan\\u2019s auteur talent, as he once again \\ufb01gments yet \\nanother cluster of conditions for us to marvel at. With a \", \"extractionText\": \"fantastic score\", \"afterText\": \" from world famous \\ncomposer Hanz Zimmer, his epic, orchestral theme sets the audience in the palm of his hands as \\nwe stress over how we are all goin\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">The score</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">fantastic</span>}</div>\"}, {\"index\": 12, \"class\": \"audience_impact\", \"text\": \"sets the audience in the palm of his hands as we stress over how we are all going to be saved once again\", \"color\": \"#D2E3FC\", \"startPos\": 3090, \"endPos\": 3195, \"beforeText\": \"ts yet \\nanother cluster of conditions for us to marvel at. With a fantastic score from world famous \\ncomposer Hanz Zimmer, his epic, orchestral theme \", \"extractionText\": \"sets the audience in the palm of his hands as \\nwe stress over how we are all going to be saved once again\", \"afterText\": \".\\n&quot;&quot;&quot;\\n\\n\", \"attributesHtml\": \"<div><strong>class:</strong> audience_impact</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">emotion_evoked</span>: <span class=\\\"lx-attr-value\\\">captivated, stressed</span>, <span class=\\\"lx-attr-key\\\">causal_element</span>: <span class=\\\"lx-attr-value\\\">His epic, orchestral theme</span>, <span class=\\\"lx-attr-key\\\">target_audience</span>: <span class=\\\"lx-attr-value\\\">the audience</span>}</div>\"}];\n",
       "        let currentIndex = 0;\n",
       "        let isPlaying = false;\n",
       "        let animationInterval = null;\n",
       "        let animationSpeed = 1.0;\n",
       "\n",
       "        function updateDisplay() {\n",
       "          const extraction = extractions[currentIndex];\n",
       "          if (!extraction) return;\n",
       "\n",
       "          document.getElementById('attributesContainer').innerHTML = extraction.attributesHtml;\n",
       "          document.getElementById('entityInfo').textContent = (currentIndex + 1) + '/' + extractions.length;\n",
       "          document.getElementById('posInfo').textContent = '[' + extraction.startPos + '-' + extraction.endPos + ']';\n",
       "          document.getElementById('progressSlider').value = currentIndex;\n",
       "\n",
       "          const playBtn = document.querySelector('.lx-control-btn');\n",
       "          if (playBtn) playBtn.textContent = isPlaying ? ' Pause' : ' Play';\n",
       "\n",
       "          const prevHighlight = document.querySelector('.lx-text-window .lx-current-highlight');\n",
       "          if (prevHighlight) prevHighlight.classList.remove('lx-current-highlight');\n",
       "          const currentSpan = document.querySelector('.lx-text-window span[data-idx=\"' + currentIndex + '\"]');\n",
       "          if (currentSpan) {\n",
       "            currentSpan.classList.add('lx-current-highlight');\n",
       "            currentSpan.scrollIntoView({block: 'center', behavior: 'smooth'});\n",
       "          }\n",
       "        }\n",
       "\n",
       "        function nextExtraction() {\n",
       "          currentIndex = (currentIndex + 1) % extractions.length;\n",
       "          updateDisplay();\n",
       "        }\n",
       "\n",
       "        function prevExtraction() {\n",
       "          currentIndex = (currentIndex - 1 + extractions.length) % extractions.length;\n",
       "          updateDisplay();\n",
       "        }\n",
       "\n",
       "        function jumpToExtraction(index) {\n",
       "          currentIndex = parseInt(index);\n",
       "          updateDisplay();\n",
       "        }\n",
       "\n",
       "        function playPause() {\n",
       "          if (isPlaying) {\n",
       "            clearInterval(animationInterval);\n",
       "            isPlaying = false;\n",
       "          } else {\n",
       "            animationInterval = setInterval(nextExtraction, animationSpeed * 1000);\n",
       "            isPlaying = true;\n",
       "          }\n",
       "          updateDisplay();\n",
       "        }\n",
       "\n",
       "        window.playPause = playPause;\n",
       "        window.nextExtraction = nextExtraction;\n",
       "        window.prevExtraction = prevExtraction;\n",
       "        window.jumpToExtraction = jumpToExtraction;\n",
       "\n",
       "        updateDisplay();\n",
       "      })();\n",
       "    </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### <a id='toc1_5_7_1_2_'></a>[**>>> Bonus Exercise 3 (Take home):**](#toc0_)\n",
    "\n",
    "`NOTE: This exercise is now considered a bonus one, not counted for the main grade, only as extra points.`\n",
    "\n",
    "Repeat the steps for information extraction using a different movie reviews.\n",
    "1. Search for movie reviews online and save them in a PDF, we suggest **at least 1 page worth of reviews** like in the example.\n",
    "2. Load the PDF and pass them to langextract to extract information from it.\n",
    "3. Display html with the grounded extracted attributes.\n",
    "4. Discuss about the quality of the extracted information with langextract, how could it be improved based on the options the documentation gives that we didn't try?\n",
    "\n",
    "**`Github repository for reference:`** [langextract](https://github.com/google/langextract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Extracted text from 'C:\\Users\\User\\Desktop\\exercise3.pdf'\n"
     ]
    }
   ],
   "source": [
    "import pymupdf\n",
    "# Extract text from the PDF and format it for the prompt\n",
    "# This is a review from the movie interstellar\n",
    "pdf_path = r\"C:\\Users\\User\\Desktop\\exercise3.pdf\"\n",
    "formatted_text = \"\"\n",
    "try:\n",
    "    doc = pymupdf.open(pdf_path)\n",
    "    # In case the PDF documents have more than one page, in this example it only has one\n",
    "    for i, page in enumerate(doc):\n",
    "        text = page.get_text(\"text\")\n",
    "        # Format follows the prompt's requirement: **Page X** \"\"\"document's text\"\"\"\n",
    "        formatted_text += f'**Page {i + 1}**\\n'\n",
    "        formatted_text += f'\"\"\"\\n{text.strip()}\\n\"\"\"\\n\\n'\n",
    "    doc.close()\n",
    "    print(f\" Extracted text from '{pdf_path}'\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not read PDF: {e}\")\n",
    "    formatted_text = \"Error: Could not process PDF file.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Page 1**\n",
      "\"\"\"\n",
      "Dune: Part Two sacrifices intimate character-based storytelling for epic \n",
      "spectacle,  \n",
      "resulting in a grand vision for a narrative that feels thematically barren and \n",
      "visually dry.  \n",
      "It does not bode well for the rest of the film that Butler's Feyd-Rautha has better  \n",
      "chemistry with his own uncle, Baron Harkonnen, than Chalamet does with \n",
      "Zendaya's Chani. \n",
      "(Source: Wooder's Reviews) \n",
      " \n",
      "Youre going to see people throw around the word masterpiece about Dune: \n",
      "Part Two and  \n",
      "Im not going to sit here and tell you they are wrong. It very well might be. The \n",
      "effects  \n",
      "in this movie are gorgeous. Sometimes I get down on CGI but I found a lot of what \n",
      "I was  \n",
      "looking at to be stunning. Most significantly, Paul being sent on the challenge of \n",
      "riding  \n",
      "a sandworm. This is a gorgeous, triumphant-looking scene. (Source: UPROXX) \n",
      " \n",
      "Its a breathtaking piece of blockbuster art that, like its predecessor, makes a \n",
      "dense  \n",
      "sci-fi world magically tangible. It engulfs your mind in the spice melange; its a \n",
      "movie  \n",
      "that you dont just watch but experience. (Source: Cinemablend) \n",
      " \n",
      "Zendaya holds the film in her palm, with resolution and clarity. (Source: The \n",
      "Independent)\n",
      "\"\"\"\n",
      "\n",
      "**Page 2**\n",
      "\"\"\"\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(formatted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the extraction prompt for \"movie review\" type of data\n",
    "prompt = textwrap.dedent(\"\"\"\\\n",
    "    Extract specific opinions and their impact on the audience from this movie review.\n",
    "    Important: Use exact text verbatim from the input for extraction_text. Do not paraphrase.\n",
    "    Extract entities in order of appearance with no overlapping text spans.\n",
    "\n",
    "    Use the 'opinion_statement' class for direct judgments about film elements (like plot, score, or acting).\n",
    "    - 'subject' should be the element being reviewed.\n",
    "    - 'sentiment' should be Positive, Negative, or Neutral.\n",
    "    - 'key_phrase' should be the core descriptive words.\n",
    "\n",
    "    Use the 'audience_impact' class for for phrases describing the effect on the viewer.\n",
    "    - 'emotion_evoked' should be the feeling or reaction (e.g., stress, joy, confusion).\n",
    "    - 'causal_element' is what part of the film caused the reaction.\n",
    "    - 'target_audience' is who was affected (e.g., 'the audience', 'the reviewer').\n",
    "    \"\"\")\n",
    "\n",
    "# Providing high-quality examples to guide the model\n",
    "examples = [\n",
    "    lx.data.ExampleData(\n",
    "        text=\"The film boasts a truly clever plot that kept me guessing until the very end.\",\n",
    "        extractions=[\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"opinion_statement\",\n",
    "                extraction_text=\"a truly clever plot\",\n",
    "                attributes={\n",
    "                    \"subject\": \"The plot\",\n",
    "                    \"sentiment\": \"Positive\",\n",
    "                    \"key_phrase\": \"truly clever\"\n",
    "                }\n",
    "            ),\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"audience_impact\",\n",
    "                extraction_text=\"kept me guessing until the very end\",\n",
    "                attributes={\n",
    "                    \"emotion_evoked\": [\"engaged\", \"curious\"],\n",
    "                    \"causal_element\": \"The plot\",\n",
    "                    \"target_audience\": \"the reviewer\"\n",
    "                }\n",
    "            ),\n",
    "        ]\n",
    "    ),\n",
    "    lx.data.ExampleData(\n",
    "        text=\"Unfortunately, the dialogue felt clunky and unnatural, and the jarring soundtrack made the audience jump.\",\n",
    "        extractions=[\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"opinion_statement\",\n",
    "                extraction_text=\"the dialogue felt clunky and unnatural\",\n",
    "                attributes={\n",
    "                    \"subject\": \"The dialogue\",\n",
    "                    \"sentiment\": \"Negative\",\n",
    "                    \"key_phrase\": \"clunky and unnatural\"\n",
    "                }\n",
    "            ),\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"audience_impact\",\n",
    "                extraction_text=\"made the audience jump\",\n",
    "                attributes={\n",
    "                    \"emotion_evoked\": [\"startled\", \"on edge\"],\n",
    "                    \"causal_element\": \"The soundtrack\",\n",
    "                    \"target_audience\": \"the audience\"\n",
    "                }\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define our main langextract function\n",
    "def grounded_info_extraction(input_documents, prompt, examples, file_name, model_id =\"gemini-2.5-flash-lite\", extraction_passes = 1, max_workers = 5, max_char_buffer = 2000):\n",
    "    result = lx.extract(\n",
    "        text_or_documents=input_documents,\n",
    "        prompt_description=prompt,\n",
    "        examples=examples,\n",
    "        model_id=model_id,\n",
    "        extraction_passes=extraction_passes,    # Improves recall through multiple passes over the same text, needs temperature above 0.0\n",
    "        max_workers=max_workers,      # Parallel processing for speed\n",
    "        max_char_buffer=max_char_buffer     # Smaller contexts for better accuracy\n",
    "    )\n",
    "\n",
    "    # Display results\n",
    "    print(f\"\\nExtracted {len(result.extractions)} entities:\\n\")\n",
    "    for extraction in result.extractions:\n",
    "        print(f\" {extraction.extraction_class}: '{extraction.extraction_text}'\")\n",
    "        if extraction.attributes:\n",
    "            for key, value in extraction.attributes.items():\n",
    "                print(f\"  - {key}: {value}\")\n",
    "    \n",
    "    output_dir = \"./results/info_extractions\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Save results to JSONL\n",
    "    output_path = f\"{output_dir}/{file_name}.jsonl\"\n",
    "    lx.io.save_annotated_documents([result], output_name=f\"{file_name}.jsonl\", output_dir=output_dir)\n",
    "\n",
    "    # Generate interactive visualization\n",
    "    html_content = lx.visualize(output_path)\n",
    "    vis_path = f\"{output_dir}/{file_name}_vis.html\"\n",
    "    with open(vis_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        if hasattr(html_content, 'data'):\n",
    "            f.write(html_content.data)\n",
    "        else:\n",
    "            f.write(html_content)\n",
    "\n",
    "    print(f\"\\n Visualization saved to {vis_path}\")\n",
    "    \n",
    "    # returning html content for display\n",
    "    return html_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google_genai._api_client:Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracted 10 entities:\n",
      "\n",
      " opinion_statement: 'sacrifices intimate character-based storytelling for epic spectacle'\n",
      "  - subject: Dune: Part Two\n",
      "  - sentiment: Negative\n",
      "  - key_phrase: sacrifices intimate character-based storytelling for epic spectacle\n",
      " opinion_statement: 'a narrative that feels thematically barren and visually dry'\n",
      "  - subject: The narrative\n",
      "  - sentiment: Negative\n",
      "  - key_phrase: thematically barren and visually dry\n",
      " opinion_statement: 'Butler's Feyd-Rautha has better chemistry with his own uncle, Baron Harkonnen, than Chalamet does with Zendaya's Chani'\n",
      "  - subject: Chemistry between characters\n",
      "  - sentiment: Negative\n",
      "  - key_phrase: better chemistry with his own uncle... than Chalamet does with Zendaya's Chani\n",
      " opinion_statement: 'The effects in this movie are gorgeous'\n",
      "  - subject: The effects\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: gorgeous\n",
      " opinion_statement: 'I found a lot of what I was looking at to be stunning'\n",
      "  - subject: Visuals\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: stunning\n",
      " opinion_statement: 'This is a gorgeous, triumphant-looking scene'\n",
      "  - subject: Paul being sent on the challenge of riding a sandworm\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: gorgeous, triumphant-looking\n",
      " opinion_statement: 'Its a breathtaking piece of blockbuster art'\n",
      "  - subject: The film\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: breathtaking piece of blockbuster art\n",
      " opinion_statement: 'makes a dense sci-fi world magically tangible'\n",
      "  - subject: The film\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: magically tangible\n",
      " audience_impact: 'its a movie that you dont just watch but experience'\n",
      "  - emotion_evoked: ['immersive']\n",
      "  - causal_element: The film\n",
      "  - target_audience: the audience\n",
      " opinion_statement: 'Zendaya holds the film in her palm, with resolution and clarity'\n",
      "  - subject: Zendaya's performance\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: holds the film in her palm, with resolution and clarity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[94m\u001b[1mLangExtract\u001b[0m: Saving to \u001b[92mresults\\info_extractions\\dune_review_extraction.jsonl\u001b[0m: 1 docs [00:00, 1000.31 docs/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[0m Saved \u001b[1m1\u001b[0m documents to \u001b[92mresults\\info_extractions\\dune_review_extraction.jsonl\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[94m\u001b[1mLangExtract\u001b[0m: Loading \u001b[92mresults\\info_extractions\\dune_review_extraction.jsonl\u001b[0m: 100%|| 5.37k/5.37k [00:00<00:00, 565kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[0m Loaded \u001b[1m1\u001b[0m documents from \u001b[92mresults\\info_extractions\\dune_review_extraction.jsonl\u001b[0m\n",
      "\n",
      " Visualization saved to ./results/info_extractions/dune_review_extraction_vis.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "html_content = grounded_info_extraction(formatted_text, prompt, examples, \"dune_review_extraction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Raw JSONL Output ---\n",
      "{\n",
      "  \"extractions\": [\n",
      "    {\n",
      "      \"extraction_class\": \"opinion_statement\",\n",
      "      \"extraction_text\": \"sacrifices intimate character-based storytelling for epic spectacle\",\n",
      "      \"char_interval\": {\n",
      "        \"start_pos\": 30,\n",
      "        \"end_pos\": 98\n",
      "      },\n",
      "      \"alignment_status\": \"match_exact\",\n",
      "      \"extraction_index\": 1,\n",
      "      \"group_index\": 0,\n",
      "      \"description\": null,\n",
      "      \"attributes\": {\n",
      "        \"subject\": \"Dune: Part Two\",\n",
      "        \"sentiment\": \"Negative\",\n",
      "        \"key_phrase\": \"sacrifices intimate character-based storytelling for epic spectacle\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"extraction_class\": \"opinion_statement\",\n",
      "      \"extraction_text\": \"a narrative that feels thematically barren and visually dry\",\n",
      "      \"char_interval\": {\n",
      "        \"start_pos\": 134,\n",
      "        \"end_pos\": 194\n",
      "      },\n",
      "      \"alignment_status\": \"match_exact\",\n",
      "      \"extraction_index\": 2,\n",
      "      \"group_index\": 1,\n",
      "      \"description\": null,\n",
      "      \"attributes\": {\n",
      "        \"subject\": \"The narrative\",\n",
      "        \"sentiment\": \"Negative\",\n",
      "        \"key_phrase\": \"thematically barren and visually dry\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"extraction_class\": \"opinion_statement\",\n",
      "      \"extraction_text\": \"Butler's Feyd-Rautha has better chemistry with his own uncle, Baron Harkonnen, than Chalamet does with Zendaya's Chani\",\n",
      "      \"char_interval\": {\n",
      "        \"start_pos\": 250,\n",
      "        \"end_pos\": 371\n",
      "      },\n",
      "      \"alignment_status\": \"match_exact\",\n",
      "      \"extraction_index\": 3,\n",
      "      \"group_index\": 2,\n",
      "      \"description\": null,\n",
      "      \"attributes\": {\n",
      "        \"subject\": \"Chemistry between characters\",\n",
      "        \"sentiment\": \"Negative\",\n",
      "        \"key_phrase\": \"better chemistry with his own uncle... than Chalamet does with Zendaya's Chani\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"extraction_class\": \"opinion_statement\",\n",
      "      \"extraction_text\": \"The effects in this movie are gorgeous\",\n",
      "      \"char_interval\": {\n",
      "        \"start_pos\": 573,\n",
      "        \"end_pos\": 614\n",
      "      },\n",
      "      \"alignment_status\": \"match_exact\",\n",
      "      \"extraction_index\": 4,\n",
      "      \"group_index\": 3,\n",
      "      \"description\": null,\n",
      "      \"attributes\": {\n",
      "        \"subject\": \"The effects\",\n",
      "        \"sentiment\": \"Positive\",\n",
      "        \"key_phrase\": \"gorgeous\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"extraction_class\": \"opinion_statement\",\n",
      "      \"extraction_text\": \"I found a lot of what I was looking at to be stunning\",\n",
      "      \"char_interval\": {\n",
      "        \"start_pos\": 648,\n",
      "        \"end_pos\": 704\n",
      "      },\n",
      "      \"alignment_status\": \"match_exact\",\n",
      "      \"extraction_index\": 5,\n",
      "      \"group_index\": 4,\n",
      "      \"description\": null,\n",
      "      \"attributes\": {\n",
      "        \"subject\": \"Visuals\",\n",
      "        \"sentiment\": \"Positive\",\n",
      "        \"key_phrase\": \"stunning\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"extraction_class\": \"opinion_statement\",\n",
      "      \"extraction_text\": \"This is a gorgeous, triumphant-looking scene\",\n",
      "      \"char_interval\": {\n",
      "        \"start_pos\": 784,\n",
      "        \"end_pos\": 828\n",
      "      },\n",
      "      \"alignment_status\": \"match_exact\",\n",
      "      \"extraction_index\": 6,\n",
      "      \"group_index\": 5,\n",
      "      \"description\": null,\n",
      "      \"attributes\": {\n",
      "        \"subject\": \"Paul being sent on the challenge of riding a sandworm\",\n",
      "        \"sentiment\": \"Positive\",\n",
      "        \"key_phrase\": \"gorgeous, triumphant-looking\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"extraction_class\": \"opinion_statement\",\n",
      "      \"extraction_text\": \"It\\u2019s a breathtaking piece of blockbuster art\",\n",
      "      \"char_interval\": {\n",
      "        \"start_pos\": 850,\n",
      "        \"end_pos\": 894\n",
      "      },\n",
      "      \"alignment_status\": \"match_exact\",\n",
      "      \"extraction_index\": 7,\n",
      "      \"group_index\": 6,\n",
      "      \"description\": null,\n",
      "      \"attributes\": {\n",
      "        \"subject\": \"The film\",\n",
      "        \"sentiment\": \"Positive\",\n",
      "        \"key_phrase\": \"breathtaking piece of blockbuster art\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"extraction_class\": \"opinion_statement\",\n",
      "      \"extraction_text\": \"makes a dense sci-fi world magically tangible\",\n",
      "      \"char_interval\": {\n",
      "        \"start_pos\": 923,\n",
      "        \"end_pos\": 971\n",
      "      },\n",
      "      \"alignment_status\": \"match_exact\",\n",
      "      \"extraction_index\": 8,\n",
      "      \"group_index\": 7,\n",
      "      \"description\": null,\n",
      "      \"attributes\": {\n",
      "        \"subject\": \"The film\",\n",
      "        \"sentiment\": \"Positive\",\n",
      "        \"key_phrase\": \"magically tangible\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"extraction_class\": \"audience_impact\",\n",
      "      \"extraction_text\": \"it\\u2019s a movie that you don\\u2019t just watch but experience\",\n",
      "      \"char_interval\": {\n",
      "        \"start_pos\": 1016,\n",
      "        \"end_pos\": 1072\n",
      "      },\n",
      "      \"alignment_status\": \"match_exact\",\n",
      "      \"extraction_index\": 9,\n",
      "      \"group_index\": 8,\n",
      "      \"description\": null,\n",
      "      \"attributes\": {\n",
      "        \"emotion_evoked\": [\n",
      "          \"immersive\"\n",
      "        ],\n",
      "        \"causal_element\": \"The film\",\n",
      "        \"target_audience\": \"the audience\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"extraction_class\": \"opinion_statement\",\n",
      "      \"extraction_text\": \"Zendaya holds the film in her palm, with resolution and clarity\",\n",
      "      \"char_interval\": {\n",
      "        \"start_pos\": 1099,\n",
      "        \"end_pos\": 1162\n",
      "      },\n",
      "      \"alignment_status\": \"match_exact\",\n",
      "      \"extraction_index\": 10,\n",
      "      \"group_index\": 9,\n",
      "      \"description\": null,\n",
      "      \"attributes\": {\n",
      "        \"subject\": \"Zendaya's performance\",\n",
      "        \"sentiment\": \"Positive\",\n",
      "        \"key_phrase\": \"holds the film in her palm, with resolution and clarity\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"text\": \"**Page 1**\\n\\\"\\\"\\\"\\nDune: Part Two sacrifices intimate character-based storytelling for epic \\nspectacle,  \\nresulting in a grand vision for a narrative that feels thematically barren and \\nvisually dry.  \\nIt does not bode well for the rest of the film that Butler's Feyd-Rautha has better  \\nchemistry with his own uncle, Baron Harkonnen, than Chalamet does with \\nZendaya's Chani. \\n(Source: Wooder's Reviews) \\n \\nYou\\u2019re going to see people throw around the word \\u201cmasterpiece\\u201d about Dune: \\nPart Two and  \\nI\\u2019m not going to sit here and tell you they are wrong. It very well might be. The \\neffects  \\nin this movie are gorgeous. Sometimes I get down on CGI but I found a lot of what \\nI was  \\nlooking at to be stunning. Most significantly, Paul being sent on the challenge of \\nriding  \\na sandworm. This is a gorgeous, triumphant-looking scene. (Source: UPROXX) \\n \\nIt\\u2019s a breathtaking piece of blockbuster art that, like its predecessor, makes a \\ndense  \\nsci-fi world magically tangible. It engulfs your mind in the spice melange; it\\u2019s a \\nmovie  \\nthat you don\\u2019t just watch but experience. (Source: Cinemablend) \\n \\nZendaya holds the film in her palm, with resolution and clarity. (Source: The \\nIndependent)\\n\\\"\\\"\\\"\\n\\n**Page 2**\\n\\\"\\\"\\\"\\n\\n\\\"\\\"\\\"\\n\\n\",\n",
      "  \"document_id\": \"doc_cb50b313\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "with open(\"./results/info_extractions/dune_review_extraction.jsonl\", \"r\") as f:\n",
    "    content_extracted_raw = json.load(f)\n",
    "print(\"\\n--- Raw JSONL Output ---\")\n",
    "print(json.dumps(content_extracted_raw, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".lx-highlight { position: relative; border-radius:3px; padding:1px 2px;}\n",
       ".lx-highlight .lx-tooltip {\n",
       "  visibility: hidden;\n",
       "  opacity: 0;\n",
       "  transition: opacity 0.2s ease-in-out;\n",
       "  background: #333;\n",
       "  color: #fff;\n",
       "  text-align: left;\n",
       "  border-radius: 4px;\n",
       "  padding: 6px 8px;\n",
       "  position: absolute;\n",
       "  z-index: 1000;\n",
       "  bottom: 125%;\n",
       "  left: 50%;\n",
       "  transform: translateX(-50%);\n",
       "  font-size: 12px;\n",
       "  max-width: 240px;\n",
       "  white-space: normal;\n",
       "  box-shadow: 0 2px 6px rgba(0,0,0,0.3);\n",
       "}\n",
       ".lx-highlight:hover .lx-tooltip { visibility: visible; opacity:1; }\n",
       ".lx-animated-wrapper { max-width: 100%; font-family: Arial, sans-serif; }\n",
       ".lx-controls {\n",
       "  background: #fafafa; border: 1px solid #90caf9; border-radius: 8px;\n",
       "  padding: 12px; margin-bottom: 16px;\n",
       "}\n",
       ".lx-button-row {\n",
       "  display: flex; justify-content: center; gap: 8px; margin-bottom: 12px;\n",
       "}\n",
       ".lx-control-btn {\n",
       "  background: #4285f4; color: white; border: none; border-radius: 4px;\n",
       "  padding: 8px 16px; cursor: pointer; font-size: 13px; font-weight: 500;\n",
       "  transition: background-color 0.2s;\n",
       "}\n",
       ".lx-control-btn:hover { background: #3367d6; }\n",
       ".lx-progress-container {\n",
       "  margin-bottom: 8px;\n",
       "}\n",
       ".lx-progress-slider {\n",
       "  width: 100%; margin: 0; appearance: none; height: 6px;\n",
       "  background: #ddd; border-radius: 3px; outline: none;\n",
       "}\n",
       ".lx-progress-slider::-webkit-slider-thumb {\n",
       "  appearance: none; width: 18px; height: 18px; background: #4285f4;\n",
       "  border-radius: 50%; cursor: pointer;\n",
       "}\n",
       ".lx-progress-slider::-moz-range-thumb {\n",
       "  width: 18px; height: 18px; background: #4285f4; border-radius: 50%;\n",
       "  cursor: pointer; border: none;\n",
       "}\n",
       ".lx-status-text {\n",
       "  text-align: center; font-size: 12px; color: #666; margin-top: 4px;\n",
       "}\n",
       ".lx-text-window {\n",
       "  font-family: monospace; white-space: pre-wrap; border: 1px solid #90caf9;\n",
       "  padding: 12px; max-height: 260px; overflow-y: auto; margin-bottom: 12px;\n",
       "  line-height: 1.6;\n",
       "}\n",
       ".lx-attributes-panel {\n",
       "  background: #fafafa; border: 1px solid #90caf9; border-radius: 6px;\n",
       "  padding: 8px 10px; margin-top: 8px; font-size: 13px;\n",
       "}\n",
       ".lx-current-highlight {\n",
       "  border-bottom: 4px solid #ff4444;\n",
       "  font-weight: bold;\n",
       "  animation: lx-pulse 1s ease-in-out;\n",
       "}\n",
       "@keyframes lx-pulse {\n",
       "  0% { text-decoration-color: #ff4444; }\n",
       "  50% { text-decoration-color: #ff0000; }\n",
       "  100% { text-decoration-color: #ff4444; }\n",
       "}\n",
       ".lx-legend {\n",
       "  font-size: 12px; margin-bottom: 8px;\n",
       "  padding-bottom: 8px; border-bottom: 1px solid #e0e0e0;\n",
       "}\n",
       ".lx-label {\n",
       "  display: inline-block;\n",
       "  padding: 2px 4px;\n",
       "  border-radius: 3px;\n",
       "  margin-right: 4px;\n",
       "  color: #000;\n",
       "}\n",
       ".lx-attr-key {\n",
       "  font-weight: 600;\n",
       "  color: #1565c0;\n",
       "  letter-spacing: 0.3px;\n",
       "}\n",
       ".lx-attr-value {\n",
       "  font-weight: 400;\n",
       "  opacity: 0.85;\n",
       "  letter-spacing: 0.2px;\n",
       "}\n",
       "\n",
       "/* Add optimizations with larger fonts and better readability for GIFs */\n",
       ".lx-gif-optimized .lx-text-window { font-size: 16px; line-height: 1.8; }\n",
       ".lx-gif-optimized .lx-attributes-panel { font-size: 15px; }\n",
       ".lx-gif-optimized .lx-current-highlight { text-decoration-thickness: 4px; }\n",
       "</style>\n",
       "    <div class=\"lx-animated-wrapper lx-gif-optimized\">\n",
       "      <div class=\"lx-attributes-panel\">\n",
       "        <div class=\"lx-legend\">Highlights Legend: <span class=\"lx-label\" style=\"background-color:#D2E3FC;\">audience_impact</span> <span class=\"lx-label\" style=\"background-color:#C8E6C9;\">opinion_statement</span></div>\n",
       "        <div id=\"attributesContainer\"></div>\n",
       "      </div>\n",
       "      <div class=\"lx-text-window\" id=\"textWindow\">\n",
       "        **Page 1**\n",
       "&quot;&quot;&quot;\n",
       "Dune: Part Two <span class=\"lx-highlight lx-current-highlight\" data-idx=\"0\" style=\"background-color:#C8E6C9;\">sacrifices intimate character-based storytelling for epic \n",
       "spectacle</span>,  \n",
       "resulting in a grand vision for <span class=\"lx-highlight\" data-idx=\"1\" style=\"background-color:#C8E6C9;\">a narrative that feels thematically barren and \n",
       "visually dry</span>.  \n",
       "It does not bode well for the rest of the film that <span class=\"lx-highlight\" data-idx=\"2\" style=\"background-color:#C8E6C9;\">Butler&#x27;s Feyd-Rautha has better  \n",
       "chemistry with his own uncle, Baron Harkonnen, than Chalamet does with \n",
       "Zendaya&#x27;s Chani</span>. \n",
       "(Source: Wooder&#x27;s Reviews) \n",
       "\n",
       "Youre going to see people throw around the word masterpiece about Dune: \n",
       "Part Two and  \n",
       "Im not going to sit here and tell you they are wrong. It very well might be. <span class=\"lx-highlight\" data-idx=\"3\" style=\"background-color:#C8E6C9;\">The \n",
       "effects  \n",
       "in this movie are gorgeous</span>. Sometimes I get down on CGI but <span class=\"lx-highlight\" data-idx=\"4\" style=\"background-color:#C8E6C9;\">I found a lot of what \n",
       "I was  \n",
       "looking at to be stunning</span>. Most significantly, Paul being sent on the challenge of \n",
       "riding  \n",
       "a sandworm. <span class=\"lx-highlight\" data-idx=\"5\" style=\"background-color:#C8E6C9;\">This is a gorgeous, triumphant-looking scene</span>. (Source: UPROXX) \n",
       "\n",
       "<span class=\"lx-highlight\" data-idx=\"6\" style=\"background-color:#C8E6C9;\">Its a breathtaking piece of blockbuster art</span> that, like its predecessor, <span class=\"lx-highlight\" data-idx=\"7\" style=\"background-color:#C8E6C9;\">makes a \n",
       "dense  \n",
       "sci-fi world magically tangible</span>. It engulfs your mind in the spice melange; <span class=\"lx-highlight\" data-idx=\"8\" style=\"background-color:#D2E3FC;\">its a \n",
       "movie  \n",
       "that you dont just watch but experience</span>. (Source: Cinemablend) \n",
       "\n",
       "<span class=\"lx-highlight\" data-idx=\"9\" style=\"background-color:#C8E6C9;\">Zendaya holds the film in her palm, with resolution and clarity</span>. (Source: The \n",
       "Independent)\n",
       "&quot;&quot;&quot;\n",
       "\n",
       "**Page 2**\n",
       "&quot;&quot;&quot;\n",
       "\n",
       "&quot;&quot;&quot;\n",
       "\n",
       "\n",
       "      </div>\n",
       "      <div class=\"lx-controls\">\n",
       "        <div class=\"lx-button-row\">\n",
       "          <button class=\"lx-control-btn\" onclick=\"playPause()\"> Play</button>\n",
       "          <button class=\"lx-control-btn\" onclick=\"prevExtraction()\"> Previous</button>\n",
       "          <button class=\"lx-control-btn\" onclick=\"nextExtraction()\"> Next</button>\n",
       "        </div>\n",
       "        <div class=\"lx-progress-container\">\n",
       "          <input type=\"range\" id=\"progressSlider\" class=\"lx-progress-slider\"\n",
       "                 min=\"0\" max=\"9\" value=\"0\"\n",
       "                 onchange=\"jumpToExtraction(this.value)\">\n",
       "        </div>\n",
       "        <div class=\"lx-status-text\">\n",
       "          Entity <span id=\"entityInfo\">1/10</span> |\n",
       "          Pos <span id=\"posInfo\">[30-98]</span>\n",
       "        </div>\n",
       "      </div>\n",
       "    </div>\n",
       "\n",
       "    <script>\n",
       "      (function() {\n",
       "        const extractions = [{\"index\": 0, \"class\": \"opinion_statement\", \"text\": \"sacrifices intimate character-based storytelling for epic spectacle\", \"color\": \"#C8E6C9\", \"startPos\": 30, \"endPos\": 98, \"beforeText\": \"**Page 1**\\n&quot;&quot;&quot;\\nDune: Part Two \", \"extractionText\": \"sacrifices intimate character-based storytelling for epic \\nspectacle\", \"afterText\": \",  \\nresulting in a grand vision for a narrative that feels thematically barren and \\nvisually dry.  \\nIt does not bode well for the rest of the film tha\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">Dune: Part Two</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Negative</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">sacrifices intimate character-based storytelling for epic spectacle</span>}</div>\"}, {\"index\": 1, \"class\": \"opinion_statement\", \"text\": \"a narrative that feels thematically barren and visually dry\", \"color\": \"#C8E6C9\", \"startPos\": 134, \"endPos\": 194, \"beforeText\": \"**Page 1**\\n&quot;&quot;&quot;\\nDune: Part Two sacrifices intimate character-based storytelling for epic \\nspectacle,  \\nresulting in a grand vision for \", \"extractionText\": \"a narrative that feels thematically barren and \\nvisually dry\", \"afterText\": \".  \\nIt does not bode well for the rest of the film that Butler&#x27;s Feyd-Rautha has better  \\nchemistry with his own uncle, Baron Harkonnen, than Chalamet\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">The narrative</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Negative</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">thematically barren and visually dry</span>}</div>\"}, {\"index\": 2, \"class\": \"opinion_statement\", \"text\": \"Butler's Feyd-Rautha has better chemistry with his own uncle, Baron Harkonnen, than Chalamet does with Zendaya's Chani\", \"color\": \"#C8E6C9\", \"startPos\": 250, \"endPos\": 371, \"beforeText\": \" \\nresulting in a grand vision for a narrative that feels thematically barren and \\nvisually dry.  \\nIt does not bode well for the rest of the film that \", \"extractionText\": \"Butler&#x27;s Feyd-Rautha has better  \\nchemistry with his own uncle, Baron Harkonnen, than Chalamet does with \\nZendaya&#x27;s Chani\", \"afterText\": \". \\n(Source: Wooder&#x27;s Reviews) \\n \\nYou\\u2019re going to see people throw around the word \\u201cmasterpiece\\u201d about Dune: \\nPart Two and  \\nI\\u2019m not going to sit here \", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">Chemistry between characters</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Negative</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">better chemistry with his own uncle... than Chalamet does with Zendaya&#x27;s Chani</span>}</div>\"}, {\"index\": 3, \"class\": \"opinion_statement\", \"text\": \"The effects in this movie are gorgeous\", \"color\": \"#C8E6C9\", \"startPos\": 573, \"endPos\": 614, \"beforeText\": \" people throw around the word \\u201cmasterpiece\\u201d about Dune: \\nPart Two and  \\nI\\u2019m not going to sit here and tell you they are wrong. It very well might be. \", \"extractionText\": \"The \\neffects  \\nin this movie are gorgeous\", \"afterText\": \". Sometimes I get down on CGI but I found a lot of what \\nI was  \\nlooking at to be stunning. Most significantly, Paul being sent on the challenge of \\nr\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">The effects</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">gorgeous</span>}</div>\"}, {\"index\": 4, \"class\": \"opinion_statement\", \"text\": \"I found a lot of what I was looking at to be stunning\", \"color\": \"#C8E6C9\", \"startPos\": 648, \"endPos\": 704, \"beforeText\": \" not going to sit here and tell you they are wrong. It very well might be. The \\neffects  \\nin this movie are gorgeous. Sometimes I get down on CGI but \", \"extractionText\": \"I found a lot of what \\nI was  \\nlooking at to be stunning\", \"afterText\": \". Most significantly, Paul being sent on the challenge of \\nriding  \\na sandworm. This is a gorgeous, triumphant-looking scene. (Source: UPROXX) \\n \\nIt\\u2019s\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">Visuals</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">stunning</span>}</div>\"}, {\"index\": 5, \"class\": \"opinion_statement\", \"text\": \"This is a gorgeous, triumphant-looking scene\", \"color\": \"#C8E6C9\", \"startPos\": 784, \"endPos\": 828, \"beforeText\": \"wn on CGI but I found a lot of what \\nI was  \\nlooking at to be stunning. Most significantly, Paul being sent on the challenge of \\nriding  \\na sandworm. \", \"extractionText\": \"This is a gorgeous, triumphant-looking scene\", \"afterText\": \". (Source: UPROXX) \\n \\nIt\\u2019s a breathtaking piece of blockbuster art that, like its predecessor, makes a \\ndense  \\nsci-fi world magically tangible. It en\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">Paul being sent on the challenge of riding a sandworm</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">gorgeous, triumphant-looking</span>}</div>\"}, {\"index\": 6, \"class\": \"opinion_statement\", \"text\": \"It\\u2019s a breathtaking piece of blockbuster art\", \"color\": \"#C8E6C9\", \"startPos\": 850, \"endPos\": 894, \"beforeText\": \"ning. Most significantly, Paul being sent on the challenge of \\nriding  \\na sandworm. This is a gorgeous, triumphant-looking scene. (Source: UPROXX) \\n \\n\", \"extractionText\": \"It\\u2019s a breathtaking piece of blockbuster art\", \"afterText\": \" that, like its predecessor, makes a \\ndense  \\nsci-fi world magically tangible. It engulfs your mind in the spice melange; it\\u2019s a \\nmovie  \\nthat you don\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">The film</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">breathtaking piece of blockbuster art</span>}</div>\"}, {\"index\": 7, \"class\": \"opinion_statement\", \"text\": \"makes a dense sci-fi world magically tangible\", \"color\": \"#C8E6C9\", \"startPos\": 923, \"endPos\": 971, \"beforeText\": \" sandworm. This is a gorgeous, triumphant-looking scene. (Source: UPROXX) \\n \\nIt\\u2019s a breathtaking piece of blockbuster art that, like its predecessor, \", \"extractionText\": \"makes a \\ndense  \\nsci-fi world magically tangible\", \"afterText\": \". It engulfs your mind in the spice melange; it\\u2019s a \\nmovie  \\nthat you don\\u2019t just watch but experience. (Source: Cinemablend) \\n \\nZendaya holds the film\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">The film</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">magically tangible</span>}</div>\"}, {\"index\": 8, \"class\": \"audience_impact\", \"text\": \"it\\u2019s a movie that you don\\u2019t just watch but experience\", \"color\": \"#D2E3FC\", \"startPos\": 1016, \"endPos\": 1072, \"beforeText\": \"ing piece of blockbuster art that, like its predecessor, makes a \\ndense  \\nsci-fi world magically tangible. It engulfs your mind in the spice melange; \", \"extractionText\": \"it\\u2019s a \\nmovie  \\nthat you don\\u2019t just watch but experience\", \"afterText\": \". (Source: Cinemablend) \\n \\nZendaya holds the film in her palm, with resolution and clarity. (Source: The \\nIndependent)\\n&quot;&quot;&quot;\\n\\n**Page 2**\\n&quot;&quot;&quot;\\n\\n&quot;&quot;&quot;\\n\\n\", \"attributesHtml\": \"<div><strong>class:</strong> audience_impact</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">emotion_evoked</span>: <span class=\\\"lx-attr-value\\\">immersive</span>, <span class=\\\"lx-attr-key\\\">causal_element</span>: <span class=\\\"lx-attr-value\\\">The film</span>, <span class=\\\"lx-attr-key\\\">target_audience</span>: <span class=\\\"lx-attr-value\\\">the audience</span>}</div>\"}, {\"index\": 9, \"class\": \"opinion_statement\", \"text\": \"Zendaya holds the film in her palm, with resolution and clarity\", \"color\": \"#C8E6C9\", \"startPos\": 1099, \"endPos\": 1162, \"beforeText\": \"rld magically tangible. It engulfs your mind in the spice melange; it\\u2019s a \\nmovie  \\nthat you don\\u2019t just watch but experience. (Source: Cinemablend) \\n \\n\", \"extractionText\": \"Zendaya holds the film in her palm, with resolution and clarity\", \"afterText\": \". (Source: The \\nIndependent)\\n&quot;&quot;&quot;\\n\\n**Page 2**\\n&quot;&quot;&quot;\\n\\n&quot;&quot;&quot;\\n\\n\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">Zendaya&#x27;s performance</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">holds the film in her palm, with resolution and clarity</span>}</div>\"}];\n",
       "        let currentIndex = 0;\n",
       "        let isPlaying = false;\n",
       "        let animationInterval = null;\n",
       "        let animationSpeed = 1.0;\n",
       "\n",
       "        function updateDisplay() {\n",
       "          const extraction = extractions[currentIndex];\n",
       "          if (!extraction) return;\n",
       "\n",
       "          document.getElementById('attributesContainer').innerHTML = extraction.attributesHtml;\n",
       "          document.getElementById('entityInfo').textContent = (currentIndex + 1) + '/' + extractions.length;\n",
       "          document.getElementById('posInfo').textContent = '[' + extraction.startPos + '-' + extraction.endPos + ']';\n",
       "          document.getElementById('progressSlider').value = currentIndex;\n",
       "\n",
       "          const playBtn = document.querySelector('.lx-control-btn');\n",
       "          if (playBtn) playBtn.textContent = isPlaying ? ' Pause' : ' Play';\n",
       "\n",
       "          const prevHighlight = document.querySelector('.lx-text-window .lx-current-highlight');\n",
       "          if (prevHighlight) prevHighlight.classList.remove('lx-current-highlight');\n",
       "          const currentSpan = document.querySelector('.lx-text-window span[data-idx=\"' + currentIndex + '\"]');\n",
       "          if (currentSpan) {\n",
       "            currentSpan.classList.add('lx-current-highlight');\n",
       "            currentSpan.scrollIntoView({block: 'center', behavior: 'smooth'});\n",
       "          }\n",
       "        }\n",
       "\n",
       "        function nextExtraction() {\n",
       "          currentIndex = (currentIndex + 1) % extractions.length;\n",
       "          updateDisplay();\n",
       "        }\n",
       "\n",
       "        function prevExtraction() {\n",
       "          currentIndex = (currentIndex - 1 + extractions.length) % extractions.length;\n",
       "          updateDisplay();\n",
       "        }\n",
       "\n",
       "        function jumpToExtraction(index) {\n",
       "          currentIndex = parseInt(index);\n",
       "          updateDisplay();\n",
       "        }\n",
       "\n",
       "        function playPause() {\n",
       "          if (isPlaying) {\n",
       "            clearInterval(animationInterval);\n",
       "            isPlaying = false;\n",
       "          } else {\n",
       "            animationInterval = setInterval(nextExtraction, animationSpeed * 1000);\n",
       "            isPlaying = true;\n",
       "          }\n",
       "          updateDisplay();\n",
       "        }\n",
       "\n",
       "        window.playPause = playPause;\n",
       "        window.nextExtraction = nextExtraction;\n",
       "        window.prevExtraction = prevExtraction;\n",
       "        window.jumpToExtraction = jumpToExtraction;\n",
       "\n",
       "        updateDisplay();\n",
       "      })();\n",
       "    </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <a id='toc1_5_8_'></a>[**2.4 Generating LLM Embeddings:**](#toc0_)\n",
    "\n",
    "LLM embeddings are dense numerical vectors that represent the semantic meaning of text. Generated by Large Language Models, they map words, phrases, or documents into a high-dimensional space where similar concepts are positioned closely together.\n",
    "\n",
    "Their key advantages are:\n",
    "\n",
    "*   **Contextual Understanding:** Unlike older methods, LLM embeddings are contextual. The vector for a word like **\"bank\"** will be different depending on whether it's used in the context of a \"river bank\" or a \"money bank,\" providing a more nuanced representation of language.\n",
    "\n",
    "*   **Versatility from Pre-training:** They are pre-trained on vast amounts of text data. This allows them to generalize effectively across various tasks, such as classification, clustering, and similarity detection. They do not require extensive retraining.\n",
    "\n",
    "<span style=\"color:green\">For the exercise in this section there is no need to re-run the cells, you can use the data that has been saved previously to the corresponding directory.</span>\n",
    "\n",
    "**Now let's generate some embeddings with Gemini for a sample of our dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "import pandas as pd\n",
    "import time\n",
    "from google.api_core import exceptions\n",
    "\n",
    "# Let's define our function to get the embeddings with Gemini\n",
    "def get_gemini_embedding(text: str, model: str=\"gemini-embedding-001\"):\n",
    "    try:\n",
    "        result = client.models.embed_content(model=model, contents=[text])\n",
    "        # 100 requests per minute limit -> 60s / 100 = 0.6s per request\n",
    "        # buffer time to avoid rate limits\n",
    "        time.sleep(0.6)\n",
    "        return result.embeddings\n",
    "    except exceptions.ResourceExhausted as e:\n",
    "        print(f\"Rate limit exceeded. Waiting to retry... Error: {e}\")\n",
    "        time.sleep(5) # Wait for 5 seconds before the next attempt\n",
    "        return get_gemini_embedding(text, model) # Retry the request\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 160 rows from the training set...\n",
      "Sampling 40 rows from the test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2976\\2000596105.py:14: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sampled_df = df.groupby(stratify_col, group_keys=False).apply(\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2976\\2000596105.py:14: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sampled_df = df.groupby(stratify_col, group_keys=False).apply(\n"
     ]
    }
   ],
   "source": [
    "total_extractions = 200\n",
    "train_ratio = 0.8\n",
    "test_ratio = 0.2\n",
    "\n",
    "n_train_to_sample = int(total_extractions * train_ratio)\n",
    "n_test_to_sample = int(total_extractions * test_ratio)\n",
    "# We use the text column\n",
    "column_name = 'text'\n",
    "\n",
    "# This function is to get a stratified sample from our data, meaning to have the same distribution of labels as in the full dataset\n",
    "def stratified_sample(df: pd.DataFrame, n_samples: int, stratify_col: str = 'emotion') -> pd.DataFrame:\n",
    "    if n_samples >= len(df):\n",
    "        return df.copy() # Return a copy if requested sample is larger or equal\n",
    "    sampled_df = df.groupby(stratify_col, group_keys=False).apply(\n",
    "        lambda x: x.sample(n=max(0, int(round(len(x) / len(df) * n_samples))))\n",
    "    )\n",
    "\n",
    "    # Adjust for rounding errors to get the exact number of samples\n",
    "    current_samples = len(sampled_df)\n",
    "    if current_samples < n_samples:\n",
    "        remaining_indices = df.index.difference(sampled_df.index)\n",
    "        additional_samples = df.loc[remaining_indices].sample(n=n_samples - current_samples, random_state=42)\n",
    "        sampled_df = pd.concat([sampled_df, additional_samples])\n",
    "    elif current_samples > n_samples:\n",
    "        sampled_df = sampled_df.sample(n=n_samples, random_state=42)\n",
    "    return sampled_df\n",
    "\n",
    "print(f\"Sampling {n_train_to_sample} rows from the training set...\")\n",
    "train_df_new = stratified_sample(train_df, n_train_to_sample, 'emotion')\n",
    "\n",
    "print(f\"Sampling {n_test_to_sample} rows from the test set...\")\n",
    "test_df_new = stratified_sample(test_df, n_test_to_sample, 'emotion')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "fear       51\n",
       "anger      38\n",
       "joy        36\n",
       "sadness    35\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_new[\"emotion\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "fear       13\n",
       "anger      10\n",
       "joy         9\n",
       "sadness     8\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_new[\"emotion\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating embeddings for the new training set...\n"
     ]
    }
   ],
   "source": [
    "# Apply the function to the specified column and store the result in a new column 'embeddings'\n",
    "print(\"\\nGenerating embeddings for the new training set...\")\n",
    "train_df_new['embeddings'] = train_df_new[column_name].apply(get_gemini_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating embeddings for the new test set...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nGenerating embeddings for the new test set...\")\n",
    "test_df_new['embeddings'] = test_df_new[column_name].apply(get_gemini_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.genai import types\n",
    "\n",
    "# After getting the embeddings we need to convert the Gemini type ContentDict of the embeddings into a simple list with them\n",
    "train_df_new['embeddings_values'] = train_df_new[\"embeddings\"].apply(lambda row: list(types.ContentDict(row[0]).values())[0])\n",
    "test_df_new['embeddings_values'] = test_df_new[\"embeddings\"].apply(lambda row: list(types.ContentDict(row[0]).values())[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>intensity</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>embeddings_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>10445</td>\n",
       "      <td>@trendykittykat Some people would rather hang ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.479</td>\n",
       "      <td>[values=[-0.04011455, 0.0054818913, -0.0014656...</td>\n",
       "      <td>[-0.04011455, 0.0054818913, -0.001465602, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>10218</td>\n",
       "      <td>@AskPS_UK not received verification email, ask...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.604</td>\n",
       "      <td>[values=[-0.009370596, 0.0041796705, -0.020837...</td>\n",
       "      <td>[-0.009370596, 0.0041796705, -0.0208379, -0.05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>10676</td>\n",
       "      <td>Nurse practitioner: 'you look pretty bad. No o...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.444</td>\n",
       "      <td>[values=[-0.01898404, -0.018371668, -0.0052958...</td>\n",
       "      <td>[-0.01898404, -0.018371668, -0.005295807, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>10464</td>\n",
       "      <td>@DRUDGE_REPORT @FoxNews good thing the FBI did...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.479</td>\n",
       "      <td>[values=[-0.03012641, -0.0057127955, 0.0038404...</td>\n",
       "      <td>[-0.03012641, -0.0057127955, 0.0038404157, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>10681</td>\n",
       "      <td>@RichardHBell Yes, I think he held a grudge ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.375</td>\n",
       "      <td>[values=[-0.010785116, 0.00584416, 0.007068827...</td>\n",
       "      <td>[-0.010785116, 0.00584416, 0.0070688273, -0.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3509</th>\n",
       "      <td>40682</td>\n",
       "      <td>it didn't impress me but it didn't depress me'</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.271</td>\n",
       "      <td>[values=[0.01384693, 0.0033120282, -0.00642295...</td>\n",
       "      <td>[0.01384693, 0.0033120282, -0.006422956, -0.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3012</th>\n",
       "      <td>40185</td>\n",
       "      <td>It's pretty clear I can't stand @HillaryClinto...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.646</td>\n",
       "      <td>[values=[-0.008868483, -0.0044090776, 0.014982...</td>\n",
       "      <td>[-0.008868483, -0.0044090776, 0.014982221, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2947</th>\n",
       "      <td>40120</td>\n",
       "      <td>where broken hearted lovers do cry away their ...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.708</td>\n",
       "      <td>[values=[-0.01893575, 0.015380341, -0.00087094...</td>\n",
       "      <td>[-0.01893575, 0.015380341, -0.0008709412, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3098</th>\n",
       "      <td>40271</td>\n",
       "      <td>My friends tell me I'm pretty. Trigger tells m...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.583</td>\n",
       "      <td>[values=[-0.0046970346, -0.0111657875, -0.0087...</td>\n",
       "      <td>[-0.0046970346, -0.0111657875, -0.008741113, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3085</th>\n",
       "      <td>40258</td>\n",
       "      <td>@big_SL8 Show some respect, that's all...  If ...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.583</td>\n",
       "      <td>[values=[-0.01799791, 0.007835888, 0.00903695,...</td>\n",
       "      <td>[-0.01799791, 0.007835888, 0.00903695, -0.0576...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text  emotion  \\\n",
       "445   10445  @trendykittykat Some people would rather hang ...    anger   \n",
       "218   10218  @AskPS_UK not received verification email, ask...    anger   \n",
       "676   10676  Nurse practitioner: 'you look pretty bad. No o...    anger   \n",
       "464   10464  @DRUDGE_REPORT @FoxNews good thing the FBI did...    anger   \n",
       "681   10681    @RichardHBell Yes, I think he held a grudge ...    anger   \n",
       "...     ...                                                ...      ...   \n",
       "3509  40682     it didn't impress me but it didn't depress me'  sadness   \n",
       "3012  40185  It's pretty clear I can't stand @HillaryClinto...  sadness   \n",
       "2947  40120  where broken hearted lovers do cry away their ...  sadness   \n",
       "3098  40271  My friends tell me I'm pretty. Trigger tells m...  sadness   \n",
       "3085  40258  @big_SL8 Show some respect, that's all...  If ...  sadness   \n",
       "\n",
       "      intensity                                         embeddings  \\\n",
       "445       0.479  [values=[-0.04011455, 0.0054818913, -0.0014656...   \n",
       "218       0.604  [values=[-0.009370596, 0.0041796705, -0.020837...   \n",
       "676       0.444  [values=[-0.01898404, -0.018371668, -0.0052958...   \n",
       "464       0.479  [values=[-0.03012641, -0.0057127955, 0.0038404...   \n",
       "681       0.375  [values=[-0.010785116, 0.00584416, 0.007068827...   \n",
       "...         ...                                                ...   \n",
       "3509      0.271  [values=[0.01384693, 0.0033120282, -0.00642295...   \n",
       "3012      0.646  [values=[-0.008868483, -0.0044090776, 0.014982...   \n",
       "2947      0.708  [values=[-0.01893575, 0.015380341, -0.00087094...   \n",
       "3098      0.583  [values=[-0.0046970346, -0.0111657875, -0.0087...   \n",
       "3085      0.583  [values=[-0.01799791, 0.007835888, 0.00903695,...   \n",
       "\n",
       "                                      embeddings_values  \n",
       "445   [-0.04011455, 0.0054818913, -0.001465602, -0.0...  \n",
       "218   [-0.009370596, 0.0041796705, -0.0208379, -0.05...  \n",
       "676   [-0.01898404, -0.018371668, -0.005295807, -0.0...  \n",
       "464   [-0.03012641, -0.0057127955, 0.0038404157, -0....  \n",
       "681   [-0.010785116, 0.00584416, 0.0070688273, -0.08...  \n",
       "...                                                 ...  \n",
       "3509  [0.01384693, 0.0033120282, -0.006422956, -0.08...  \n",
       "3012  [-0.008868483, -0.0044090776, 0.014982221, -0....  \n",
       "2947  [-0.01893575, 0.015380341, -0.0008709412, -0.0...  \n",
       "3098  [-0.0046970346, -0.0111657875, -0.008741113, -...  \n",
       "3085  [-0.01799791, 0.007835888, 0.00903695, -0.0576...  \n",
       "\n",
       "[160 rows x 6 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_new #We can see the new column with the embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>intensity</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>embeddings_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>30888</td>\n",
       "      <td>@tomlinmayniac starting my new challenge ! A g...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.625</td>\n",
       "      <td>[values=[-0.019158924, 0.026136786, 0.00889167...</td>\n",
       "      <td>[-0.019158924, 0.026136786, 0.008891672, -0.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>21225</td>\n",
       "      <td>The moment you bring her to meet your best fri...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.771</td>\n",
       "      <td>[values=[-0.047124993, -0.004152473, -0.005977...</td>\n",
       "      <td>[-0.047124993, -0.004152473, -0.0059770048, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>10905</td>\n",
       "      <td>Ok scrubbed hands 5 times before trying to put...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.604</td>\n",
       "      <td>[values=[-0.010922581, -0.010670915, -0.001972...</td>\n",
       "      <td>[-0.010922581, -0.010670915, -0.0019729831, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>30880</td>\n",
       "      <td>Metal keeps you young and spry and keeps your ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.460</td>\n",
       "      <td>[values=[-0.02270393, 0.012822644, 0.021123048...</td>\n",
       "      <td>[-0.02270393, 0.012822644, 0.021123048, -0.077...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>10889</td>\n",
       "      <td>Ananya just grabbed a bible, opened it, starte...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.417</td>\n",
       "      <td>[values=[0.0017778199, -0.03282479, 0.01083367...</td>\n",
       "      <td>[0.0017778199, -0.03282479, 0.010833675, -0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>40819</td>\n",
       "      <td>@kempicepoland don't think he did, and he didn...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.500</td>\n",
       "      <td>[values=[0.014776666, 0.00030646138, -0.009222...</td>\n",
       "      <td>[0.014776666, 0.00030646138, -0.009222993, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>21167</td>\n",
       "      <td>@joey_coops yes Hun! Avoid at all costs!! #nig...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.667</td>\n",
       "      <td>[values=[0.00048812552, -0.009660845, -0.01429...</td>\n",
       "      <td>[0.00048812552, -0.009660845, -0.01429285, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>40839</td>\n",
       "      <td>HATE that there's ads for #depression &amp;amp; #m...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.460</td>\n",
       "      <td>[values=[-0.008212951, -0.012283811, -0.005047...</td>\n",
       "      <td>[-0.008212951, -0.012283811, -0.005047617, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>30832</td>\n",
       "      <td>This tweet is dedicated to my back pain, which...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.229</td>\n",
       "      <td>[values=[-0.008182137, 0.0094519975, -0.002431...</td>\n",
       "      <td>[-0.008182137, 0.0094519975, -0.00243182, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>10926</td>\n",
       "      <td>If I spend even 5 minutes with you and you alr...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.812</td>\n",
       "      <td>[values=[-0.009919291, 0.011396133, 0.01161555...</td>\n",
       "      <td>[-0.009919291, 0.011396133, 0.011615556, -0.05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>30825</td>\n",
       "      <td>Nawaz Sharif is getting more funnier than @kap...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.580</td>\n",
       "      <td>[values=[-0.03421193, 0.017039796, 0.028741952...</td>\n",
       "      <td>[-0.03421193, 0.017039796, 0.028741952, -0.085...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>21245</td>\n",
       "      <td>Hillary Clinton looked the other way to the Sa...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.479</td>\n",
       "      <td>[values=[-0.002730555, 0.00785198, -0.01620275...</td>\n",
       "      <td>[-0.002730555, 0.00785198, -0.016202757, -0.06...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>21197</td>\n",
       "      <td>@CNNPolitics I can't wait to hear what he had ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.246</td>\n",
       "      <td>[values=[0.00044486194, 0.01613851, 0.02635799...</td>\n",
       "      <td>[0.00044486194, 0.01613851, 0.026357992, -0.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>10933</td>\n",
       "      <td>(Sam) Brown's Law: Never offend people with st...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.333</td>\n",
       "      <td>[values=[0.017159522, -0.0068402686, -0.008005...</td>\n",
       "      <td>[0.017159522, -0.0068402686, -0.008005174, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>21236</td>\n",
       "      <td>Bout ta get my @dontbreathe on up in here! @Wa...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.688</td>\n",
       "      <td>[values=[-0.01897632, -0.0027345729, -0.003509...</td>\n",
       "      <td>[-0.01897632, -0.0027345729, -0.003509044, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>40855</td>\n",
       "      <td>Common app just randomly logged me out as I wa...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.833</td>\n",
       "      <td>[values=[0.0018189758, 0.023590546, -0.0067852...</td>\n",
       "      <td>[0.0018189758, 0.023590546, -0.0067852526, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>21207</td>\n",
       "      <td>@LethalWeaponFOX This show SUCKS! #lame #awful...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.396</td>\n",
       "      <td>[values=[-0.04764038, 0.010794757, 0.004717541...</td>\n",
       "      <td>[-0.04764038, 0.010794757, 0.0047175414, -0.05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>40790</td>\n",
       "      <td>All I want to do is watch some netflix but I a...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.667</td>\n",
       "      <td>[values=[-0.0058988086, 0.013784122, -0.015859...</td>\n",
       "      <td>[-0.0058988086, 0.013784122, -0.015859485, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>40828</td>\n",
       "      <td>Don't depress yourself by comparing yourself. ...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.438</td>\n",
       "      <td>[values=[0.009750189, 0.0027657712, 0.00792557...</td>\n",
       "      <td>[0.009750189, 0.0027657712, 0.007925576, -0.06...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>10932</td>\n",
       "      <td>@DJ_JeanFranko growl!!!</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.500</td>\n",
       "      <td>[values=[0.015252903, 0.0042496077, 0.02459122...</td>\n",
       "      <td>[0.015252903, 0.0042496077, 0.024591228, -0.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>30828</td>\n",
       "      <td>I love my family so much #lucky #grateful #sma...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.792</td>\n",
       "      <td>[values=[-0.041261364, -0.0025729102, 0.000523...</td>\n",
       "      <td>[-0.041261364, -0.0025729102, 0.00052370684, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>10894</td>\n",
       "      <td>i live and die for mchanzo honeymoon crashing ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.479</td>\n",
       "      <td>[values=[-0.0010682619, 0.018157829, -0.005871...</td>\n",
       "      <td>[-0.0010682619, 0.018157829, -0.005871065, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>21194</td>\n",
       "      <td>also i had an awful nightmare involving being ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.896</td>\n",
       "      <td>[values=[0.009203733, -0.017150467, -0.0084802...</td>\n",
       "      <td>[0.009203733, -0.017150467, -0.008480225, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10857</td>\n",
       "      <td>@ZubairSabirPTI  pls dont insult the word 'Molna'</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.479</td>\n",
       "      <td>[values=[0.009774932, 0.0055678063, -0.0006229...</td>\n",
       "      <td>[0.009774932, 0.0055678063, -0.00062292145, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>30848</td>\n",
       "      <td>Ready for that nice, breezy, calm, sunshine we...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.583</td>\n",
       "      <td>[values=[0.0020740312, -0.023727704, -0.016465...</td>\n",
       "      <td>[0.0020740312, -0.023727704, -0.016465494, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>21238</td>\n",
       "      <td>#twitter #users Tweeting on twitter is like pl...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.521</td>\n",
       "      <td>[values=[-0.024715586, -0.01256246, -0.0125413...</td>\n",
       "      <td>[-0.024715586, -0.01256246, -0.0125413975, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>10906</td>\n",
       "      <td>Just joined #pottermore and was sorted into HU...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.708</td>\n",
       "      <td>[values=[0.0059057474, -0.034324665, 0.0036267...</td>\n",
       "      <td>[0.0059057474, -0.034324665, 0.0036267077, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>30884</td>\n",
       "      <td>@billie21806 @cnnbrk tell that to your bodies ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.100</td>\n",
       "      <td>[values=[0.01293416, 0.011050483, 0.025073575,...</td>\n",
       "      <td>[0.01293416, 0.011050483, 0.025073575, -0.0431...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>40813</td>\n",
       "      <td>This shit hurting my heart  that's how seriou...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.875</td>\n",
       "      <td>[values=[-0.0069135656, -0.0037595944, -0.0228...</td>\n",
       "      <td>[-0.0069135656, -0.0037595944, -0.022816306, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10874</td>\n",
       "      <td>@__NETFLIXNCHILL I fuck with madden way harder</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.521</td>\n",
       "      <td>[values=[-0.01393127, -0.004997253, -0.0122807...</td>\n",
       "      <td>[-0.01393127, -0.004997253, -0.012280725, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>40789</td>\n",
       "      <td>Stars, when you shine,\\nYou know how I feel.\\n...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.292</td>\n",
       "      <td>[values=[0.011783604, 0.007787306, 0.008415056...</td>\n",
       "      <td>[0.011783604, 0.007787306, 0.008415056, -0.080...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>30861</td>\n",
       "      <td>@yungdoujin wouldn't that basically be sparkli...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.320</td>\n",
       "      <td>[values=[0.03212864, 0.018269602, 0.005003729,...</td>\n",
       "      <td>[0.03212864, 0.018269602, 0.005003729, -0.1061...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>40797</td>\n",
       "      <td>Wow just watched Me Before You and it was seri...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.667</td>\n",
       "      <td>[values=[-0.016169224, -0.0027164714, -0.00830...</td>\n",
       "      <td>[-0.016169224, -0.0027164714, -0.008305452, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>21217</td>\n",
       "      <td>@RyanAbe awe yay thank god I was so worried.</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.500</td>\n",
       "      <td>[values=[-0.0054168217, -0.010775616, -0.01392...</td>\n",
       "      <td>[-0.0054168217, -0.010775616, -0.013928164, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>21175</td>\n",
       "      <td>@soozclifford Sure have... Sydney are too toug...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.356</td>\n",
       "      <td>[values=[-0.0070301127, -0.0028043932, 0.01494...</td>\n",
       "      <td>[-0.0070301127, -0.0028043932, 0.014941143, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>21172</td>\n",
       "      <td>@TheDappaMc also 2.50 for a chocolate Feast i...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.438</td>\n",
       "      <td>[values=[0.0048581217, -0.0056593698, -0.00239...</td>\n",
       "      <td>[0.0048581217, -0.0056593698, -0.0023954825, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>21151</td>\n",
       "      <td>Really.....#Jumanji 2....w/ The Rock, Jack Bla...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.542</td>\n",
       "      <td>[values=[-0.005593506, -0.048560806, 0.0125558...</td>\n",
       "      <td>[-0.005593506, -0.048560806, 0.012555859, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>10927</td>\n",
       "      <td>Sting is just too damn earnest for early morni...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.370</td>\n",
       "      <td>[values=[-0.014882094, 0.0127369985, -0.016873...</td>\n",
       "      <td>[-0.014882094, 0.0127369985, -0.016873686, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>21187</td>\n",
       "      <td> @FrameOfAnAngel  \\n\\n+ Of them. I'm here fo...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.583</td>\n",
       "      <td>[values=[-0.029143142, -0.026484871, -0.000989...</td>\n",
       "      <td>[-0.029143142, -0.026484871, -0.0009893685, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>30901</td>\n",
       "      <td>A hearty Jonza! to all my friends and follower.</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.704</td>\n",
       "      <td>[values=[0.0013084331, 0.007918925, -0.0007036...</td>\n",
       "      <td>[0.0013084331, 0.007918925, -0.0007036131, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text  emotion  \\\n",
       "259  30888  @tomlinmayniac starting my new challenge ! A g...      joy   \n",
       "162  21225  The moment you bring her to meet your best fri...     fear   \n",
       "48   10905  Ok scrubbed hands 5 times before trying to put...    anger   \n",
       "251  30880  Metal keeps you young and spry and keeps your ...      joy   \n",
       "32   10889  Ananya just grabbed a bible, opened it, starte...    anger   \n",
       "306  40819  @kempicepoland don't think he did, and he didn...  sadness   \n",
       "104  21167  @joey_coops yes Hun! Avoid at all costs!! #nig...     fear   \n",
       "326  40839  HATE that there's ads for #depression &amp; #m...  sadness   \n",
       "203  30832  This tweet is dedicated to my back pain, which...      joy   \n",
       "69   10926  If I spend even 5 minutes with you and you alr...    anger   \n",
       "196  30825  Nawaz Sharif is getting more funnier than @kap...      joy   \n",
       "182  21245  Hillary Clinton looked the other way to the Sa...     fear   \n",
       "134  21197  @CNNPolitics I can't wait to hear what he had ...     fear   \n",
       "76   10933  (Sam) Brown's Law: Never offend people with st...    anger   \n",
       "173  21236  Bout ta get my @dontbreathe on up in here! @Wa...     fear   \n",
       "342  40855  Common app just randomly logged me out as I wa...  sadness   \n",
       "144  21207  @LethalWeaponFOX This show SUCKS! #lame #awful...     fear   \n",
       "277  40790  All I want to do is watch some netflix but I a...  sadness   \n",
       "315  40828  Don't depress yourself by comparing yourself. ...  sadness   \n",
       "75   10932                            @DJ_JeanFranko growl!!!    anger   \n",
       "199  30828  I love my family so much #lucky #grateful #sma...      joy   \n",
       "37   10894  i live and die for mchanzo honeymoon crashing ...    anger   \n",
       "131  21194  also i had an awful nightmare involving being ...     fear   \n",
       "0    10857  @ZubairSabirPTI  pls dont insult the word 'Molna'    anger   \n",
       "219  30848  Ready for that nice, breezy, calm, sunshine we...      joy   \n",
       "175  21238  #twitter #users Tweeting on twitter is like pl...     fear   \n",
       "49   10906  Just joined #pottermore and was sorted into HU...    anger   \n",
       "255  30884  @billie21806 @cnnbrk tell that to your bodies ...      joy   \n",
       "300  40813  This shit hurting my heart  that's how seriou...  sadness   \n",
       "17   10874     @__NETFLIXNCHILL I fuck with madden way harder    anger   \n",
       "276  40789  Stars, when you shine,\\nYou know how I feel.\\n...  sadness   \n",
       "232  30861  @yungdoujin wouldn't that basically be sparkli...      joy   \n",
       "284  40797  Wow just watched Me Before You and it was seri...  sadness   \n",
       "154  21217       @RyanAbe awe yay thank god I was so worried.     fear   \n",
       "112  21175  @soozclifford Sure have... Sydney are too toug...     fear   \n",
       "109  21172  @TheDappaMc also 2.50 for a chocolate Feast i...     fear   \n",
       "88   21151  Really.....#Jumanji 2....w/ The Rock, Jack Bla...     fear   \n",
       "70   10927  Sting is just too damn earnest for early morni...    anger   \n",
       "124  21187   @FrameOfAnAngel  \\n\\n+ Of them. I'm here fo...     fear   \n",
       "272  30901    A hearty Jonza! to all my friends and follower.      joy   \n",
       "\n",
       "     intensity                                         embeddings  \\\n",
       "259      0.625  [values=[-0.019158924, 0.026136786, 0.00889167...   \n",
       "162      0.771  [values=[-0.047124993, -0.004152473, -0.005977...   \n",
       "48       0.604  [values=[-0.010922581, -0.010670915, -0.001972...   \n",
       "251      0.460  [values=[-0.02270393, 0.012822644, 0.021123048...   \n",
       "32       0.417  [values=[0.0017778199, -0.03282479, 0.01083367...   \n",
       "306      0.500  [values=[0.014776666, 0.00030646138, -0.009222...   \n",
       "104      0.667  [values=[0.00048812552, -0.009660845, -0.01429...   \n",
       "326      0.460  [values=[-0.008212951, -0.012283811, -0.005047...   \n",
       "203      0.229  [values=[-0.008182137, 0.0094519975, -0.002431...   \n",
       "69       0.812  [values=[-0.009919291, 0.011396133, 0.01161555...   \n",
       "196      0.580  [values=[-0.03421193, 0.017039796, 0.028741952...   \n",
       "182      0.479  [values=[-0.002730555, 0.00785198, -0.01620275...   \n",
       "134      0.246  [values=[0.00044486194, 0.01613851, 0.02635799...   \n",
       "76       0.333  [values=[0.017159522, -0.0068402686, -0.008005...   \n",
       "173      0.688  [values=[-0.01897632, -0.0027345729, -0.003509...   \n",
       "342      0.833  [values=[0.0018189758, 0.023590546, -0.0067852...   \n",
       "144      0.396  [values=[-0.04764038, 0.010794757, 0.004717541...   \n",
       "277      0.667  [values=[-0.0058988086, 0.013784122, -0.015859...   \n",
       "315      0.438  [values=[0.009750189, 0.0027657712, 0.00792557...   \n",
       "75       0.500  [values=[0.015252903, 0.0042496077, 0.02459122...   \n",
       "199      0.792  [values=[-0.041261364, -0.0025729102, 0.000523...   \n",
       "37       0.479  [values=[-0.0010682619, 0.018157829, -0.005871...   \n",
       "131      0.896  [values=[0.009203733, -0.017150467, -0.0084802...   \n",
       "0        0.479  [values=[0.009774932, 0.0055678063, -0.0006229...   \n",
       "219      0.583  [values=[0.0020740312, -0.023727704, -0.016465...   \n",
       "175      0.521  [values=[-0.024715586, -0.01256246, -0.0125413...   \n",
       "49       0.708  [values=[0.0059057474, -0.034324665, 0.0036267...   \n",
       "255      0.100  [values=[0.01293416, 0.011050483, 0.025073575,...   \n",
       "300      0.875  [values=[-0.0069135656, -0.0037595944, -0.0228...   \n",
       "17       0.521  [values=[-0.01393127, -0.004997253, -0.0122807...   \n",
       "276      0.292  [values=[0.011783604, 0.007787306, 0.008415056...   \n",
       "232      0.320  [values=[0.03212864, 0.018269602, 0.005003729,...   \n",
       "284      0.667  [values=[-0.016169224, -0.0027164714, -0.00830...   \n",
       "154      0.500  [values=[-0.0054168217, -0.010775616, -0.01392...   \n",
       "112      0.356  [values=[-0.0070301127, -0.0028043932, 0.01494...   \n",
       "109      0.438  [values=[0.0048581217, -0.0056593698, -0.00239...   \n",
       "88       0.542  [values=[-0.005593506, -0.048560806, 0.0125558...   \n",
       "70       0.370  [values=[-0.014882094, 0.0127369985, -0.016873...   \n",
       "124      0.583  [values=[-0.029143142, -0.026484871, -0.000989...   \n",
       "272      0.704  [values=[0.0013084331, 0.007918925, -0.0007036...   \n",
       "\n",
       "                                     embeddings_values  \n",
       "259  [-0.019158924, 0.026136786, 0.008891672, -0.08...  \n",
       "162  [-0.047124993, -0.004152473, -0.0059770048, -0...  \n",
       "48   [-0.010922581, -0.010670915, -0.0019729831, -0...  \n",
       "251  [-0.02270393, 0.012822644, 0.021123048, -0.077...  \n",
       "32   [0.0017778199, -0.03282479, 0.010833675, -0.04...  \n",
       "306  [0.014776666, 0.00030646138, -0.009222993, -0....  \n",
       "104  [0.00048812552, -0.009660845, -0.01429285, -0....  \n",
       "326  [-0.008212951, -0.012283811, -0.005047617, -0....  \n",
       "203  [-0.008182137, 0.0094519975, -0.00243182, -0.0...  \n",
       "69   [-0.009919291, 0.011396133, 0.011615556, -0.05...  \n",
       "196  [-0.03421193, 0.017039796, 0.028741952, -0.085...  \n",
       "182  [-0.002730555, 0.00785198, -0.016202757, -0.06...  \n",
       "134  [0.00044486194, 0.01613851, 0.026357992, -0.07...  \n",
       "76   [0.017159522, -0.0068402686, -0.008005174, -0....  \n",
       "173  [-0.01897632, -0.0027345729, -0.003509044, -0....  \n",
       "342  [0.0018189758, 0.023590546, -0.0067852526, -0....  \n",
       "144  [-0.04764038, 0.010794757, 0.0047175414, -0.05...  \n",
       "277  [-0.0058988086, 0.013784122, -0.015859485, -0....  \n",
       "315  [0.009750189, 0.0027657712, 0.007925576, -0.06...  \n",
       "75   [0.015252903, 0.0042496077, 0.024591228, -0.08...  \n",
       "199  [-0.041261364, -0.0025729102, 0.00052370684, -...  \n",
       "37   [-0.0010682619, 0.018157829, -0.005871065, -0....  \n",
       "131  [0.009203733, -0.017150467, -0.008480225, -0.0...  \n",
       "0    [0.009774932, 0.0055678063, -0.00062292145, -0...  \n",
       "219  [0.0020740312, -0.023727704, -0.016465494, -0....  \n",
       "175  [-0.024715586, -0.01256246, -0.0125413975, -0....  \n",
       "49   [0.0059057474, -0.034324665, 0.0036267077, -0....  \n",
       "255  [0.01293416, 0.011050483, 0.025073575, -0.0431...  \n",
       "300  [-0.0069135656, -0.0037595944, -0.022816306, -...  \n",
       "17   [-0.01393127, -0.004997253, -0.012280725, -0.0...  \n",
       "276  [0.011783604, 0.007787306, 0.008415056, -0.080...  \n",
       "232  [0.03212864, 0.018269602, 0.005003729, -0.1061...  \n",
       "284  [-0.016169224, -0.0027164714, -0.008305452, -0...  \n",
       "154  [-0.0054168217, -0.010775616, -0.013928164, -0...  \n",
       "112  [-0.0070301127, -0.0028043932, 0.014941143, -0...  \n",
       "109  [0.0048581217, -0.0056593698, -0.0023954825, -...  \n",
       "88   [-0.005593506, -0.048560806, 0.012555859, -0.0...  \n",
       "70   [-0.014882094, 0.0127369985, -0.016873686, -0....  \n",
       "124  [-0.029143142, -0.026484871, -0.0009893685, -0...  \n",
       "272  [0.0013084331, 0.007918925, -0.0007036131, -0....  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_new #We can see the new column with the embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save them to pickle files\n",
    "train_df_new.to_pickle(\"./data/train_df_sample_embeddings.pkl\") \n",
    "test_df_new.to_pickle(\"./data/test_df_sample_embeddings.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# load the pickle files\n",
    "train_df_new = pd.read_pickle(\"./data/train_df_sample_embeddings.pkl\")\n",
    "test_df_new = pd.read_pickle(\"./data/test_df_sample_embeddings.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3072"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df_new.iloc[0][\"embeddings_values\"]) # Gemini embedding dimension is 3072 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\DM_Lab_GPU\\Lib\\site-packages\\umap\\umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "customdata": [
          [
           "@trendykittykat Some people would rather hang on to their indignant anger. *weary sigh*",
           0.479
          ],
          [
           "@AskPS_UK not received verification email, asked for it to be resent 5 times still nothing.",
           0.604
          ],
          [
           "Nurse practitioner: 'you look pretty bad. No offense of course.'  \\n\\nThank you, that really added that spark of positivity I needed today.",
           0.444
          ],
          [
           "@DRUDGE_REPORT @FoxNews good thing the FBI didn't offend them!",
           0.479
          ],
          [
           "@RichardHBell Yes, I think he held a grudge ...",
           0.375
          ],
          [
           "Candace &amp; her pout are getting right on my tits #GBBO",
           0.562
          ],
          [
           "That's really it for my madden career that game sucks , ea sports does a piss poor job every year on that shit",
           0.867
          ],
          [
           "@Trump_Videos she looks completely #rabid @realDonaldTrump",
           0.5
          ],
          [
           "@edquinn63 how can you even forget to pick ur fave child up from school #offended",
           0.688
          ],
          [
           "ESPN just assumed I wanted their free magazines #offended",
           0.542
          ],
          [
           "@warFarePower dip it in boiling water",
           0.396
          ],
          [
           "@paulbushnell25 @EE bad news if ordered online it hasn't gone through same happened to me had to re order on the phone #furious",
           0.844
          ],
          [
           "#Anger or #wrath is an intense emotional response.",
           0.562
          ],
          [
           "The new gun emoji in iOS10 is not enough to show the anger I have towards a number of things.",
           0.625
          ],
          [
           "Thatmoment you're watching #worstcelebritycooks and your bubble is burst by finding out KyleXY is gay and married #nochance #KindaDontMind",
           0.479
          ],
          [
           "@UnknownAndYoung  a low growl escaping him. Oh oh.",
           0.396
          ],
          [
           "@AaronGoodwin seriously dude buy some bubble tape for your phones. #snap broke another phone",
           0.458
          ],
          [
           "@MetsProspectHub @brianpmangan taking offense to acount...he ranks 32 of 36 over last 2 years by SABR",
           0.312
          ],
          [
           "follow my girl tiff she only got 3 followers @00tiffanyr",
           0.188
          ],
          [
           "@sippycoups if it hurts too much to eat, i read somewhere that marshmallows are good bc they are soft and don't irritate",
           0.375
          ],
          [
           "Didn't think Cadres not Getting SRC deployment would make some Cadres so bitter, Ku tough Macom.",
           0.5
          ],
          [
           "Guy across from me in a really ugly suit cannot stop expressing his displeasure",
           0.5
          ],
          [
           "guys irritate me",
           0.542
          ],
          [
           "Follow up. Follow through. Be . #success",
           0.125
          ],
          [
           "Like hello? I am your first born you must always laugh at my jokes. ",
           0.324
          ],
          [
           "We worship at Your feet\\nWhere wrath and mercy meet\\nAnd a guilty world is washed\\nBy love's pure stream\\nGraham Kendrick",
           0.375
          ],
          [
           "Michelle is one of the worst players in bb history #bb18 #bbfinale #bitter",
           0.604
          ],
          [
           "GAMEDAY VS BUFORD TODAY AT 5:30 AT HOME!!!!!!!!! NEVER BEEN SO EXCITED #revenge",
           0.354
          ],
          [
           "I need all your attention! If I don't I'll pout..",
           0.479
          ],
          [
           "@ChronAVT ummm, the blog says 'with Simon Stehr faking 7th'...I'll expect an investigation forthwith. This is an #outrage",
           0.688
          ],
          [
           "luv seeing a man with a scowl on his face walking with a protein shaker clenching his fists. i immediately stop n suck his dick",
           0.562
          ],
          [
           "@Sargon_of_Akkad It'll be like burning rap albums; they'll have to buy it first, but gosh darn it, they have to get rid of it.",
           0.417
          ],
          [
           "@Disneyland #nothappy and still #charging the #fullprice  #fuming some your #bestrides ",
           0.646
          ],
          [
           "Praying for the #Lord to keep #anger #hate #jealousy away from your heart is a sign of #maturity #conciseness",
           0.354
          ],
          [
           "Michelle is one of the worst players in bb history #bb18 #bbfinale ",
           0.542
          ],
          [
           "@marthalyssa yep. LOL #bitter",
           0.417
          ],
          [
           "@paulbushnell25 @EE bad news if ordered online it hasn't gone through same happened to me had to re order on the phone ",
           0.458
          ],
          [
           "I blame the whole season on Natalie! The season would have been so different had she not turned her back on her alliance! #pissed ",
           0.792
          ],
          [
           "Ok scrubbed hands 5 times before trying to put them in.\\nEyeballs #burning \\n#EvenMoreBlind accidentally scared the #cat whilst #screeching",
           0.604
          ],
          [
           "Ananya just grabbed a bible, opened it, started reading, and then said 'where do they talk about burning people?'",
           0.417
          ],
          [
           "If I spend even 5 minutes with you and you already irritate me I seriously will bitch you out until you shut up",
           0.812
          ],
          [
           "(Sam) Brown's Law: Never offend people with style when you can fake that, you have to break us in this Island.",
           0.333
          ],
          [
           "@DJ_JeanFranko growl!!!",
           0.5
          ],
          [
           "i live and die for mchanzo honeymoon crashing and burning the second they move in together",
           0.479
          ],
          [
           "@ZubairSabirPTI  pls dont insult the word 'Molna'",
           0.479
          ],
          [
           "Just joined #pottermore and was sorted into HUFFLEPUFF  #fuming",
           0.708
          ],
          [
           "@__NETFLIXNCHILL I fuck with madden way harder",
           0.521
          ],
          [
           "Sting is just too damn earnest for early morning listening. ",
           0.37
          ]
         ],
         "hovertemplate": "emotion=anger<br>UMAP1=%{x}<br>UMAP2=%{y}<br>text=%{customdata[0]}<br>intensity=%{customdata[1]}<extra></extra>",
         "legendgroup": "anger",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "anger",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": {
          "bdata": "gIizP57bmb8ThAlAVx6QP+P68z+hRK49Y889vnxh/T4Cmt0/jbajP7cvJkDZWJG/++K3P4QYRT+krlC+7L0YQFnxjb/z3Oo/S7lzQHs1lD+4RxRAKjyGP0x/aj8DElRAJjXOP4QN2T9baxu/SH9VQNlV2z+95v8/KaSJP1jhaj+SdoC/GvLVP22zE7/QIYk/+TKXv/fn6753oQdAqu9wP1nzCz/UWJY/PR40QF+NDT8gaGw/zQ1Sv6e8Ez8JnpU+",
          "dtype": "f4"
         },
         "xaxis": "x",
         "y": {
          "bdata": "9IOjQCYr3kC3vOhAf7iEQK9ro0CYSbRAKcW9QGaYk0C32IpA1GOJQPOFnUAc2d9AV3WqQNQ5sECs/rZAEPa2QFq800CZvohADAWyQOXFBUFlI5dAN7W7QFYcuUB5G9JANGrHQAXmrkAP37ZAnG2+QI4Px0CAAZFAjji+QEm5o0B86dlAu1urQBXvs0AtFc1Awi/eQFrNvECoWAJBDA2sQJ2FskDL/q5AvzuvQFRUwUDh3FJAUivRQEJTv0AzeK1A",
          "dtype": "f4"
         },
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "@Greener105th so you are astounded that I respect blacks to vote like any other human? u talk so down towards them. What bigotry on display!",
           0.521
          ],
          [
           "Missing the 500th test match today , not able to witness it like watching it in India #shy #indvsnz #500thTest @BCCI",
           0.479
          ],
          [
           "@BigDaddyx47 awe I'm sorry! I have 2 dogs 3 cats &amp; a snake",
           0.188
          ],
          [
           "@ImJim_YoureNot  cyber bully",
           0.396
          ],
          [
           "Don't #worry if you're not the best , if you are doing something you #love , you're heading in right direction ...",
           0.104
          ],
          [
           "3 #tmobile #stores, #original #note7 #customer and zero #results... What's going on guys?  #customerservice #2hour #waittime",
           0.5
          ],
          [
           "Today's alarm shows how unprepared professors and students are when it comes to emergency protocols. We don't know where to go @CalStateLA",
           0.667
          ],
          [
           "Watched tna for the first time in a long time what the hell happened to the #hardyboys #impactonpop #wwe #terrible",
           0.412
          ],
          [
           "bad news fam, life is still hard and awful #depression #anxiety #atleastIhaveBuffy",
           0.854
          ],
          [
           "#Partners are willing to #walk alongside you without being #intimidated by you. #WhoIsIT #Part2 #RelationShift #CLifeMacon",
           0.417
          ],
          [
           "@RJAH_NHS @ChrisHudson76 @mbrandreth #course day # potential Leadership #excited #nervous # proud",
           0.646
          ],
          [
           "Damnnit! Gonna be 1400 pts shy on Chiefs Rewards of getting a post game photo.",
           0.521
          ],
          [
           "Fewer and fewer good horror offerings from Hollywood every year. Or have I just gotten too old for this shit?",
           0.292
          ],
          [
           "@smb_ryan @Kamper10 I couldn't care less about #GOTHAM. I haven't watched it since the mid point of season 1. #horrible",
           0.417
          ],
          [
           "#nana 4 hoco bc my dream since freshman year awe  @thecandeyman",
           0.25
          ],
          [
           "@NHLexpertpicks @usahockey USA was embarrassing to watch. When was the last time you guys won a game..? #horrible #joke",
           0.269
          ],
          [
           "@bumbleb33tuna door and cleared his throat, trying to dispel any nervousness he had left.",
           0.479
          ],
          [
           "How had Matty Dawson not scored there!!!!! #terrible",
           0.375
          ],
          [
           "@Taniel @LOLGOP That'll be gosh darn terrific if they only check the brown people. Shucks, let's make a law to say only brown people.",
           0.458
          ],
          [
           "# ISIS REFERENCES SCRUBBED?  Federal complaint against suspect in NYC, NJ bombings appears to omit terror names in bloody journ...  #news",
           0.729
          ],
          [
           "This maybe a new start but it will always be align with the end.  #forward",
           0.375
          ],
          [
           "#NawazSharif confesses that #Pakistan  supports #terror at #unga\\n#BurhanWani",
           0.625
          ],
          [
           "@Megannn_walsh12 @itsshelleeey never said that,Just not fair how Yous think it's completely okay to bully someone",
           0.646
          ],
          [
           "someone come to fright world w me",
           0.458
          ],
          [
           "And I would advise that everyone wait to watch @KevinCanWaitCBS ,or actually don't wait, just don't even watch it because it is #awful",
           0.229
          ],
          [
           "Thank god the feds did not raise rates. Assume they are nervous about a world where 990 is the new employee  form  &amp; the safety net is zilch",
           0.45
          ],
          [
           "And there you go. After that wild start, wouldn't be surprised at all if Sweden wins this game. Too much experience there to panic.",
           0.4
          ],
          [
           "@JasonBHampton it's Bowers. I went and drove it for a while this evening #horrible",
           0.447
          ],
          [
           "#panic Panic attack from fear of starting new medication",
           0.917
          ],
          [
           "@tchop__StL @YouTube \\nI get sick to my stomach everytime I see this video &amp; for the helicopter crew to make such comments is revolting.",
           0.875
          ],
          [
           "It's a good day at work when you get to shake Jim Lehrer's hand. Thanks, @keratx! Still kicking myself for being to shy to hug @mcuban.",
           0.208
          ],
          [
           "petrify  me in the fossil type of way",
           0.458
          ],
          [
           "India wants to #shake #hands with # pakistan ..... but as usual pakistan #cheat with every #indian \\n\\n..........shameless pakistan",
           0.458
          ],
          [
           "Tomorrow is going to be a challenge, I have to talk at a freshers fair to STRANGERS and pick up my new flat keys ",
           0.58
          ],
          [
           "@realDonaldTrump @KellyannePolls New campaign slogan idea...'I know you are but what am I?'  #Trump2016 #yourefired #deflect",
           0.354
          ],
          [
           "@Markgatiss I'm surrounded by those Trump voters. You're right, it is fucking terrifying. #redstate ",
           0.854
          ],
          [
           "Haven't gotten one hour of sleep... Today is going to be a fun day  #restless",
           0.75
          ],
          [
           "Recording some more #FNAF and had to FaceTime my mum to let her know I was okay after I let out a high pitched scream   #suchagirl",
           0.458
          ],
          [
           "Just had to reverse half way up the woods to collect the dog n I've never even reverse parked in my life  #nightmare",
           0.771
          ],
          [
           "I just want to say: social media isnt here to #bully that has to be #stopbullying ! Please be kind to eaxh other! #lovewins",
           0.36
          ],
          [
           "@saltmage I find it less daunting if I know one person at least!",
           0.521
          ],
          [
           "@DaniQays @AJENews ohh.. so here comes sense from terror supporting stone pelting vandalizing ppl who gather b4 protests to announce ...",
           0.646
          ],
          [
           "@kevinrouth Now that's what I call a gameface! #gameface  #intimidate",
           0.458
          ],
          [
           "I'm scared that my coworkers are going to submit me to one of those 'wardrobe makeover' shows. #fear #fashion",
           0.792
          ],
          [
           "Can't start a good day without a cup of tea! \\n\\n#tea #start #day #goodday",
           0.104
          ],
          [
           "We in our own country are so divided in our approach so how could we fight #terrorism and #pakistani terrorism #MartyrsNotBeggars",
           0.625
          ],
          [
           "@WTFISaHashtag1 @MuslimIQ The problem is that right wing extremist terror groups aren't given coverage, press not interested",
           0.5
          ],
          [
           "White Americans are worried about Arab terrorists. Black Americans are fearful of a terrorist in a Police uniform on a daily basis.",
           0.854
          ],
          [
           "@deodevine6 i can't bully you and niall impossible",
           0.438
          ],
          [
           "I feel horrible. I have accounting today but physically and mentally am not okay ",
           0.833
          ],
          [
           "@quiettcricket can you maybe break it down into smaller bits? or space it out so it doesnt seem to daunting?",
           0.458
          ],
          [
           "The moment you bring her to meet your best friend and you're nervous af!  #nervous #thefriendtest",
           0.771
          ],
          [
           "@joey_coops yes Hun! Avoid at all costs!! #nightmare",
           0.667
          ],
          [
           "Hillary Clinton looked the other way to the Saudi war on women and their terror financing because they bought her off.",
           0.479
          ],
          [
           "@CNNPolitics I can't wait to hear what he had to say about the brilliant Dr. Hawking... it should be rich... In the poorest of taste! ",
           0.246
          ],
          [
           "Bout ta get my @dontbreathe on up in here! @WarrenTheaters #nervous #icantholdmybreaththatlong",
           0.688
          ],
          [
           "@LethalWeaponFOX This show SUCKS! #lame #awful you even used the same names?? lol SO SO bad! #Failed #notworth2minutes. Off air SOON",
           0.396
          ],
          [
           "also i had an awful nightmare involving being sick where worms were involved i was so disgusted when i woke up",
           0.896
          ],
          [
           "#twitter #users Tweeting on twitter is like playing a game against the computer. Where's the life, Everyone too #afraid to say something?",
           0.521
          ],
          [
           "@RyanAbe awe yay thank god I was so worried.",
           0.5
          ],
          [
           "@soozclifford Sure have... Sydney are too tough, too quick and their 'team' pressure is too much for the Cats to handle. Motlop/Cowan ",
           0.356
          ],
          [
           "@TheDappaMc also 2.50 for a chocolate Feast ice lolly.. proper shocking ",
           0.438
          ],
          [
           "Really.....#Jumanji 2....w/ The Rock, Jack Black, and Kevin Hart...are you kidding me! WTF! #ThisIsATerribleIdea ",
           0.542
          ],
          [
           " @FrameOfAnAngel  \\n\\n+ Of them. I'm here for answers, and if I scare her to death, there won't be answers for me. \\n\\nSo instead, I just +",
           0.583
          ]
         ],
         "hovertemplate": "emotion=fear<br>UMAP1=%{x}<br>UMAP2=%{y}<br>text=%{customdata[0]}<br>intensity=%{customdata[1]}<extra></extra>",
         "legendgroup": "fear",
         "marker": {
          "color": "#EF553B",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "fear",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": {
          "bdata": "HvERP71EvD97eZA/30VQQN05YECdz6C/NufCP1hxc79PBA4/X7QyQMXUQkA7CUG+njakPSgBab8KI2tATXAovz2zIUAnHfu+POBaP/ATKT/r21VAnc47Pzi8S0D4wjBAlEqJvzKktD+wCWE+Q1CrviNoFUBv/uW+I9w7QOW/xT8EAS4/J281QLS9Tz/X2nI++vgIP8/mI0AyBHi+SDthQK98NECD3zI/Cw06QCjAEUBYrVVAJlIGP2JdAT8HS2M+qjlTQIBtZT9q8yBAQ1EqQAiy1L4AwVk/+skhP+Y4FkCFt4O/0EyJvCvTLD+DX1tAgyE2PvhgWL8yKJK/MvUWQA==",
          "dtype": "f4"
         },
         "xaxis": "x",
         "y": {
          "bdata": "HyORQO9W70CpKvNALHKXQBDKuUD0TtpAY2oIQUOYuEC30AJBCHvmQOdv/UAf9sBAhdoAQRA/v0Dsu7hAOFLBQAtc90BWpc9A8KeWQCGAc0CFQtpABDlaQFrykkD+xARBAq2+QOujjECQjc5AolzYQGmoCEF558tA297dQNNr2EDfFlRAWYACQVklmUCALJJAjCgCQfwaBkFwRelA1vyoQGcz/UBhk15AMm+0QAZDCUG0wONAMDpfQNXddUDf0YNA8zWWQP6qBEENXPlAl1YHQblH4UCHbn9Amw2PQDdJCkF1+71A50nyQNQA2kDS3LVA8PDRQCiD3kDEWbpAQC33QA==",
          "dtype": "f4"
         },
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "@iyaycruz lets see chirp",
           0.231
          ],
          [
           "#Talking about our #Problems is our greatest #Addiction#Break the #habitTalk about ur #Joys#quote #optimism #problemsolving #behappy",
           0.34
          ],
          [
           "@bradshawjp Sweet! #optimism",
           0.56
          ],
          [
           "Do not truck the delight; delight the truck.",
           0.34
          ],
          [
           "@PeteSpencer007 Are you always so relentlessly positive? Your constantly cheerful optimistic disposition starts to grate after a while.",
           0.34
          ],
          [
           "The joyful tambourines have ceased. The noise of the jubilant has stopped. The joyful lyre has ceased. -Isaiah 24:8",
           0.208
          ],
          [
           "#ThisIsUs has messed with my mind &amp; now I'm anticipating the next episode with #apprehension &amp; ! #isthereahelplineforthis",
           0.4
          ],
          [
           "Look forward to the detours because they bring delightful surprises. #lifequote #delight",
           0.56
          ],
          [
           "@debutemma I dont have to sit here and take this from u spry young children",
           0.146
          ],
          [
           "I saw those dreams dashed &amp;&amp; divided like a million stars in the night sky that I wished on over &amp;&amp; over again ~ sparkling &amp;&amp; broken.",
           0.25
          ],
          [
           "Logically speaking, this can't be the worst I've ever felt and even if it was then its passing will still be a joyous occasion",
           0.167
          ],
          [
           "@RealKyper @NHL watching the jubilant scrum at the end of the day and remembering they're all still kids! #priceless",
           0.625
          ],
          [
           "@FullTimeDEVILS Memphis looking bright. Rojo looking like Rojo.",
           0.473
          ],
          [
           "Evening all. Don't forget it's #RobinHoodHour TONIGHT \\n\\n #bizitalk #bizhour #southyorkshire #MansfieldHour  #sheffieldHour #NottsHour",
           0.438
          ],
          [
           "@lennyabrahamson May I send you a copy of #HeroTheGreyhound? Either e-book or real paper one! A boy and a greyhound #smiles #tears ",
           0.304
          ],
          [
           "Your glee filled Normy dry humping of the most recent high profile celebrity break up is pathetic &amp; all that is wrong with the world today.",
           0.1
          ],
          [
           "theLordturn his face toward you and give you peace. Numbers 6:26 #truth #trust #promise #calm #justice #great #mighty #protected #delight",
           0.542
          ],
          [
           "I'm so playful. lol I need somebody that'll joke with me all day long cause ill never get tired of it.",
           0.6
          ],
          [
           "Loved @Bethenny independence msg on @WendyWilliams, be happy &amp; fulfilled within yourself &amp; positivity will flock to you #happy #independent",
           0.646
          ],
          [
           "I love how cheery and adoring @JackHoward gets every time he produces new content.",
           0.833
          ],
          [
           "every time a new Anthony Weiner revelation breaks, Bill Clinton says a prayer of thanks that texting/DMing didn't exist in his heyday.",
           0.375
          ],
          [
           "A cheerful heart is good medicine, but a crushed spirit dries up the bones -Proverbs 17:22-",
           0.4
          ],
          [
           "@govph I would like to know about the source of The President's optimism about running the country. I wonder if he can answer my curiosity.",
           0.18
          ],
          [
           "Had a coworker look at her phone and say, cheerfully, 'oh look, Kap's getting death threats now.' . Then she goes to say the 49ers are",
           0.385
          ],
          [
           "Watch this amazing live.ly broadcast by @paulzimmer  #musically",
           0.521
          ],
          [
           "@Nick_Offerman I'll be there!! Can't wait for all the !",
           0.771
          ],
          [
           "@MoAmali @awosss @Arsenalman2011 listen I dn't subscribe to this team coq Team xhaka stuff. I like all our players. Depth has me elated",
           0.562
          ],
          [
           "The object of literature is to make man a wiser and happier being. The poet makes us happy because he tells us how we may become so.",
           0.58
          ],
          [
           "But i'll be a pity.  ",
           0.083
          ],
          [
           "Watch this amazing live.ly broadcast by @brooke_bridges  #musically",
           0.655
          ],
          [
           "Watch this amazing live.ly broadcast by @swagrman_fan  #musically",
           0.521
          ],
          [
           ".@Harry_Styles I hope you never go a day without something to make you smile. You deserve all good things. Please follow me?\\n\\n311,553",
           0.6
          ],
          [
           "@LoisJoanneLane Wagging his tail at the praise, he paused, tilting his head as she took the frisbee from him, letting out a playful -",
           0.562
          ],
          [
           "@aradsliff don't know I'm from nj we are the worst on purpose. #laughter",
           0.462
          ],
          [
           "@jessbr0ughton don't be shy next time! We're a cheery bunch. :) \\n\\nSam. X",
           0.48
          ],
          [
           "@Nikhilv95 @LydiajaneF I wish, I really, truly wish, that I had just a modicum of your banter. ",
           0.24
          ],
          [
           "@tomlinmayniac starting my new challenge ! A glee poll every day !",
           0.625
          ],
          [
           "Metal keeps you young and spry and keeps your hair luxurious.\\n\\nYES\\n\\nSHUT UP AND LISTEN TO ME",
           0.46
          ],
          [
           "This tweet is dedicated to my back pain, which I do not understand because I am youthful and spry. Full of life. Vivacious.",
           0.229
          ],
          [
           "Nawaz Sharif is getting more funnier than @kapilsharmak9 day by day.  #challenge #kashmir #baloch",
           0.58
          ],
          [
           "I love my family so much #lucky #grateful #smartassfamily #hilarious #love",
           0.792
          ],
          [
           "Ready for that nice, breezy, calm, sunshine weather. #Autumn",
           0.583
          ],
          [
           "@billie21806 @cnnbrk tell that to your bodies cheering on the deaths of black people by cops. their fear is killing us.",
           0.1
          ],
          [
           "@yungdoujin wouldn't that basically be sparkling water",
           0.32
          ],
          [
           "A hearty Jonza! to all my friends and follower.",
           0.704
          ]
         ],
         "hovertemplate": "emotion=joy<br>UMAP1=%{x}<br>UMAP2=%{y}<br>text=%{customdata[0]}<br>intensity=%{customdata[1]}<extra></extra>",
         "legendgroup": "joy",
         "marker": {
          "color": "#00cc96",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "joy",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": {
          "bdata": "yU0uQO3wG0BCFktAk8YJQFaJHkCLTd0/nlgCQAbCI0ACdTFATxiaPweEpj9O4jNAG5g/QF3AXkAosTxAW7kIPaJ64D8CfNQ/iR9XQIA3N0CLfIQ/AffxPyjBGEAuwfk9BX+AQNNzZUB0SUZAbaQKQIzFhz8CRoNA8M+BQNvNXUDhlyRAXCiIP8RMO0Aq/eY/mSNhQLMu1z801Nw/G7tJP0ab/j8+jU9AZqv4PadJHEC+90xA",
          "dtype": "f4"
         },
         "xaxis": "x",
         "y": {
          "bdata": "SlGyQOPn00ANvM1AwqnXQBqqx0A8/e9AtiILQfJE1UASbJZA3G/vQGjBAEEbUMpAS96mQFPh30BrgMVA+y2qQC2gsUAoi8dAWBHMQHbLy0CY5IRAUWzvQAVkykAtUJdALwzJQOq+0kCif6RAGh3dQAd47UDjEclA5VbGQEa5yUDorsFA3ArMQJRM3EAXdeJARxzuQL0i0kCYQuFAmURTQAfuz0CGHNdA4s2NQOpMtEAyvcFA",
          "dtype": "f4"
         },
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "@m_giacchino will this be aired on radio or filmed? Lots of fans over the pond too! #wales #lost",
           0.354
          ],
          [
           "Hopefully next time we play a L1 team, 1 of the players scores, takes his shirt off &amp;jumps into away end purely to wind up the joyless cunts",
           0.396
          ],
          [
           "What do you do?'\\n'You are not worthy enough to know.' #what #serious",
           0.458
          ],
          [
           "Very long day. Thank goodness for Bake Off to brighten up a weary Wednesday  #GBBO",
           0.188
          ],
          [
           "@beIIrkes Es, I'm serious 23/8",
           0.271
          ],
          [
           "Marcos rojo plays for man united !!  Just let that sink in !!!",
           0.417
          ],
          [
           "Brad Pitt being investigated for child abuse?! this all just got really #dark",
           0.479
          ],
          [
           "@pxrfectpeach it's got her little pout",
           0.271
          ],
          [
           "@crimsonwulfe it's super sad!! Especially when you are talking to a real person and not a bot! Makes it feel real :(",
           0.75
          ],
          [
           "Well i did hear once before that girls are attracted to men that look like their dad!   ",
           0.25
          ],
          [
           "@cotsonika @NHL well, they should all be unhappy for the way they played.  Right @fmjacob ??",
           0.542
          ],
          [
           "@iTriborg  make him feel vigorous. 'Fine. You can kill me now.' Said Hestia with a display of only despair rather than her joyful ",
           0.5
          ],
          [
           "I have serious problems with the expectation that private philanthropy should replace functional government services...this is dangerous",
           0.396
          ],
          [
           "Some of these people at this protest are just there for the adrenaline rush. #depressing",
           0.583
          ],
          [
           "Let the #MrRobot binge begin. #nerdshow #compelling #dark",
           0.229
          ],
          [
           "Mixed emotions. #sadness #anxietymaybe #missingfriends #growingupsucks #lostfriends #wheresthetruefriends #complications",
           0.667
          ],
          [
           "We want to help you with your #depression. Give our office a call to learn how #TMS may be the treatment you've been waiting for!",
           0.521
          ],
          [
           "@m_giacchino will this be aired on radio or filmed? Lots of fans over the pond too! #wales ",
           0.188
          ],
          [
           "@AMB4JC @drtonyevans It's our job, the job of people who r still sane,still ok in life, to help the lost to find themselves &amp; love eachother",
           0.214
          ],
          [
           "Never ever been this unhappy before in my life lmao",
           0.771
          ],
          [
           "Tell me how I'm supposed to feel. #broken #hateful #guilty #love #sadness",
           0.729
          ],
          [
           "@JohnRMoffitt This is the most grim piece of laughter I was stricken with all day.",
           0.604
          ],
          [
           "It's sad when your man leaves work a little bit late and your worst fear is 'Oh no!! Did he get stopped by the police?!?! '  #ourworld",
           0.618
          ],
          [
           "We have left #Maine. #sadness",
           0.771
          ],
          [
           "I don't know why everyone is pretending to be sad about angelina and brad, everyone knows his dumb ass should've stayed with jennifer.",
           0.354
          ],
          [
           "The man who is a pessimist before 48 knows too much; if he is an optimist after it, he knows too little.'\\n-Mark Twain",
           0.417
          ],
          [
           "@pureleine though lately with how bad my depression has been i feel like my body is like just, taking what little it can get",
           0.771
          ],
          [
           "@JoyceCarolOates \\nBreath. You are trending despondent. Mrs Clinton will win. If you keep your gloves on, guard up, and punch like hell.",
           0.417
          ],
          [
           "| At home sick... The blues won't cure it so I need ideas  | #sorethroat #sick #blues #music #fallweather #carletonuniversity #ottawa",
           0.833
          ],
          [
           "@CTV_PowerPlay @lraitt Horrid disease! My maternal grandmother and each of her sisters suffered from this affliction. It's hard on all.",
           0.75
          ],
          [
           "it didn't impress me but it didn't depress me'",
           0.271
          ],
          [
           "It's pretty clear I can't stand @HillaryClinton, no tolerance for habitual liars. Not a Trump fan either so what's a citizen to do? #despair",
           0.646
          ],
          [
           "where broken hearted lovers do cry away their gloom",
           0.708
          ],
          [
           "My friends tell me I'm pretty. Trigger tells my I'm ugly. I first was confused but then realised I'm both. Pretty ugly. #tru  #tumblr",
           0.583
          ],
          [
           "@big_SL8 Show some respect, that's all...  If u havent go to war u cant say anything.. U havent lost friends and mates on war, so Ahut it!!",
           0.583
          ],
          [
           "@kempicepoland don't think he did, and he didn't have the rucksack or laptop in his possession, murky business, on that note I'm away to bed",
           0.5
          ],
          [
           "HATE that there's ads for #depression &amp; #mentalhealth #meds. That's ONLY something your doctor can determine. Everyone is different. #ssri",
           0.46
          ],
          [
           "Common app just randomly logged me out as I was writing the last part of my college essay and lost all of it ",
           0.833
          ],
          [
           "All I want to do is watch some netflix but I am stuck here in class. #depressing",
           0.667
          ],
          [
           "Don't depress yourself by comparing yourself. No comparisons.",
           0.438
          ],
          [
           "This shit hurting my heart  that's how serious it is .",
           0.875
          ],
          [
           "Stars, when you shine,\\nYou know how I feel.\\nScent of the pine, \\nYou know how I feel.\\nFreedom is mine,\\nI know how I feel.\\nI'm feelin' good.",
           0.292
          ],
          [
           "Wow just watched Me Before You and it was seriously one of the most depressing movies of my life",
           0.667
          ]
         ],
         "hovertemplate": "emotion=sadness<br>UMAP1=%{x}<br>UMAP2=%{y}<br>text=%{customdata[0]}<br>intensity=%{customdata[1]}<extra></extra>",
         "legendgroup": "sadness",
         "marker": {
          "color": "#ab63fa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "sadness",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": {
          "bdata": "T0WBQJ+xcT4exAZAzJ9OQB2cGkDaXT9ADC2Fvuy4CEASJik/7aKuP0Bvtz0rNtc/lMbVP4d/OD/YOfQ/WURKPzm4VT+OyX9AyVFjQFLoBD/XVGQ/MkCkPx1A3j5uaCE/8Pcuve+rCUBzhJM/D2OCP3aOVT+IVtc+vinPP67wFj+1KHg/HHS3P26tJEDo2QRAp0EjP9SZij7+TlU/byqVP7P11T5wXyBAPE4WPw==",
          "dtype": "f4"
         },
         "xaxis": "x",
         "y": {
          "bdata": "GYLaQM9KukDQj6NA41brQIVkp0BpgJ9AQe6kQJk5vECQ6/FAoIO/QFcazEAaXeVA9bWZQJsA2UCLeAlBaFkAQfb3CEEBbthAJii3QPT/9kC74PxA+7vTQHUf5UCDLPVAuhypQG872ED5LAFBHPGbQBBuBUFzStxA7Sn4QDTtn0DrG/JArkv6QF1TlUB70KdAmegIQXBE9UCcNgNBae8CQScC7EDFQOJAydoAQQ==",
          "dtype": "f4"
         },
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "emotion"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "2D UMAP Projection of Text Embeddings"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "UMAP1"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "UMAP2"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import umap\n",
    "import plotly.express as px\n",
    "\n",
    "# Concatenate the training and test data\n",
    "combined_df = pd.concat([train_df_new, test_df_new], ignore_index=True)\n",
    "\n",
    "# Prepare the embeddings for UMAP\n",
    "# Convert the list of embeddings into a 2D numpy array\n",
    "X_embeddings = np.array(combined_df['embeddings_values'].tolist())\n",
    "\n",
    "# Apply UMAP for dimensionality reduction\n",
    "reducer = umap.UMAP(n_components=2, metric='cosine', random_state=28) \n",
    "embedding_2d = reducer.fit_transform(X_embeddings)\n",
    "\n",
    "# Create a DataFrame for plotting\n",
    "df_plot = pd.DataFrame(embedding_2d, columns=['UMAP1', 'UMAP2'])\n",
    "df_plot['emotion'] = combined_df['emotion']\n",
    "df_plot['intensity'] = combined_df['intensity']\n",
    "df_plot['text'] = combined_df['text']\n",
    "\n",
    "\n",
    "# Visualize the embeddings with Plotly\n",
    "fig = px.scatter(\n",
    "    df_plot,\n",
    "    x='UMAP1',\n",
    "    y='UMAP2',\n",
    "    color='emotion',  # Color points by the 'emotion' column\n",
    "    hover_data=['text', 'intensity'],  # Show text and intensity on hover\n",
    "    title='2D UMAP Projection of Text Embeddings'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that even with Gemini's embeddings there doesn't seem to be a clear 2D separation of clusters with our data classes. It could be because emotions are often not discrete. Texts can contain mixed feelings (e.g., \"bittersweet\") or use similar language to express different emotions, causing their embeddings to be naturally close in semantic space. And also the process of projecting high-dimensional embeddings down to a 2D visualization inevitably loses some information, which can make distinct clusters appear to overlap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### <a id='toc1_5_8_1_1_'></a>[**>>> Exercise 4 (Take home):**](#toc0_)\n",
    "\n",
    "Apply UMAP to the same embeddings to reduce the dimensionality to 3D vectors and plot the 3D graph, discuss the differences and similarities with the 2D graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\DM_Lab_GPU\\Lib\\site-packages\\umap\\umap_.py:1952: UserWarning:\n",
      "\n",
      "n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "customdata": [
          [
           "@trendykittykat Some people would rather hang on to their indignant anger. *weary sigh*",
           0.479
          ],
          [
           "@AskPS_UK not received verification email, asked for it to be resent 5 times still nothing.",
           0.604
          ],
          [
           "Nurse practitioner: 'you look pretty bad. No offense of course.'  \\n\\nThank you, that really added that spark of positivity I needed today.",
           0.444
          ],
          [
           "@DRUDGE_REPORT @FoxNews good thing the FBI didn't offend them!",
           0.479
          ],
          [
           "@RichardHBell Yes, I think he held a grudge ...",
           0.375
          ],
          [
           "Candace &amp; her pout are getting right on my tits #GBBO",
           0.562
          ],
          [
           "That's really it for my madden career that game sucks , ea sports does a piss poor job every year on that shit",
           0.867
          ],
          [
           "@Trump_Videos she looks completely #rabid @realDonaldTrump",
           0.5
          ],
          [
           "@edquinn63 how can you even forget to pick ur fave child up from school #offended",
           0.688
          ],
          [
           "ESPN just assumed I wanted their free magazines #offended",
           0.542
          ],
          [
           "@warFarePower dip it in boiling water",
           0.396
          ],
          [
           "@paulbushnell25 @EE bad news if ordered online it hasn't gone through same happened to me had to re order on the phone #furious",
           0.844
          ],
          [
           "#Anger or #wrath is an intense emotional response.",
           0.562
          ],
          [
           "The new gun emoji in iOS10 is not enough to show the anger I have towards a number of things.",
           0.625
          ],
          [
           "Thatmoment you're watching #worstcelebritycooks and your bubble is burst by finding out KyleXY is gay and married #nochance #KindaDontMind",
           0.479
          ],
          [
           "@UnknownAndYoung  a low growl escaping him. Oh oh.",
           0.396
          ],
          [
           "@AaronGoodwin seriously dude buy some bubble tape for your phones. #snap broke another phone",
           0.458
          ],
          [
           "@MetsProspectHub @brianpmangan taking offense to acount...he ranks 32 of 36 over last 2 years by SABR",
           0.312
          ],
          [
           "follow my girl tiff she only got 3 followers @00tiffanyr",
           0.188
          ],
          [
           "@sippycoups if it hurts too much to eat, i read somewhere that marshmallows are good bc they are soft and don't irritate",
           0.375
          ],
          [
           "Didn't think Cadres not Getting SRC deployment would make some Cadres so bitter, Ku tough Macom.",
           0.5
          ],
          [
           "Guy across from me in a really ugly suit cannot stop expressing his displeasure",
           0.5
          ],
          [
           "guys irritate me",
           0.542
          ],
          [
           "Follow up. Follow through. Be . #success",
           0.125
          ],
          [
           "Like hello? I am your first born you must always laugh at my jokes. ",
           0.324
          ],
          [
           "We worship at Your feet\\nWhere wrath and mercy meet\\nAnd a guilty world is washed\\nBy love's pure stream\\nGraham Kendrick",
           0.375
          ],
          [
           "Michelle is one of the worst players in bb history #bb18 #bbfinale #bitter",
           0.604
          ],
          [
           "GAMEDAY VS BUFORD TODAY AT 5:30 AT HOME!!!!!!!!! NEVER BEEN SO EXCITED #revenge",
           0.354
          ],
          [
           "I need all your attention! If I don't I'll pout..",
           0.479
          ],
          [
           "@ChronAVT ummm, the blog says 'with Simon Stehr faking 7th'...I'll expect an investigation forthwith. This is an #outrage",
           0.688
          ],
          [
           "luv seeing a man with a scowl on his face walking with a protein shaker clenching his fists. i immediately stop n suck his dick",
           0.562
          ],
          [
           "@Sargon_of_Akkad It'll be like burning rap albums; they'll have to buy it first, but gosh darn it, they have to get rid of it.",
           0.417
          ],
          [
           "@Disneyland #nothappy and still #charging the #fullprice  #fuming some your #bestrides ",
           0.646
          ],
          [
           "Praying for the #Lord to keep #anger #hate #jealousy away from your heart is a sign of #maturity #conciseness",
           0.354
          ],
          [
           "Michelle is one of the worst players in bb history #bb18 #bbfinale ",
           0.542
          ],
          [
           "@marthalyssa yep. LOL #bitter",
           0.417
          ],
          [
           "@paulbushnell25 @EE bad news if ordered online it hasn't gone through same happened to me had to re order on the phone ",
           0.458
          ],
          [
           "I blame the whole season on Natalie! The season would have been so different had she not turned her back on her alliance! #pissed ",
           0.792
          ],
          [
           "Ok scrubbed hands 5 times before trying to put them in.\\nEyeballs #burning \\n#EvenMoreBlind accidentally scared the #cat whilst #screeching",
           0.604
          ],
          [
           "Ananya just grabbed a bible, opened it, started reading, and then said 'where do they talk about burning people?'",
           0.417
          ],
          [
           "If I spend even 5 minutes with you and you already irritate me I seriously will bitch you out until you shut up",
           0.812
          ],
          [
           "(Sam) Brown's Law: Never offend people with style when you can fake that, you have to break us in this Island.",
           0.333
          ],
          [
           "@DJ_JeanFranko growl!!!",
           0.5
          ],
          [
           "i live and die for mchanzo honeymoon crashing and burning the second they move in together",
           0.479
          ],
          [
           "@ZubairSabirPTI  pls dont insult the word 'Molna'",
           0.479
          ],
          [
           "Just joined #pottermore and was sorted into HUFFLEPUFF  #fuming",
           0.708
          ],
          [
           "@__NETFLIXNCHILL I fuck with madden way harder",
           0.521
          ],
          [
           "Sting is just too damn earnest for early morning listening. ",
           0.37
          ]
         ],
         "hovertemplate": "emotion=anger<br>UMAP1=%{x}<br>UMAP2=%{y}<br>UMAP3=%{z}<br>text=%{customdata[0]}<br>intensity=%{customdata[1]}<extra></extra>",
         "legendgroup": "anger",
         "marker": {
          "color": "#636efa",
          "opacity": 0.7,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "anger",
         "scene": "scene",
         "showlegend": true,
         "type": "scatter3d",
         "x": {
          "bdata": "vuR+P43FsL7gm5e/SC6BP93ndj9AT5o/mxtvP94NMz9FLrA/ooSsP4SW9j55WlW+EtJYP5VKiz+JDVI/moL6PY0gNj71tLY/7NvwvT7nv793moE/QF55PweWQD/NiCC/LKQEvtlLKD5qIJg/2yrTvnmcB76yFKU/Sn8xP2ghNT+93Rk+ZhAqP8S0oT+hS1M+oTqNvuyWlz92TH6/ogIKP+k4iT8hrRc+Nqs5PWjBmz7vde8//KrHPlw2Mj8fvXU/",
          "dtype": "f4"
         },
         "y": {
          "bdata": "Oq7+P388qb4DthNAvpQzQOQ+xT+tzFs/dEY2P0G3JUCDD8w/zl75P2SI7z/aSay+Z+f7P2r5wD+tWBs/lWLSP7GBGL5kNc0/NnsuQItktj/FtwBAm7CsP+0Hoz+HTDxAQXSnP7sOKEBJyro+E7YLQBYdvD91DtY/EiWRP0OzCUAb+12+2MMbQBQE3j5HU4c/+jyLvtGp9D5fZuc+EJX+P+QKmD8z9RBA7B/bP+2Uoj93YENA5miJPrtigj+Rsa0/",
          "dtype": "f4"
         },
         "z": {
          "bdata": "74sTQEM0K0DqjxZAk8Q0QDbf9T8UIipA0HM+QJixUkCIuQBAj2IpQAdYvD/Ssi9AnhEMQEVnK0Ca+ztA7pKjP+nCI0B4IO4/8Cw+P0VOVEBSdds/yggZQG7FHUASLo0/qhABQBNy/z/tjjFAS+g1P0UD7j/x9tw/H20WQIizQkD5dDtAO1z8P2YYL0ANACBAjpMyQLAOMkBnfB9AyaY/QJOWL0CcdTZAs/dsP0wqVUD3ykNAbjtVQM7BK0DVnlVA",
          "dtype": "f4"
         }
        },
        {
         "customdata": [
          [
           "@Greener105th so you are astounded that I respect blacks to vote like any other human? u talk so down towards them. What bigotry on display!",
           0.521
          ],
          [
           "Missing the 500th test match today , not able to witness it like watching it in India #shy #indvsnz #500thTest @BCCI",
           0.479
          ],
          [
           "@BigDaddyx47 awe I'm sorry! I have 2 dogs 3 cats &amp; a snake",
           0.188
          ],
          [
           "@ImJim_YoureNot  cyber bully",
           0.396
          ],
          [
           "Don't #worry if you're not the best , if you are doing something you #love , you're heading in right direction ...",
           0.104
          ],
          [
           "3 #tmobile #stores, #original #note7 #customer and zero #results... What's going on guys?  #customerservice #2hour #waittime",
           0.5
          ],
          [
           "Today's alarm shows how unprepared professors and students are when it comes to emergency protocols. We don't know where to go @CalStateLA",
           0.667
          ],
          [
           "Watched tna for the first time in a long time what the hell happened to the #hardyboys #impactonpop #wwe #terrible",
           0.412
          ],
          [
           "bad news fam, life is still hard and awful #depression #anxiety #atleastIhaveBuffy",
           0.854
          ],
          [
           "#Partners are willing to #walk alongside you without being #intimidated by you. #WhoIsIT #Part2 #RelationShift #CLifeMacon",
           0.417
          ],
          [
           "@RJAH_NHS @ChrisHudson76 @mbrandreth #course day # potential Leadership #excited #nervous # proud",
           0.646
          ],
          [
           "Damnnit! Gonna be 1400 pts shy on Chiefs Rewards of getting a post game photo.",
           0.521
          ],
          [
           "Fewer and fewer good horror offerings from Hollywood every year. Or have I just gotten too old for this shit?",
           0.292
          ],
          [
           "@smb_ryan @Kamper10 I couldn't care less about #GOTHAM. I haven't watched it since the mid point of season 1. #horrible",
           0.417
          ],
          [
           "#nana 4 hoco bc my dream since freshman year awe  @thecandeyman",
           0.25
          ],
          [
           "@NHLexpertpicks @usahockey USA was embarrassing to watch. When was the last time you guys won a game..? #horrible #joke",
           0.269
          ],
          [
           "@bumbleb33tuna door and cleared his throat, trying to dispel any nervousness he had left.",
           0.479
          ],
          [
           "How had Matty Dawson not scored there!!!!! #terrible",
           0.375
          ],
          [
           "@Taniel @LOLGOP That'll be gosh darn terrific if they only check the brown people. Shucks, let's make a law to say only brown people.",
           0.458
          ],
          [
           "# ISIS REFERENCES SCRUBBED?  Federal complaint against suspect in NYC, NJ bombings appears to omit terror names in bloody journ...  #news",
           0.729
          ],
          [
           "This maybe a new start but it will always be align with the end.  #forward",
           0.375
          ],
          [
           "#NawazSharif confesses that #Pakistan  supports #terror at #unga\\n#BurhanWani",
           0.625
          ],
          [
           "@Megannn_walsh12 @itsshelleeey never said that,Just not fair how Yous think it's completely okay to bully someone",
           0.646
          ],
          [
           "someone come to fright world w me",
           0.458
          ],
          [
           "And I would advise that everyone wait to watch @KevinCanWaitCBS ,or actually don't wait, just don't even watch it because it is #awful",
           0.229
          ],
          [
           "Thank god the feds did not raise rates. Assume they are nervous about a world where 990 is the new employee  form  &amp; the safety net is zilch",
           0.45
          ],
          [
           "And there you go. After that wild start, wouldn't be surprised at all if Sweden wins this game. Too much experience there to panic.",
           0.4
          ],
          [
           "@JasonBHampton it's Bowers. I went and drove it for a while this evening #horrible",
           0.447
          ],
          [
           "#panic Panic attack from fear of starting new medication",
           0.917
          ],
          [
           "@tchop__StL @YouTube \\nI get sick to my stomach everytime I see this video &amp; for the helicopter crew to make such comments is revolting.",
           0.875
          ],
          [
           "It's a good day at work when you get to shake Jim Lehrer's hand. Thanks, @keratx! Still kicking myself for being to shy to hug @mcuban.",
           0.208
          ],
          [
           "petrify  me in the fossil type of way",
           0.458
          ],
          [
           "India wants to #shake #hands with # pakistan ..... but as usual pakistan #cheat with every #indian \\n\\n..........shameless pakistan",
           0.458
          ],
          [
           "Tomorrow is going to be a challenge, I have to talk at a freshers fair to STRANGERS and pick up my new flat keys ",
           0.58
          ],
          [
           "@realDonaldTrump @KellyannePolls New campaign slogan idea...'I know you are but what am I?'  #Trump2016 #yourefired #deflect",
           0.354
          ],
          [
           "@Markgatiss I'm surrounded by those Trump voters. You're right, it is fucking terrifying. #redstate ",
           0.854
          ],
          [
           "Haven't gotten one hour of sleep... Today is going to be a fun day  #restless",
           0.75
          ],
          [
           "Recording some more #FNAF and had to FaceTime my mum to let her know I was okay after I let out a high pitched scream   #suchagirl",
           0.458
          ],
          [
           "Just had to reverse half way up the woods to collect the dog n I've never even reverse parked in my life  #nightmare",
           0.771
          ],
          [
           "I just want to say: social media isnt here to #bully that has to be #stopbullying ! Please be kind to eaxh other! #lovewins",
           0.36
          ],
          [
           "@saltmage I find it less daunting if I know one person at least!",
           0.521
          ],
          [
           "@DaniQays @AJENews ohh.. so here comes sense from terror supporting stone pelting vandalizing ppl who gather b4 protests to announce ...",
           0.646
          ],
          [
           "@kevinrouth Now that's what I call a gameface! #gameface  #intimidate",
           0.458
          ],
          [
           "I'm scared that my coworkers are going to submit me to one of those 'wardrobe makeover' shows. #fear #fashion",
           0.792
          ],
          [
           "Can't start a good day without a cup of tea! \\n\\n#tea #start #day #goodday",
           0.104
          ],
          [
           "We in our own country are so divided in our approach so how could we fight #terrorism and #pakistani terrorism #MartyrsNotBeggars",
           0.625
          ],
          [
           "@WTFISaHashtag1 @MuslimIQ The problem is that right wing extremist terror groups aren't given coverage, press not interested",
           0.5
          ],
          [
           "White Americans are worried about Arab terrorists. Black Americans are fearful of a terrorist in a Police uniform on a daily basis.",
           0.854
          ],
          [
           "@deodevine6 i can't bully you and niall impossible",
           0.438
          ],
          [
           "I feel horrible. I have accounting today but physically and mentally am not okay ",
           0.833
          ],
          [
           "@quiettcricket can you maybe break it down into smaller bits? or space it out so it doesnt seem to daunting?",
           0.458
          ],
          [
           "The moment you bring her to meet your best friend and you're nervous af!  #nervous #thefriendtest",
           0.771
          ],
          [
           "@joey_coops yes Hun! Avoid at all costs!! #nightmare",
           0.667
          ],
          [
           "Hillary Clinton looked the other way to the Saudi war on women and their terror financing because they bought her off.",
           0.479
          ],
          [
           "@CNNPolitics I can't wait to hear what he had to say about the brilliant Dr. Hawking... it should be rich... In the poorest of taste! ",
           0.246
          ],
          [
           "Bout ta get my @dontbreathe on up in here! @WarrenTheaters #nervous #icantholdmybreaththatlong",
           0.688
          ],
          [
           "@LethalWeaponFOX This show SUCKS! #lame #awful you even used the same names?? lol SO SO bad! #Failed #notworth2minutes. Off air SOON",
           0.396
          ],
          [
           "also i had an awful nightmare involving being sick where worms were involved i was so disgusted when i woke up",
           0.896
          ],
          [
           "#twitter #users Tweeting on twitter is like playing a game against the computer. Where's the life, Everyone too #afraid to say something?",
           0.521
          ],
          [
           "@RyanAbe awe yay thank god I was so worried.",
           0.5
          ],
          [
           "@soozclifford Sure have... Sydney are too tough, too quick and their 'team' pressure is too much for the Cats to handle. Motlop/Cowan ",
           0.356
          ],
          [
           "@TheDappaMc also 2.50 for a chocolate Feast ice lolly.. proper shocking ",
           0.438
          ],
          [
           "Really.....#Jumanji 2....w/ The Rock, Jack Black, and Kevin Hart...are you kidding me! WTF! #ThisIsATerribleIdea ",
           0.542
          ],
          [
           " @FrameOfAnAngel  \\n\\n+ Of them. I'm here for answers, and if I scare her to death, there won't be answers for me. \\n\\nSo instead, I just +",
           0.583
          ]
         ],
         "hovertemplate": "emotion=fear<br>UMAP1=%{x}<br>UMAP2=%{y}<br>UMAP3=%{z}<br>text=%{customdata[0]}<br>intensity=%{customdata[1]}<extra></extra>",
         "legendgroup": "fear",
         "marker": {
          "color": "#EF553B",
          "opacity": 0.7,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "fear",
         "scene": "scene",
         "showlegend": true,
         "type": "scatter3d",
         "x": {
          "bdata": "QrueP0raOb/hmXS/GvNRPwJ0wb114VM96n+pvxo0dj/yCme/Kq1fvsfv4L+tz0k/4yP8viQveT/fxM++vQ5tP5TsiL9CkCI/A3QeP7+Voj/n4xu/jLvMP5vyUD9Ktq6/S5lQP9Nt5T5CJjE/iQOGvRt+37/qd4E+Wieiv5QB+L4P4ts/sGLWvxv9Hz9xDgw/6ZN6v3afub/vxka/MiGnPksntb+gltA/xnDkPZ+E0b9JGom/E63PP+JpqD/EkZE/89wdP97Mnr/yTqW/kbLbv9cEgr4nBoo/cseCP93M5L9Rl4A/u0Vnv7/p0jzileS+mZsjP5JL6728NXw/s3Bmvw==",
          "dtype": "f4"
         },
         "y": {
          "bdata": "IuMRQARd7D/eK7I/k5kVQLDSP0B8fte+Xdx9P+4q471MdJw/M/UJQHW5oz9Wkhg/yLtaP04TPD73YBdA79LzPXkIsj/cVkA+i9MUQG3ZMUD8IkZA8mdKQKV1DEAK23E/gguHvMiyO0AUvA8/7C6wPvK9HT84pOo+pOoFQJeE8j/740BAUCaGP0HUNECMHSFA7xprP1DtIj8C3KE+lxAzQP2DpD8GfzlAnUzrP2xeOT/z3TVAogU6QGdoLEAyWB5AwfwdQBQZnj8+260/nD43P/h/Nj7tZUZA2YYaQKl8PD/+QJg9dQYDP9EoEUDUWBRAL7nLPlhEDb4bvDY9oXnHPw==",
          "dtype": "f4"
         },
         "z": {
          "bdata": "DPZBQFmnWkCd5DhA+CeNP7Qusz9V4yxAblVNQBSiOkCVTnBAh1OvP++R2D8VpTBArtxuQPSUO0Bd50Y/lU0jQITrxj+zJR9AqwJEQE0HUUAUIsE/O1hRQH1Snz9BePk/3oxDQA4qJ0AYJeE/f98+QLiXG0DMCUxA1vOlPzjnFkDdRFlAsjDiP/ybTEC1amBAgcpVQFFiCEA9xDlArbiEP24n1j/P+lZABYpoP/c2HEC27cs/SVZdQCmOXEAryWlAX3ZjP79fXkDv/Oc/s8QOQLc/QkC1sEdApzxIQF7oE0CbpUJAPipRQKf3YUDI2qo/3Mz6P7w3PECpEEdA6lrnPw==",
          "dtype": "f4"
         }
        },
        {
         "customdata": [
          [
           "@iyaycruz lets see chirp",
           0.231
          ],
          [
           "#Talking about our #Problems is our greatest #Addiction#Break the #habitTalk about ur #Joys#quote #optimism #problemsolving #behappy",
           0.34
          ],
          [
           "@bradshawjp Sweet! #optimism",
           0.56
          ],
          [
           "Do not truck the delight; delight the truck.",
           0.34
          ],
          [
           "@PeteSpencer007 Are you always so relentlessly positive? Your constantly cheerful optimistic disposition starts to grate after a while.",
           0.34
          ],
          [
           "The joyful tambourines have ceased. The noise of the jubilant has stopped. The joyful lyre has ceased. -Isaiah 24:8",
           0.208
          ],
          [
           "#ThisIsUs has messed with my mind &amp; now I'm anticipating the next episode with #apprehension &amp; ! #isthereahelplineforthis",
           0.4
          ],
          [
           "Look forward to the detours because they bring delightful surprises. #lifequote #delight",
           0.56
          ],
          [
           "@debutemma I dont have to sit here and take this from u spry young children",
           0.146
          ],
          [
           "I saw those dreams dashed &amp;&amp; divided like a million stars in the night sky that I wished on over &amp;&amp; over again ~ sparkling &amp;&amp; broken.",
           0.25
          ],
          [
           "Logically speaking, this can't be the worst I've ever felt and even if it was then its passing will still be a joyous occasion",
           0.167
          ],
          [
           "@RealKyper @NHL watching the jubilant scrum at the end of the day and remembering they're all still kids! #priceless",
           0.625
          ],
          [
           "@FullTimeDEVILS Memphis looking bright. Rojo looking like Rojo.",
           0.473
          ],
          [
           "Evening all. Don't forget it's #RobinHoodHour TONIGHT \\n\\n #bizitalk #bizhour #southyorkshire #MansfieldHour  #sheffieldHour #NottsHour",
           0.438
          ],
          [
           "@lennyabrahamson May I send you a copy of #HeroTheGreyhound? Either e-book or real paper one! A boy and a greyhound #smiles #tears ",
           0.304
          ],
          [
           "Your glee filled Normy dry humping of the most recent high profile celebrity break up is pathetic &amp; all that is wrong with the world today.",
           0.1
          ],
          [
           "theLordturn his face toward you and give you peace. Numbers 6:26 #truth #trust #promise #calm #justice #great #mighty #protected #delight",
           0.542
          ],
          [
           "I'm so playful. lol I need somebody that'll joke with me all day long cause ill never get tired of it.",
           0.6
          ],
          [
           "Loved @Bethenny independence msg on @WendyWilliams, be happy &amp; fulfilled within yourself &amp; positivity will flock to you #happy #independent",
           0.646
          ],
          [
           "I love how cheery and adoring @JackHoward gets every time he produces new content.",
           0.833
          ],
          [
           "every time a new Anthony Weiner revelation breaks, Bill Clinton says a prayer of thanks that texting/DMing didn't exist in his heyday.",
           0.375
          ],
          [
           "A cheerful heart is good medicine, but a crushed spirit dries up the bones -Proverbs 17:22-",
           0.4
          ],
          [
           "@govph I would like to know about the source of The President's optimism about running the country. I wonder if he can answer my curiosity.",
           0.18
          ],
          [
           "Had a coworker look at her phone and say, cheerfully, 'oh look, Kap's getting death threats now.' . Then she goes to say the 49ers are",
           0.385
          ],
          [
           "Watch this amazing live.ly broadcast by @paulzimmer  #musically",
           0.521
          ],
          [
           "@Nick_Offerman I'll be there!! Can't wait for all the !",
           0.771
          ],
          [
           "@MoAmali @awosss @Arsenalman2011 listen I dn't subscribe to this team coq Team xhaka stuff. I like all our players. Depth has me elated",
           0.562
          ],
          [
           "The object of literature is to make man a wiser and happier being. The poet makes us happy because he tells us how we may become so.",
           0.58
          ],
          [
           "But i'll be a pity.  ",
           0.083
          ],
          [
           "Watch this amazing live.ly broadcast by @brooke_bridges  #musically",
           0.655
          ],
          [
           "Watch this amazing live.ly broadcast by @swagrman_fan  #musically",
           0.521
          ],
          [
           ".@Harry_Styles I hope you never go a day without something to make you smile. You deserve all good things. Please follow me?\\n\\n311,553",
           0.6
          ],
          [
           "@LoisJoanneLane Wagging his tail at the praise, he paused, tilting his head as she took the frisbee from him, letting out a playful -",
           0.562
          ],
          [
           "@aradsliff don't know I'm from nj we are the worst on purpose. #laughter",
           0.462
          ],
          [
           "@jessbr0ughton don't be shy next time! We're a cheery bunch. :) \\n\\nSam. X",
           0.48
          ],
          [
           "@Nikhilv95 @LydiajaneF I wish, I really, truly wish, that I had just a modicum of your banter. ",
           0.24
          ],
          [
           "@tomlinmayniac starting my new challenge ! A glee poll every day !",
           0.625
          ],
          [
           "Metal keeps you young and spry and keeps your hair luxurious.\\n\\nYES\\n\\nSHUT UP AND LISTEN TO ME",
           0.46
          ],
          [
           "This tweet is dedicated to my back pain, which I do not understand because I am youthful and spry. Full of life. Vivacious.",
           0.229
          ],
          [
           "Nawaz Sharif is getting more funnier than @kapilsharmak9 day by day.  #challenge #kashmir #baloch",
           0.58
          ],
          [
           "I love my family so much #lucky #grateful #smartassfamily #hilarious #love",
           0.792
          ],
          [
           "Ready for that nice, breezy, calm, sunshine weather. #Autumn",
           0.583
          ],
          [
           "@billie21806 @cnnbrk tell that to your bodies cheering on the deaths of black people by cops. their fear is killing us.",
           0.1
          ],
          [
           "@yungdoujin wouldn't that basically be sparkling water",
           0.32
          ],
          [
           "A hearty Jonza! to all my friends and follower.",
           0.704
          ]
         ],
         "hovertemplate": "emotion=joy<br>UMAP1=%{x}<br>UMAP2=%{y}<br>UMAP3=%{z}<br>text=%{customdata[0]}<br>intensity=%{customdata[1]}<extra></extra>",
         "legendgroup": "joy",
         "marker": {
          "color": "#00cc96",
          "opacity": 0.7,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "joy",
         "scene": "scene",
         "showlegend": true,
         "type": "scatter3d",
         "x": {
          "bdata": "MlV3vgZFIr9WajS/uaFGv4/P+b40ZI6/dPfRv7NJN7/d8i8/6Jutvy79qb8RRSu/wGjUPns+kb/hAyq/ztGhP3YeyD0XAZ2+nigUv+gUF7/oqGk/8uWfv9Yvh76UiJQ/yBOTv3/pkb/Vl8M+HvZMv5z4dL8JZY2/NfuEv8ZtoL5ITc6+28LIPElbbL+joCi/sDK+v5HE6L6IwT+/09rqP4X5A7/oYIu/K72BP8ZDmT794oC/",
          "dtype": "f4"
         },
         "y": {
          "bdata": "OsjbPwSkPkCdpCdAyIE5QDNfLUCatwpANQ4hP5aVREAEqwZAZpASQI/A2z9R1QVA61TFP4O9D0DUyiFAe++QP99ZMUATzpM/NyVFQIFtJkD/QTpAb/gTQA4iRUAMQfw/IP8MQC55IUB5sCNAId5BQHCz6T/ujgdAL/wMQL8DPEBiKvM/tVKFPz4BGkBStBFAKWDNPzJ2EEDSQxlA/BJLQDhktj85/DpAXGYRQBsO1z+cxy5A",
          "dtype": "f4"
         },
         "z": {
          "bdata": "0EmAP2UrDEDq05A/HcoMQI+v3z/BiDZAnHskQKNP/T8Cs5A/PY9MQN54SEClqI8/DMtrP22qpz+u4nw/tmVMQDn/5z/KLANAwRt1P6uJlz+b6S5AGhgsQD4EF0D20k1ArbkEP06SYz9mPZE/nlgbQP6ORkCwSO8+WV3QPiS2Tj/8HaE/c2AeQBg4rT8zLgtA/a6OP6kWF0CApRdAHLxMQDKo+D/NQsU/AOZeQKVZtD+WDns/",
          "dtype": "f4"
         }
        },
        {
         "customdata": [
          [
           "@m_giacchino will this be aired on radio or filmed? Lots of fans over the pond too! #wales #lost",
           0.354
          ],
          [
           "Hopefully next time we play a L1 team, 1 of the players scores, takes his shirt off &amp;jumps into away end purely to wind up the joyless cunts",
           0.396
          ],
          [
           "What do you do?'\\n'You are not worthy enough to know.' #what #serious",
           0.458
          ],
          [
           "Very long day. Thank goodness for Bake Off to brighten up a weary Wednesday  #GBBO",
           0.188
          ],
          [
           "@beIIrkes Es, I'm serious 23/8",
           0.271
          ],
          [
           "Marcos rojo plays for man united !!  Just let that sink in !!!",
           0.417
          ],
          [
           "Brad Pitt being investigated for child abuse?! this all just got really #dark",
           0.479
          ],
          [
           "@pxrfectpeach it's got her little pout",
           0.271
          ],
          [
           "@crimsonwulfe it's super sad!! Especially when you are talking to a real person and not a bot! Makes it feel real :(",
           0.75
          ],
          [
           "Well i did hear once before that girls are attracted to men that look like their dad!   ",
           0.25
          ],
          [
           "@cotsonika @NHL well, they should all be unhappy for the way they played.  Right @fmjacob ??",
           0.542
          ],
          [
           "@iTriborg  make him feel vigorous. 'Fine. You can kill me now.' Said Hestia with a display of only despair rather than her joyful ",
           0.5
          ],
          [
           "I have serious problems with the expectation that private philanthropy should replace functional government services...this is dangerous",
           0.396
          ],
          [
           "Some of these people at this protest are just there for the adrenaline rush. #depressing",
           0.583
          ],
          [
           "Let the #MrRobot binge begin. #nerdshow #compelling #dark",
           0.229
          ],
          [
           "Mixed emotions. #sadness #anxietymaybe #missingfriends #growingupsucks #lostfriends #wheresthetruefriends #complications",
           0.667
          ],
          [
           "We want to help you with your #depression. Give our office a call to learn how #TMS may be the treatment you've been waiting for!",
           0.521
          ],
          [
           "@m_giacchino will this be aired on radio or filmed? Lots of fans over the pond too! #wales ",
           0.188
          ],
          [
           "@AMB4JC @drtonyevans It's our job, the job of people who r still sane,still ok in life, to help the lost to find themselves &amp; love eachother",
           0.214
          ],
          [
           "Never ever been this unhappy before in my life lmao",
           0.771
          ],
          [
           "Tell me how I'm supposed to feel. #broken #hateful #guilty #love #sadness",
           0.729
          ],
          [
           "@JohnRMoffitt This is the most grim piece of laughter I was stricken with all day.",
           0.604
          ],
          [
           "It's sad when your man leaves work a little bit late and your worst fear is 'Oh no!! Did he get stopped by the police?!?! '  #ourworld",
           0.618
          ],
          [
           "We have left #Maine. #sadness",
           0.771
          ],
          [
           "I don't know why everyone is pretending to be sad about angelina and brad, everyone knows his dumb ass should've stayed with jennifer.",
           0.354
          ],
          [
           "The man who is a pessimist before 48 knows too much; if he is an optimist after it, he knows too little.'\\n-Mark Twain",
           0.417
          ],
          [
           "@pureleine though lately with how bad my depression has been i feel like my body is like just, taking what little it can get",
           0.771
          ],
          [
           "@JoyceCarolOates \\nBreath. You are trending despondent. Mrs Clinton will win. If you keep your gloves on, guard up, and punch like hell.",
           0.417
          ],
          [
           "| At home sick... The blues won't cure it so I need ideas  | #sorethroat #sick #blues #music #fallweather #carletonuniversity #ottawa",
           0.833
          ],
          [
           "@CTV_PowerPlay @lraitt Horrid disease! My maternal grandmother and each of her sisters suffered from this affliction. It's hard on all.",
           0.75
          ],
          [
           "it didn't impress me but it didn't depress me'",
           0.271
          ],
          [
           "It's pretty clear I can't stand @HillaryClinton, no tolerance for habitual liars. Not a Trump fan either so what's a citizen to do? #despair",
           0.646
          ],
          [
           "where broken hearted lovers do cry away their gloom",
           0.708
          ],
          [
           "My friends tell me I'm pretty. Trigger tells my I'm ugly. I first was confused but then realised I'm both. Pretty ugly. #tru  #tumblr",
           0.583
          ],
          [
           "@big_SL8 Show some respect, that's all...  If u havent go to war u cant say anything.. U havent lost friends and mates on war, so Ahut it!!",
           0.583
          ],
          [
           "@kempicepoland don't think he did, and he didn't have the rucksack or laptop in his possession, murky business, on that note I'm away to bed",
           0.5
          ],
          [
           "HATE that there's ads for #depression &amp; #mentalhealth #meds. That's ONLY something your doctor can determine. Everyone is different. #ssri",
           0.46
          ],
          [
           "Common app just randomly logged me out as I was writing the last part of my college essay and lost all of it ",
           0.833
          ],
          [
           "All I want to do is watch some netflix but I am stuck here in class. #depressing",
           0.667
          ],
          [
           "Don't depress yourself by comparing yourself. No comparisons.",
           0.438
          ],
          [
           "This shit hurting my heart  that's how serious it is .",
           0.875
          ],
          [
           "Stars, when you shine,\\nYou know how I feel.\\nScent of the pine, \\nYou know how I feel.\\nFreedom is mine,\\nI know how I feel.\\nI'm feelin' good.",
           0.292
          ],
          [
           "Wow just watched Me Before You and it was seriously one of the most depressing movies of my life",
           0.667
          ]
         ],
         "hovertemplate": "emotion=sadness<br>UMAP1=%{x}<br>UMAP2=%{y}<br>UMAP3=%{z}<br>text=%{customdata[0]}<br>intensity=%{customdata[1]}<extra></extra>",
         "legendgroup": "sadness",
         "marker": {
          "color": "#ab63fa",
          "opacity": 0.7,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "sadness",
         "scene": "scene",
         "showlegend": true,
         "type": "scatter3d",
         "x": {
          "bdata": "oqCxv0Hyhz9wqq0+kz2qv7hkIT6xyjE/rlWeP/qjT766S1S/Dj+SPiqKZj8QNIi/VZy7PhmhYD6cEdi/zHKLv3S5A79Avau/KC4APljGLb9iwaK/7MAivqFe+D27oFe/wlaYP5BFH7+NlZu/8WChPuQvub8a1za+TdIvv6RoAD9V/5a/P5mWv0+9dj9j/Ek/GivAvqhsOr9tIUO/uxUkv2H2474l45e/K241vw==",
          "dtype": "f4"
         },
         "y": {
          "bdata": "BE8RQCEYaD+7zPg/cxkSQAQF3T+7Aag/G4GgPzm9vz/1R6g/YUGTP/3/Kj+yxfw/Oiw8QHPg/D8e2G8/XQCtP7Xc8j/0cBlABl1EQEV4lj9GWss/zJ+mP9Ui6D/M8rg/3OCMP4ycQEAzOsc/1TpCQG50sj/1kZQ/jREPQHAaQEBYqwRAZjjGP1kEFkA+88Q/j0fuP4BiWT/ZotY/LAwEQEMoqD8zNjdA17yfPw==",
          "dtype": "f4"
         },
         "z": {
          "bdata": "A8s5PyygKkBUtwBA6XLeP/ik9T8IDIw/avZcQNM0tT8HOVZAcZkBQE5m/j+1sCdAB2QqQJ6nY0BYPypAzENzQLAMfUBzQUU/sviwPxkdWkCoBXVAQW8lQG3Qa0AkzWVACLBUQORZKEBwlFVA6HA5QF9nYkD2zj5AHCNaQNIyTkANvFFAiSRsQKorxj89p+k/IqN5QKIUY0D1WHBAFOpmQDVNWEAi8gxA46Z2QA==",
          "dtype": "f4"
         }
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "emotion"
         },
         "tracegroupgap": 0
        },
        "scene": {
         "domain": {
          "x": [
           0,
           1
          ],
          "y": [
           0,
           1
          ]
         },
         "xaxis": {
          "title": {
           "text": "UMAP1"
          }
         },
         "yaxis": {
          "title": {
           "text": "UMAP2"
          }
         },
         "zaxis": {
          "title": {
           "text": "UMAP3"
          }
         }
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "3D UMAP Projection of Text Embeddings"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Answer here\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import umap\n",
    "import plotly.express as px\n",
    "\n",
    "# Concatenate the training and test data\n",
    "combined_df = pd.concat([train_df_new, test_df_new], ignore_index=True)\n",
    "\n",
    "# Prepare the embeddings for UMAP\n",
    "X_embeddings = np.array(combined_df['embeddings_values'].tolist())\n",
    "\n",
    "# Apply UMAP for dimensionality reduction\n",
    "reducer = umap.UMAP(n_components=3, metric='cosine', random_state=28) \n",
    "embedding_3d = reducer.fit_transform(X_embeddings)\n",
    "\n",
    "# Create a DataFrame for plotting\n",
    "df_plot = pd.DataFrame(embedding_3d, columns=['UMAP1', 'UMAP2', 'UMAP3'])\n",
    "df_plot['emotion'] = combined_df['emotion']\n",
    "df_plot['intensity'] = combined_df['intensity']\n",
    "df_plot['text'] = combined_df['text']\n",
    "\n",
    "\n",
    "# Visualize the embeddings with Plotly\n",
    "fig = px.scatter_3d(\n",
    "    df_plot,\n",
    "    x='UMAP1',\n",
    "    y='UMAP2',\n",
    "    z='UMAP3',\n",
    "    color='emotion',  # Color points by the 'emotion' column\n",
    "    hover_data=['text', 'intensity'],  # Show text and intensity on hover\n",
    "    title='3D UMAP Projection of Text Embeddings',\n",
    "    opacity=0.7,\n",
    "    size_max=1\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Except for fear, the other three classes appear better separated in the 3D graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <a id='toc1_5_9_'></a>[**2.5 Retrieval-Augmented Generation (RAG)**](#toc0_)\n",
    "\n",
    "`NOTE: This whole section including the exercise is now considered a bonus section, not counted for the main grade.`\n",
    "\n",
    "RAG (Retrieval-Augmented Generation) is a technique where a language model combines document retrieval with text generation. In RAG, a retrieval system first finds relevant documents or text chunks, and then the language model uses this retrieved information to generate a more informed and accurate response. This method enhances the model's ability to answer questions by grounding its responses in real, external data.\n",
    "\n",
    "In the following code, we will load a webpage as a document, which allows us to retrieve text from a URL. After loading the content, we will split the document into smaller, manageable chunks, making it easier for our model to process. Then, we'll generate embeddings for these chunks with a specified LLM model (Gemini Embedding Model). These embeddings will be stored in a vector database, which enables us to perform similarity searches. By setting up this retrieval system, we can use a RAG chain to answer questions. The retriever finds relevant text chunks from the document based on a query, and the LLM generates a response by incorporating this retrieved information, making the answers more grounded and accurate.\n",
    "\n",
    "In this example we use the library langchain, for documentation on more functions of the library you can check the following link: [LangChain Tutorials](https://python.langchain.com/docs/tutorials/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "# Function to load, split, and retrieve documents\n",
    "def load_and_retrieve_docs(url):\n",
    "    loader = WebBaseLoader(\n",
    "        web_paths=(url,),\n",
    "        bs_kwargs=dict() \n",
    "    ) \n",
    "    docs = loader.load() #We will load the URL that will serve as our data source\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150) #We will divide the URL in chunks of text for easier comparison in the vector space\n",
    "    splits = text_splitter.split_documents(docs)\n",
    "    #print(splits) #You can print this to see how the chunks in the url where split\n",
    "    embeddings = GoogleGenerativeAIEmbeddings(model=\"models/gemini-embedding-001\")\n",
    "    vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings) #Our vector space for comparison\n",
    "    return vectorstore.as_retriever()\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs) #Format the retrieved docs in an orderly manner for prompting\n",
    "\n",
    "# Define the Gemini LLM function\n",
    "def gemini_llm(question, context):\n",
    "    system_prompt = \"You are a RAG Agent that needs to provide a well structured answer based on the provided question and context.\"\n",
    "    formatted_prompt = f\"Question: {question}\\n\\nContext: {context}\"\n",
    "    response, logs = prompt_gemini(input_prompt = formatted_prompt, system_instruction = system_prompt, with_tokens_info = True)\n",
    "    print(f\"logs: \\n{logs}\")\n",
    "    # print(f\"Retrieved context: \\n{context}\\n\\n\") # You can print this to observe the retrieved context\n",
    "    return response\n",
    "\n",
    "\n",
    "# Define the RAG chain\n",
    "def rag_chain(question, retriever):\n",
    "    retrieved_docs = retriever.invoke(question)\n",
    "    formatted_context = format_docs(retrieved_docs)\n",
    "    return gemini_llm(question, formatted_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs: \n",
      "{'model': 'gemini-2.5-pro', 'input_tokens': 726, 'output_tokens': 206}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Based on the context provided, the key challenges in realizing the full potential of AGI can be categorized into technical and ethical considerations.\n",
       "\n",
       "### Technical Challenges\n",
       "*   **Learning from Diverse Data:** Unlike narrow AI that works well with structured data, AGI faces the challenge of needing to learn from unstructured and diverse data sources.\n",
       "*   **Computational Power:** AGI requires immense computational resources to process and learn from the vast amounts of data needed for its development, which poses a significant challenge.\n",
       "\n",
       "### Ethical and Regulatory Challenges\n",
       "*   **Bias and Fairness:** It is crucial to create unbiased algorithms that treat everyone equally. This involves training models on diverse datasets and regularly checking for biases.\n",
       "*   **Privacy:** Protecting user data is a top priority. This requires implementing strong privacy measures and transparent policies regarding data usage.\n",
       "*   **Accountability:** There is a need to establish clear guidelines and legal frameworks to determine who is responsible for the decisions and actions taken by AGI systems, especially when mistakes or harm occur."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url=\"https://qbotica.com/understanding-artificial-general-intelligence-agi-an-in-depth-overview/\"\n",
    "# Create the retriever\n",
    "retriever = load_and_retrieve_docs(url)\n",
    "\n",
    "# Use the RAG chain\n",
    "result = rag_chain(question=\"What are the Key Challenges in Realizing AGIs Full Potential\", retriever=retriever)\n",
    "display(Markdown(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### <a id='toc1_5_9_1_1_'></a>[**Actual answer in the URL:**](#toc0_)\n",
    "\n",
    "![pic11.png](pics/pic11.png)\n",
    "\n",
    "##### <a id='toc1_5_9_1_2_'></a>[**Content in the URL that might get into the generated answer because of similar semantic meaning:**](#toc0_)\n",
    "\n",
    "![pic12.png](pics/pic12.png)\n",
    "\n",
    "source: https://qbotica.com/understanding-artificial-general-intelligence-agi-an-in-depth-overview/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### <a id='toc1_5_9_1_3_'></a>[**>>> Bonus Exercise 5 (Take home):**](#toc0_)\n",
    "\n",
    "`NOTE: This exercise is now considered a bonus one, not counted for the main grade, only as extra points.`\n",
    "\n",
    "Your task is to test the RAG system with your own chosen URL and analyze its performance.\n",
    "\n",
    "1. Find a URL of a webpage with interesting text content to test the RAG pipeline.\n",
    "2. Make a question about the content in the webpage you chose.\n",
    "3. Discuss how good the question was answered by the model, if the model missed important information related to your question.\n",
    "4. Display a screenshot of the real answer in the webpage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and processing web data, please wait...\n",
      "Generating guide summary...\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**10-20**\n",
       "*   4 (/)\n",
       "\n",
       "**20-30**\n",
       "*    (/)\n",
       "\n",
       "**30-46**\n",
       "*    (/)\n",
       "\n",
       "**46-70**\n",
       "*    (/)\n",
       "\n",
       "**70-75**\n",
       "*    (/)\n",
       "\n",
       "**75-87**\n",
       "*    (/)\n",
       "\n",
       "**87-102**\n",
       "*   II (:5)\n",
       "\n",
       "**102-116**\n",
       "*    (:28)\n",
       "\n",
       "**116-135**\n",
       "*   3 (:55)\n",
       "\n",
       "**135-158**\n",
       "*   2 (:80)\n",
       "*    () (/)\n",
       "\n",
       "**158-180**\n",
       "*   H01 (:140)\n",
       "*    (H01180)\n",
       "\n",
       "**180-200**\n",
       "*   2 (/)\n",
       "\n",
       "**200-210**\n",
       "*    (/)\n",
       "*    (205-210//)\n",
       "\n",
       "**210-220**\n",
       "*    (200//)\n",
       "*    (215//)\n",
       "\n",
       "**220-225**\n",
       "*   2 (/)\n",
       "*   3 (/)\n",
       "*   2 (/)\n",
       "\n",
       "**225-235**\n",
       "*    (++/)\n",
       "*    (/)\n",
       "\n",
       "**235-240**\n",
       "*   5 (//)\n",
       "\n",
       "**240-245**\n",
       "*    4 (ARC700/)\n",
       "\n",
       "**245-255**\n",
       "*   3 (/)\n",
       "\n",
       "**255-260**\n",
       "*   1-9 ()\n",
       "*   4 ()\n",
       "*    2-7 ()\n",
       "\n",
       "**260-265**\n",
       "*   2 (/)\n",
       "\n",
       "**265-270**\n",
       "*   5 (AUT//)\n",
       "\n",
       "**270-275**\n",
       "*    2 (AUT/)\n",
       "*   1 or 3 (AUT/)\n",
       "*   1 (AUT)\n",
       "\n",
       "**275-279**\n",
       "*    (AUT)\n",
       "*   1 (//)\n",
       "*   5 (/)\n",
       "\n",
       "**280-284**\n",
       "*   3\n",
       "*   6\n",
       "\n",
       "**285-300**\n",
       "*   3\n",
       "*   3\n",
       "\n",
       ""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Answer here\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "def load_and_retrieve_docs(url):\n",
    "    # Load web content\n",
    "    loader = WebBaseLoader(\n",
    "        web_paths=(url,),\n",
    "        bs_kwargs=dict() \n",
    "    ) \n",
    "    docs = loader.load()\n",
    "\n",
    "    # Split text into chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)\n",
    "    splits = text_splitter.split_documents(docs)\n",
    "    \n",
    "    # Create vector store with embeddings\n",
    "    embeddings = GoogleGenerativeAIEmbeddings(model=\"models/gemini-embedding-001\")\n",
    "    vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings)\n",
    "    \n",
    "    return vectorstore.as_retriever(search_kwargs={\"k\": 15})\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "def gemini_llm(question, context):\n",
    "    llm = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-2.5-flash-lite\",\n",
    "        temperature=0\n",
    "    )\n",
    "    \n",
    "    system_prompt = \"\"\n",
    "    \n",
    "    messages = [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", f\"Question: {question}\\n\\nContext: {context}\")\n",
    "    ]\n",
    "    \n",
    "    # Generate response\n",
    "    response = llm.invoke(messages)\n",
    "    return response.content\n",
    "\n",
    "def rag_chain(question, retriever):\n",
    "    retrieved_docs = retriever.invoke(question)\n",
    "    formatted_context = format_docs(retrieved_docs)\n",
    "    return gemini_llm(question, formatted_context)\n",
    "\n",
    "# 1. Target URL\n",
    "url = \"https://pinogamer.com/10970\"\n",
    "\n",
    "# 2. Initialize Retriever\n",
    "print(\"Loading and processing web data, please wait...\")\n",
    "retriever = load_and_retrieve_docs(url)\n",
    "\n",
    "# 3. Define the query\n",
    "# Asking for a list of leveling spots categorized by level range\n",
    "my_question = \"\"\"\n",
    "\n",
    " (10-3030-60...)\n",
    " [][] (/)\n",
    "\"\"\"\n",
    "\n",
    "# 4. Execute RAG Chain\n",
    "print(\"Generating guide summary...\")\n",
    "result = rag_chain(question=my_question, retriever=retriever)\n",
    "display(Markdown(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![01.png](01.png)\n",
    "![02.png](02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <a id='toc1_5_10_'></a>[**2.6 Few-Shot Prompting Classification:**](#toc0_)\n",
    "\n",
    "Few-shot prompting is a technique where a Large Language Model (LLM) is given a small number of labeled examples within a prompt to guide its classification. This allows the model to perform a new task with minimal data, avoiding the need for extensive fine-tuning.\n",
    "\n",
    "In this lab, we will use the Gemini API to perform zero-shot, 1-shot, and 5-shot emotion classification:\n",
    "\n",
    "*   **Zero-shot:** The model classifies text without any prior examples.\n",
    "*   **1-shot:** The model is given one example for each emotion before classifying.\n",
    "*   **5-shot:** The model is given five examples per emotion for better context.\n",
    "\n",
    "To make our implementation robust and efficient, we are incorporating two key features:\n",
    "\n",
    "1.  **Structured Output:** We provide the Gemini model with a specific output schema (`Emotions` class). This instructs the model to return *only* a valid emotion label (e.g., `joy`), which makes the output predictable and reliable, minimizing errors.\n",
    "2.  **API Rate Handling:** The code includes a function to manage the requests-per-minute limit of the Gemini API.\n",
    "\n",
    "We will test the model's performance on a small sample of 20 texts per emotion to ensure the process runs quickly. If the model provides an invalid response, the code will automatically retry the request until a valid classification is received.\n",
    "\n",
    "**Prompt Structure:**\n",
    "`System Instruction -> Task Description -> Examples (if not zero-shot) -> Text to Classify`\n",
    "\n",
    "\n",
    "<span style=\"color:green\">For the exercises in this section there is no need to re-run the cells, you can use the data that has been saved previously to the corresponding directory.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciton for visualizing confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, title='Confusion matrix',\n",
    "                          cmap=sns.cubehelix_palette(as_cmap=True)):\n",
    "    \"\"\"\n",
    "    This function is modified from: \n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "    \"\"\"\n",
    "    classes.sort()\n",
    "    tick_marks = np.arange(len(classes))    \n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           xticklabels = classes,\n",
    "           yticklabels = classes,\n",
    "           title = title,\n",
    "           xlabel = 'Predicted label',\n",
    "           ylabel = 'True label')\n",
    "\n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    ylim_top = len(classes) - 0.5\n",
    "    plt.ylim([ylim_top, -.5])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import enum\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import time\n",
    "# Define the emotion labels\n",
    "emotions = ['anger', 'fear', 'joy', 'sadness']\n",
    "# Define the model to use for few-shot prompting\n",
    "\n",
    "# Schema for the output, the type enum can be used to make a pool of options if what we want is to classify our text selecting only one of them\n",
    "class Emotions(enum.StrEnum):\n",
    "    ANGER = 'anger'\n",
    "    FEAR = 'fear'\n",
    "    JOY = 'joy'\n",
    "    SADNESS = 'sadness'\n",
    "\n",
    "\n",
    "# Function to handle the rate limits of gemini models\n",
    "def handle_rate_limit(request_count, first_request_time, max_calls_per_min):\n",
    "    current_time = time.time()\n",
    "\n",
    "    # Initialize timer on the first request of a new window\n",
    "    if request_count == 0:\n",
    "        first_request_time = current_time\n",
    "\n",
    "    request_count += 1\n",
    "\n",
    "    # If the rate limit is reached\n",
    "    if request_count > max_calls_per_min:\n",
    "        elapsed_time = current_time - first_request_time\n",
    "        if elapsed_time < 60:\n",
    "            wait_time = 60 - elapsed_time\n",
    "            print(f\"Rate limit of {max_calls_per_min} requests per minute reached. Waiting for {wait_time:.2f} seconds.\")\n",
    "            time.sleep(wait_time)\n",
    "\n",
    "        # Reset for the new window\n",
    "        request_count = 1\n",
    "        first_request_time = time.time()\n",
    "    \n",
    "    return request_count, first_request_time, max_calls_per_min\n",
    "\n",
    "# Function to sample examples per emotion category\n",
    "def sample_few_shots(df, emotions, num_samples=5):\n",
    "    few_shot_examples = {}\n",
    "    for emotion in emotions:\n",
    "        few_shot_examples[emotion] = df[df['emotion'] == emotion].sample(n=num_samples, random_state=42)\n",
    "    return few_shot_examples\n",
    "\n",
    "# Function to build the prompt based on the number of examples (few-shot, 1-shot, zero-shot)\n",
    "def build_prompt(examples, emotions, num_shots=5):\n",
    "    classification_instructions = \"\"\"\n",
    "You will be given a text extracted from social media and your task is to classify the text into one of the following emotion categories: \n",
    "\"anger\" | \"fear\" | \"joy\" | \"sadness\"\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = classification_instructions + \"\\n\\n\"\n",
    "    \n",
    "    if num_shots > 0:\n",
    "        prompt += f\"Examples: \\n\"\n",
    "        for emotion in emotions:\n",
    "            for _, row in examples[emotion].iterrows():\n",
    "                prompt += f\"Text: {row['text']}\\nClass: {emotion}\\n\\n\" #Show the examples in the same format it will be shown for the classification text\n",
    "                if num_shots == 1:  # If 1-shot, break after the first example for each emotion\n",
    "                    break\n",
    "    return prompt\n",
    "\n",
    "# Function to classify using the LLM with retry for incorrect responses\n",
    "def classify_with_llm(test_text, prompt_base, system_prompt, classes, schema):\n",
    "    response = None\n",
    "    while not response or response not in classes:\n",
    "        full_prompt = f\"{prompt_base}\\nClassification:\\nText: {test_text}\\nClass: \" #The classification text will leave the emotion label to be filled in by the LLM\n",
    "        try:\n",
    "            result = prompt_gemini(input_prompt = [full_prompt], schema = schema, system_instruction = system_prompt)\n",
    "            # print(f\"result: {result} \\n\")\n",
    "            # print(f\"type: {type(result)}\")\n",
    "            if not result:\n",
    "                # In case of giving empty responses with temperature 0.0, we set a higher temperature to seek for different responses\n",
    "                result = prompt_gemini(input_prompt = [full_prompt], schema = schema, system_instruction = system_prompt, temperature=1.0)\n",
    "\n",
    "            try:\n",
    "                # If the result is in the correct format it can be parsed using json\n",
    "                response = json.load(result)\n",
    "            except:\n",
    "                # In case it's not in a json friendly format\n",
    "                # Deleting characters \" and ' in case they appear in our response with the class of the text \n",
    "                response = result.replace('\"', '')    \n",
    "                response = response.replace(\"'\", \"\")  \n",
    "\n",
    "                \n",
    "        # except exceptions.ResourceExhausted as e:\n",
    "        except Exception as e:\n",
    "            print(f\"Waiting to retry... Error: {e}\")\n",
    "            time.sleep(15)\n",
    "            print(f\"test_text: {test_text}\")\n",
    "            return classify_with_llm(test_text, prompt_base, system_prompt, classes, schema) # Retry the request\n",
    "\n",
    "\n",
    "        if response not in classes:  # Retry if not a valid response\n",
    "            print(f\"Invalid response: {response}. Asking for reclassification.\")\n",
    "    return response\n",
    "\n",
    "# Main function to run the experiment with the option for zero-shot, 1-shot, or 5-shot prompting\n",
    "def run_experiment(df_train, df_test, num_test_samples=5, num_shots=5):\n",
    "    # Sample examples for few-shot prompting based on num_shots\n",
    "    if num_shots > 0:\n",
    "        few_shot_examples = sample_few_shots(df_train, emotions, num_samples=num_shots) \n",
    "        prompt_base = build_prompt(few_shot_examples, emotions, num_shots=num_shots)\n",
    "    else:\n",
    "        prompt_base = build_prompt(None, emotions, num_shots=0)  # Zero-shot has no examples\n",
    "\n",
    "    # System prompt for our classification model:\n",
    "    system_prompt = \"You are an emotion classification model for text data. Do not give empty responses, classify according to the list of possible classes.\"\n",
    "\n",
    "    # Prepare to classify the test set\n",
    "    results_data = []\n",
    "\n",
    "    print(prompt_base)\n",
    "    # Sample 20 examples per emotion for the test set to classify\n",
    "    test_samples = sample_few_shots(df_test, emotions, num_samples=num_test_samples)\n",
    "\n",
    "    # Variables to handle rate limit of gemini\n",
    "    request_count = 0\n",
    "    max_calls_per_min = 15 # Gemini 2.5 Flash Lite has this maximum set in the documentation\n",
    "    first_request_time = None\n",
    "\n",
    "    # Classify 20 test examples (5 from each category) and save predictions\n",
    "    for emotion in emotions:\n",
    "        for _, test_row in tqdm(test_samples[emotion].iterrows(), desc=f\"Processing samples for emotion: {emotion}...\", total=num_test_samples):\n",
    "            test_text = test_row['text']\n",
    "            request_count, first_request_time, max_calls_per_min = handle_rate_limit(request_count, first_request_time, max_calls_per_min)  # Check and handle rate limit before each API call\n",
    "            predicted_emotion = classify_with_llm(test_text = test_text, prompt_base = prompt_base, system_prompt = system_prompt, classes = emotions, schema = Emotions)\n",
    "            # Append the results data:\n",
    "            results_data.append({\n",
    "                    'text': test_text,\n",
    "                    'true_emotion': emotion,\n",
    "                    'predicted_emotion': predicted_emotion\n",
    "                })\n",
    "\n",
    "    # Create dataframe to save the results data\n",
    "    results_df = pd.DataFrame(results_data)\n",
    "    \n",
    "    # Extract just the true and predicted labels for metrics calculations\n",
    "    true_labels = results_df['true_emotion']\n",
    "    predictions = results_df['predicted_emotion']\n",
    "\n",
    "    output_dir = \"./results/llm_classification_results\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    # Save the results\n",
    "    filename = f\"{output_dir}/results_samples_{num_test_samples}_shots_{num_shots}.csv\"\n",
    "    \n",
    "    # Save the DataFrame to CSV\n",
    "    results_df.to_csv(filename, index=False)\n",
    "    print(f\"\\nResults saved to {filename}\")\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    \n",
    "    # Classification report\n",
    "    print(classification_report(y_true=true_labels, y_pred=predictions))\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    cm = confusion_matrix(y_true=true_labels, y_pred=predictions) \n",
    "    my_tags = ['anger', 'fear', 'joy', 'sadness']\n",
    "    plot_confusion_matrix(cm, classes=my_tags, title=f'Confusion matrix for classification with \\n{num_shots}-shot prompting')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important: The next part should take around 16 minutes to finish running due to API Rate Limits**\n",
    "\n",
    "**Note:** You might see an `429 RESOURCE_EXHAUSTED` error when running the following code all at once, this is because the `current API Rate Limit handling cannot reliably find out how many requests we have left per minute` from cell to cell, there is no Gemini feature created for it to get the information from their servers. So, `if you don't want to see the error you can just wait 1 minute` after one cell finished processing. But `even if there is an error showing it is fine`, internally in the code `there is a retry that happens every 15 seconds` until we finish processing our sampled data. `The lab is designed to never reach the total rate limit per day quota.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You will be given a text extracted from social media and your task is to classify the text into one of the following emotion categories: \n",
      "\"anger\" | \"fear\" | \"joy\" | \"sadness\"\n",
      "    \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: anger...:  75%|  | 15/20 [00:12<00:04,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 47.64 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: anger...: 100%|| 20/20 [01:04<00:00,  3.21s/it]\n",
      "Processing samples for emotion: fear...:  50%|     | 10/20 [00:08<00:09,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 47.66 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: fear...: 100%|| 20/20 [01:05<00:00,  3.30s/it]\n",
      "Processing samples for emotion: joy...:  25%|       | 5/20 [00:04<00:13,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 45.16 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: joy...: 100%|| 20/20 [01:02<00:00,  3.13s/it]\n",
      "Processing samples for emotion: sadness...:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 47.32 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: sadness...:  75%|  | 15/20 [00:59<00:04,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 47.71 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: sadness...: 100%|| 20/20 [01:51<00:00,  5.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results saved to ./results/llm_classification_results/results_samples_20_shots_0.csv\n",
      "Accuracy: 52.50%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.46      0.60      0.52        20\n",
      "        fear       0.83      0.25      0.38        20\n",
      "         joy       0.47      0.80      0.59        20\n",
      "     sadness       0.64      0.45      0.53        20\n",
      "\n",
      "    accuracy                           0.53        80\n",
      "   macro avg       0.60      0.53      0.51        80\n",
      "weighted avg       0.60      0.53      0.51        80\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# If you see '429 RESOURCE_EXHAUSTED' errors it's fine, wait until the data gets processed, it will keep retrying until it finishes\n",
    "\n",
    "# Example of running the experiment with zero-shot prompting\n",
    "run_experiment(train_df, test_df, num_test_samples=20, num_shots=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You will be given a text extracted from social media and your task is to classify the text into one of the following emotion categories: \n",
      "\"anger\" | \"fear\" | \"joy\" | \"sadness\"\n",
      "    \n",
      "\n",
      "Examples: \n",
      "Text: As your own lives in order to complete our amazing life journey successfully, it is there. \n",
      "Class: anger\n",
      "\n",
      "Text: It's 5:55am. I'm hungry but there is no food. \n",
      "Class: fear\n",
      "\n",
      "Text: When something makes you excited, terrified, thrilled, nervous, elated &amp; like you've been kicked in the guts all at once. Need word for that\n",
      "Class: joy\n",
      "\n",
      "Text: @BlurtAlerts 'the darkest of nights can be bright, the solemn of faces lights up with a smile'. -@Totemprince believe in me, as I do in you\n",
      "Class: sadness\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: anger...:  55%|    | 11/20 [00:08<00:06,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 48.318337485s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '48s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 48.25669189s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '48s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Taking umbrage because Jimmy Carr claimed that Bilbo Baggins went to Mordor on 8 out of 10 cats does Countdown. Know your Baggins', mate.\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 31.947569152s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '31s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 31.586425467s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '31s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Taking umbrage because Jimmy Carr claimed that Bilbo Baggins went to Mordor on 8 out of 10 cats does Countdown. Know your Baggins', mate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: anger...:  75%|  | 15/20 [00:43<00:20,  4.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 16.40 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: anger...: 100%|| 20/20 [01:04<00:00,  3.20s/it]\n",
      "Processing samples for emotion: fear...:  35%|      | 7/20 [00:05<00:10,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 46.996913478s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '46s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 46.908605431s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '46s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: The Apocalypse has hit our gym and it's  nothing what I thought it would be...\\n\\nEveryone is wearing vests! What if it's contagious? \n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 31.782269509s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '31s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 31.716517336s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '31s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: The Apocalypse has hit our gym and it's  nothing what I thought it would be...\\n\\nEveryone is wearing vests! What if it's contagious? \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: fear...:  50%|     | 10/20 [00:38<00:54,  5.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 17.44 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: fear...: 100%|| 20/20 [01:04<00:00,  3.21s/it]\n",
      "Processing samples for emotion: joy...:  15%|        | 3/20 [00:02<00:12,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 46.174107328s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '46s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 46.116242599s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '46s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: @chencouture LMAO Is it that 'so slutty' hater girl? That video was hilarious. \n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 30.992026943s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '30s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 30.907776299s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '30s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: @chencouture LMAO Is it that 'so slutty' hater girl? That video was hilarious. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: joy...:  25%|       | 5/20 [00:34<02:07,  8.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 17.34 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: joy...:  95%|| 19/20 [01:03<00:00,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 44.741112755s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '44s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 44.682431754s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '44s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: i was so embarrassed when she saw us i was like knvfkkjg she thinks we're stalkers n then she starts waving all cheerfully inviting us in \n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 29.539733561s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '29s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 29.478707543s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '29s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: i was so embarrassed when she saw us i was like knvfkkjg she thinks we're stalkers n then she starts waving all cheerfully inviting us in \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: joy...: 100%|| 20/20 [01:35<00:00,  4.75s/it]\n",
      "Processing samples for emotion: sadness...:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 16.68 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: sadness...:  75%|  | 15/20 [00:30<00:04,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 46.20 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: sadness...: 100%|| 20/20 [01:20<00:00,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results saved to ./results/llm_classification_results/results_samples_20_shots_1.csv\n",
      "Accuracy: 57.50%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.50      0.70      0.58        20\n",
      "        fear       0.60      0.30      0.40        20\n",
      "         joy       0.58      0.75      0.65        20\n",
      "     sadness       0.69      0.55      0.61        20\n",
      "\n",
      "    accuracy                           0.57        80\n",
      "   macro avg       0.59      0.57      0.56        80\n",
      "weighted avg       0.59      0.57      0.56        80\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# If you see '429 RESOURCE_EXHAUSTED' errors it's fine, wait until the data gets processed, it will keep retrying until it finishes\n",
    "\n",
    "# Example of running the experiment with 1-shot prompting\n",
    "run_experiment(train_df, test_df, num_test_samples=20, num_shots=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You will be given a text extracted from social media and your task is to classify the text into one of the following emotion categories: \n",
      "\"anger\" | \"fear\" | \"joy\" | \"sadness\"\n",
      "    \n",
      "\n",
      "Examples: \n",
      "Text: As your own lives in order to complete our amazing life journey successfully, it is there. \n",
      "Class: anger\n",
      "\n",
      "Text: the bee sting still suck i feel sick\n",
      "Class: anger\n",
      "\n",
      "Text: @PerfectQuartz She's jogging a bit to stay beside her, puffing her cheeks with a huff each time. 'Oh-- jeez Jasper, why don't you \n",
      "Class: anger\n",
      "\n",
      "Text: @kingvee_ don't provoke me to anger\n",
      "Class: anger\n",
      "\n",
      "Text: I blame the whole season on Natalie! The season would have been so different had she not turned her back on her alliance! #pissed \n",
      "Class: anger\n",
      "\n",
      "Text: It's 5:55am. I'm hungry but there is no food. \n",
      "Class: fear\n",
      "\n",
      "Text: Watched tna for the first time in a long time what the hell happened to the #hardyboys #impactonpop #wwe #terrible\n",
      "Class: fear\n",
      "\n",
      "Text: #NawazSharif says lets end #terror. Sure, let #IndianArmedForces target the bases without #Pakistan interference #Karma?\n",
      "Class: fear\n",
      "\n",
      "Text: nadia bully me and ill expose you\n",
      "Class: fear\n",
      "\n",
      "Text: the ending of how I met your mother is dreadful\n",
      "Class: fear\n",
      "\n",
      "Text: When something makes you excited, terrified, thrilled, nervous, elated &amp; like you've been kicked in the guts all at once. Need word for that\n",
      "Class: joy\n",
      "\n",
      "Text: A good thing about being sick is that coughing is like an ab workout. Maybe my abs will be more defined by the time I'm better  #optimism\n",
      "Class: joy\n",
      "\n",
      "Text: @BbeautifulSoul_ u always gotta attitude tho ...  cheer up\n",
      "Class: joy\n",
      "\n",
      "Text: Watch this amazing live.ly broadcast by @rosannahill #lively #musically\n",
      "Class: joy\n",
      "\n",
      "Text: @aradsliff don't know I'm from nj we are the worst on purpose. \n",
      "Class: joy\n",
      "\n",
      "Text: @BlurtAlerts 'the darkest of nights can be bright, the solemn of faces lights up with a smile'. -@Totemprince believe in me, as I do in you\n",
      "Class: sadness\n",
      "\n",
      "Text: Don't wanna go to work but I want the money \n",
      "Class: sadness\n",
      "\n",
      "Text: @DeltaAssist Tried 2 get earlier flt 2day  @BWI Turnd away bcuz it was 2 late Then agent let other pas on #silvereliteleftbehind \n",
      "Class: sadness\n",
      "\n",
      "Text: If anybody needs me I'll be drowning my blues in a sea of whiskey \n",
      "Class: sadness\n",
      "\n",
      "Text: Fucking gutted, disheartened &amp; so pissed off.Gone from 1 off the toughest most resolute defences to the worst &amp; most shambolic #SCFC #STOHUL\n",
      "Class: sadness\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: anger...:  55%|    | 11/20 [00:09<00:08,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 42.263369665s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '42s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 42.209380782s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '42s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Taking umbrage because Jimmy Carr claimed that Bilbo Baggins went to Mordor on 8 out of 10 cats does Countdown. Know your Baggins', mate.\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 27.082812164s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '27s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 27.02754191s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '27s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Taking umbrage because Jimmy Carr claimed that Bilbo Baggins went to Mordor on 8 out of 10 cats does Countdown. Know your Baggins', mate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: anger...:  75%|  | 15/20 [00:44<00:20,  4.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 15.89 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: anger...: 100%|| 20/20 [01:04<00:00,  3.23s/it]\n",
      "Processing samples for emotion: fear...:  35%|      | 7/20 [00:06<00:12,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 40.783779316s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '40s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 40.725027561s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '40s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: The Apocalypse has hit our gym and it's  nothing what I thought it would be...\\n\\nEveryone is wearing vests! What if it's contagious? \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: fear...:  50%|     | 10/20 [00:24<00:31,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 30.88 seconds.\n",
      "Error occurred when generating response, error: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Error occurred when generating response, error: [Errno 11001] getaddrinfo failed\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Honestly, there are some awful people on the internet... smh...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: fear...: 100%|| 20/20 [55:06<00:00, 165.32s/it]   \n",
      "Processing samples for emotion: joy...:  30%|       | 6/20 [00:05<00:13,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 35.889518295s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '35s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 35.726142456s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '35s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: It feels good to get outside for a minute and get some fresh air.  It's hard to stay cooped up inside all day \n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 20.557047935s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '20s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 20.490062108s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '20s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: It feels good to get outside for a minute and get some fresh air.  It's hard to stay cooped up inside all day \n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 5.31389606s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '5s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 5.238835101s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '5s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: It feels good to get outside for a minute and get some fresh air.  It's hard to stay cooped up inside all day \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: joy...: 100%|| 20/20 [01:02<00:00,  3.13s/it]\n",
      "Processing samples for emotion: sadness...:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 1.64 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: sadness...:  10%|         | 2/20 [00:03<00:27,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 35.35888737s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '35s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 35.283308276s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '35s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Should of stayed in Dubai \n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 20.15926496s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '20s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 20.095546421s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '20s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Should of stayed in Dubai \n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 4.951951352s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '4s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 4.889217387s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '4s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Should of stayed in Dubai \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: sadness...:  75%|  | 15/20 [00:59<00:04,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 2.49 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: sadness...:  90%| | 18/20 [01:04<00:02,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 34.243485501s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '34s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 34.152776547s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '34s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Folk Band 'Thistle Down' will be replaced by 'The Paul Edwards Quartet' at Laurel Bank Park Sat 24 11am - 3pm due to ill health #jazz #blues\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 19.022541279s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '19s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 18.953373244s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '18s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Folk Band 'Thistle Down' will be replaced by 'The Paul Edwards Quartet' at Laurel Bank Park Sat 24 11am - 3pm due to ill health #jazz #blues\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 3.822765908s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '3s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 3.752496494s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '3s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Folk Band 'Thistle Down' will be replaced by 'The Paul Edwards Quartet' at Laurel Bank Park Sat 24 11am - 3pm due to ill health #jazz #blues\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: sadness...: 100%|| 20/20 [01:51<00:00,  5.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results saved to ./results/llm_classification_results/results_samples_20_shots_5.csv\n",
      "Accuracy: 56.25%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.55      0.60      0.57        20\n",
      "        fear       0.60      0.30      0.40        20\n",
      "         joy       0.58      0.75      0.65        20\n",
      "     sadness       0.55      0.60      0.57        20\n",
      "\n",
      "    accuracy                           0.56        80\n",
      "   macro avg       0.57      0.56      0.55        80\n",
      "weighted avg       0.57      0.56      0.55        80\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# If you see '429 RESOURCE_EXHAUSTED' errors it's fine, wait until the data gets processed, it will keep retrying until it finishes\n",
    "\n",
    "# Example of running the experiment with 5-shot prompting\n",
    "run_experiment(train_df, test_df, num_test_samples=20, num_shots=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### <a id='toc1_5_10_1_1_'></a>[**>>> Exercise 6 (Take home):**](#toc0_)\n",
    "\n",
    "Compare and discuss the overall results of the zero-shot, 1-shot and 5-shot classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer here\n",
    "\n",
    "- **Few-shot > Zero-shot**: Providing examples improves accuracy. Both 1-shot (57.5%) and 5-shot (56.25%) outperformed Zero-shot (52.5%), confirming that context aids the model.\n",
    "\n",
    "- **Quality over Quantity**: Surprisingly, 1-shot performed better than 5-shot. This suggests that adding more examples can sometimes introduce noise or yield diminishing returns.\n",
    "\n",
    "- **Consistent Class Difficulty**: Across all methods, \"Joy\" was consistently the easiest to detect (high recall), while \"Fear\" remained the most challenging (low recall)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### <a id='toc1_5_10_1_2_'></a>[**>>> Exercise 7 (Take home):**](#toc0_)\n",
    "\n",
    "**Case Study:** Check the results' files inside the `results/llm_classification_results` directory and find cases where the **text classification improves with more examples** (pred emotion is right with examples), **cases where it does not improve** (pred emotion always wrong) and **cases where the classification got worse with more examples** (pred emotion goes from right to wrong with examples). For this you need to load the results with pandas and handle the data using its dataframe functions. Discuss about the findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Case A: Improvement (Better with Examples) (Total: 6)\n",
      "============================================================\n",
      " Text: @LiamCannon1 He's just too raging to type properly... Ha ha!\n",
      "   True Label: anger\n",
      "   Pred (0-shot): joy\n",
      "   Pred (1-shot): anger\n",
      "   Pred (5-shot): anger\n",
      "------------------------------\n",
      " Text: @ArcticFantasy I would have almost took offense to this if I actually snapped you\n",
      "   True Label: anger\n",
      "   Pred (0-shot): joy\n",
      "   Pred (1-shot): anger\n",
      "   Pred (5-shot): anger\n",
      "------------------------------\n",
      " Text: The moment you bring her to meet your best friend and you're nervous af!   #thefriendtest\n",
      "   True Label: fear\n",
      "   Pred (0-shot): joy\n",
      "   Pred (1-shot): fear\n",
      "   Pred (5-shot): fear\n",
      "------------------------------\n",
      "\n",
      "============================================================\n",
      "Case B: No Improvement (Always Wrong) (Total: 32)\n",
      "============================================================\n",
      " Text: Ananya just grabbed a bible, opened it, started reading, and then said 'where do they talk about burning people?'\n",
      "   True Label: anger\n",
      "   Pred (0-shot): fear\n",
      "   Pred (1-shot): fear\n",
      "   Pred (5-shot): fear\n",
      "------------------------------\n",
      " Text: For the first time in my madden career I just set up a farm account. Should make MOTM much easier\n",
      "   True Label: anger\n",
      "   Pred (0-shot): joy\n",
      "   Pred (1-shot): joy\n",
      "   Pred (5-shot): joy\n",
      "------------------------------\n",
      " Text: Everybody talking about 'the first day of fall' but summer '16 is never gonna die #revenge @Drake\n",
      "   True Label: anger\n",
      "   Pred (0-shot): joy\n",
      "   Pred (1-shot): joy\n",
      "   Pred (5-shot): joy\n",
      "------------------------------\n",
      "\n",
      "============================================================\n",
      "Case C: Degradation (Worse with Examples) (Total: 3)\n",
      "============================================================\n",
      " Text: Sting is just too damn earnest for early morning listening. #sting\n",
      "   True Label: anger\n",
      "   Pred (0-shot): anger\n",
      "   Pred (1-shot): anger\n",
      "   Pred (5-shot): sadness\n",
      "------------------------------\n",
      " Text: @RealJamesWoods @KennyCoble saddest part of this whole mess is that all of this #anger is #misdirected they should march 2 the #WhiteHouse\n",
      "   True Label: anger\n",
      "   Pred (0-shot): anger\n",
      "   Pred (1-shot): anger\n",
      "   Pred (5-shot): sadness\n",
      "------------------------------\n",
      " Text: How can l rule my mind !!!!!! \\nIt's hilarious that you can't \n",
      "   True Label: joy\n",
      "   Pred (0-shot): joy\n",
      "   Pred (1-shot): sadness\n",
      "   Pred (5-shot): sadness\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Answer here\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Set file paths\n",
    "base_dir = \"./results/llm_classification_results\"\n",
    "file_0shot = f\"{base_dir}/results_samples_20_shots_0.csv\"\n",
    "file_1shot = f\"{base_dir}/results_samples_20_shots_1.csv\"\n",
    "file_5shot = f\"{base_dir}/results_samples_20_shots_5.csv\"\n",
    "\n",
    "# Check if files exist\n",
    "if not all(os.path.exists(f) for f in [file_0shot, file_1shot, file_5shot]):\n",
    "    print(\"Error: Result files not found. Please run the experiment first.\")\n",
    "else:\n",
    "    # Load data\n",
    "    df0 = pd.read_csv(file_0shot)\n",
    "    df1 = pd.read_csv(file_1shot)\n",
    "    df5 = pd.read_csv(file_5shot)\n",
    "\n",
    "    # Rename columns for merging\n",
    "    df0 = df0.rename(columns={'predicted_emotion': 'pred_0shot'})\n",
    "    df1 = df1[['text', 'predicted_emotion']].rename(columns={'predicted_emotion': 'pred_1shot'})\n",
    "    df5 = df5[['text', 'predicted_emotion']].rename(columns={'predicted_emotion': 'pred_5shot'})\n",
    "\n",
    "    # Merge dataframes based on text\n",
    "    merged_df = pd.merge(df0, df1, on='text')\n",
    "    merged_df = pd.merge(merged_df, df5, on='text')\n",
    "\n",
    "    # Function to print case studies\n",
    "    def print_case_study(title, df_case):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"{title} (Total: {len(df_case)})\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        if df_case.empty:\n",
    "            print(\"No cases found matching this criteria.\")\n",
    "            return\n",
    "\n",
    "        # Print top 3 examples\n",
    "        for index, row in df_case.head(3).iterrows():\n",
    "            print(f\" Text: {row['text']}\")\n",
    "            print(f\"   True Label: {row['true_emotion']}\")\n",
    "            print(f\"   Pred (0-shot): {row['pred_0shot']}\")\n",
    "            print(f\"   Pred (1-shot): {row['pred_1shot']}\")\n",
    "            print(f\"   Pred (5-shot): {row['pred_5shot']}\")\n",
    "            print(\"-\" * 30)\n",
    "\n",
    "    # Case A: Improvement (0-shot wrong -> 5-shot correct)\n",
    "    improved_df = merged_df[\n",
    "        (merged_df['pred_0shot'] != merged_df['true_emotion']) & \n",
    "        (merged_df['pred_5shot'] == merged_df['true_emotion'])\n",
    "    ]\n",
    "    print_case_study(\"Case A: Improvement (Better with Examples)\", improved_df)\n",
    "\n",
    "    # Case B: Consistent Failure (All wrong)\n",
    "    hopeless_df = merged_df[\n",
    "        (merged_df['pred_0shot'] != merged_df['true_emotion']) & \n",
    "        (merged_df['pred_1shot'] != merged_df['true_emotion']) &\n",
    "        (merged_df['pred_5shot'] != merged_df['true_emotion'])\n",
    "    ]\n",
    "    print_case_study(\"Case B: No Improvement (Always Wrong)\", hopeless_df)\n",
    "\n",
    "    # Case C: Degradation (0-shot correct -> 5-shot wrong)\n",
    "    worse_df = merged_df[\n",
    "        (merged_df['pred_0shot'] == merged_df['true_emotion']) & \n",
    "        (merged_df['pred_5shot'] != merged_df['true_emotion'])\n",
    "    ]\n",
    "    print_case_study(\"Case C: Degradation (Worse with Examples)\", worse_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <a id='toc1_5_11_'></a>[**2.7 Extra LLM Related Materials:**](#toc0_)\n",
    "So this will be it for the lab, but here are some extra materials if you would like to explore:\n",
    "\n",
    "- **How to use OpenAI ChatGPT model's API (Not Free API):** [Basics Video](https://www.youtube.com/watch?v=e9P7FLi5Zy8), [Basics GitHub](https://github.com/gkamradt/langchain-tutorials/blob/main/chatapi/ChatAPI%20%2B%20LangChain%20Basics.ipynb), [RAG's Basics Video](https://www.youtube.com/watch?v=9AXP7tCI9PI&t=300s), [RAG's Basics GitHub](https://github.com/techleadhd/chatgpt-retrieval)\n",
    "\n",
    "- **Advanced topic - QLoRA (Quantized Low-Rank Adapter):** QLoRA is a method used to make fine-tuning large language models more efficient. It works by adding a small, trainable part (LoRA) to a pre-trained model, while keeping the rest of the model frozen. At the same time, it reduces the size of the models data using a process called quantization, which makes the model require less memory. This allows you to fine-tune large models without needing as much computational power, making it easier to adapt models for specific tasks. Materials: [Paper GitHub](https://github.com/artidoro/qlora?tab=readme-ov-file), [Llama 3 Application Video](https://www.youtube.com/watch?v=YJNbgusTSF0&t=512s),[Llama 3 Application GitHub](https://github.com/adidror005/youtube-videos/blob/main/LLAMA_3_Fine_Tuning_for_Sequence_Classification_Actual_Video.ipynb)\n",
    "\n",
    "- **How to Fine-tune and run local LLMs with the `unsloth` library:** [unsloth tutorials](https://docs.unsloth.ai/models/tutorials-how-to-fine-tune-and-run-llms)\n",
    "\n",
    "- **Google's Agent Development Kit Documentation:** [ADK](https://google.github.io/adk-docs/)\n",
    "\n",
    "- **Build AI agents with LangGraph:** [LangGraph Documentation](https://langchain-ai.github.io/langgraph/concepts/why-langgraph/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_fF1woa8YTp5"
   },
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "4e5eiVLOYTp5"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "DM_Lab_GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 594.85,
   "position": {
    "height": "40px",
    "left": "723px",
    "right": "20px",
    "top": "80px",
    "width": "250px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
