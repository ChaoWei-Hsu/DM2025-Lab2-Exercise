{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Student Information**\n",
    "Name: Ë®±ÊôÅÁëã\n",
    "\n",
    "Student ID: NCCU 113351046\n",
    "\n",
    "GitHub ID: ChaoWei-Hsu\n",
    "\n",
    "Kaggle name: Chao-Wei Hsu\n",
    "\n",
    "Kaggle private scoreboard snapshot: \n",
    "\n",
    "![kaggle.png](./pics/kaggle.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Instructions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab we have divided the assignments into **three phases/parts**. The `first two phases` refer to the `exercises inside the Master notebooks` of the [DM2025-Lab2-Exercise Repo](https://github.com/difersalest/DM2025-Lab2-Exercise.git). The `third phase` refers to an `internal Kaggle competition` that we are gonna run among all the Data Mining students. Together they add up to `100 points` of your grade. There are also some `bonus points` to be gained if you complete `extra exercises` in the lab **(bonus 15 pts)** and in the `Kaggle Competition report` **(bonus 5 pts)**.\n",
    "\n",
    "**Environment recommendations to solve lab 2:**\n",
    "- **Phase 1 exercises:** Need GPU for training the models explained in that part, if you don't have a GPU in your laptop it is recommended to run in Colab or Kaggle for a faster experience, although with CPU they can still be solved but with a slower execution.\n",
    "- **Phase 2 exercises:** We use Gemini's API so everything can be run with only CPU without a problem.\n",
    "- **Phase 3 exercises:** For the competition you will probably need GPU to train your models, so it is recommended to use Colab or Kaggle if you don't have a laptop with a dedicated GPU.\n",
    "- **Optional Ollama Notebook (not graded):** You need GPU, at least 4GB of VRAM with 16 GB of RAM to run the local open-source LLM models. \n",
    "\n",
    "## **Phase 1 (30 pts):**\n",
    "\n",
    "1. __Main Exercises (25 pts):__ Do the **take home exercises** from Sections: `1. Data Preparation` to `9. High-dimension Visualization: t-SNE and UMAP`, in the [DM2025-Lab2-Master-Phase_1 Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_1.ipynb). Total: `8 exercises`. Commit your code and submit the repository link to NTU Cool **`BEFORE the deadline (Nov. 3th, 11:59 pm, Monday)`**\n",
    "\n",
    "2. **Code Comments (5 pts):** **Tidy up the code in your notebook**. \n",
    "\n",
    "## **Phase 2 (30 pts):**\n",
    "\n",
    "1. **Main Exercises (25 pts):** Do the remaining **take home exercises** from Section: `2. Large Language Models (LLMs)` in the [DM2025-Lab2-Master-Phase_2_Main Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_2_Main.ipynb). Total: `5 exercises required from sections 2.1, 2.2, 2.4 and 2.6`. Commit your code and submit the repository link to NTU Cool **`BEFORE the deadline (Nov. 24th, 11:59 pm, Monday)`**\n",
    "\n",
    "2. **Code Comments (5 pts):** **Tidy up the code in your notebook**. \n",
    "\n",
    "3. **`Bonus (15 pts):`** Complete the bonus exercises in the [DM2025-Lab2-Master-Phase_2_Bonus Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_2_Bonus.ipynb) and [DM2025-Lab2-Master-Phase_2_Main Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_2_Main.ipynb) `where 2 exercises are counted as bonus from sections 2.3 and 2.5 in the main notebook`. Total: `7 exercises`. Commit your code and submit the repository link to NTU Cool **`BEFORE the deadline (Nov. 24th, 11:59 pm, Monday)`**\n",
    "\n",
    "## **Phase 3 (40 pts):**\n",
    "\n",
    "1. **Kaggle Competition Participation (30 pts):** Participate in the in-class **Kaggle Competition** regarding Emotion Recognition on Twitter by clicking in this link: **[Data Mining Class Kaggle Competition](https://www.kaggle.com/t/3a2df4c6d6b4417e8bf718ed648d7554)**. The scoring will be given according to your place in the Private Leaderboard ranking: \n",
    "    - **Bottom 40%**: Get 20 pts of the 30 pts in this competition participation part.\n",
    "\n",
    "    - **Top 41% - 100%**: Get (0.6N + 1 - x) / (0.6N) * 10 + 20 points, where N is the total number of participants, and x is your rank. (ie. If there are 100 participants and you rank 3rd your score will be (0.6 * 100 + 1 - 3) / (0.6 * 100) * 10 + 20 = 29.67% out of 30%.)   \n",
    "    Submit your last submission **`BEFORE the deadline (Nov. 24th, 11:59 pm, Monday)`**. Make sure to take a screenshot of your position at the end of the competition and store it as `pic_ranking.png` under the `pics` folder of this repository and rerun the cell **Student Information**.\n",
    "\n",
    "2. **Competition Report (10 pts)** A report section to be filled in inside this notebook in Markdown Format, we already provided you with the template below. You need to describe your work developing the model for the competition. The report should include a section describing briefly the following elements: \n",
    "* Your preprocessing steps.\n",
    "* The feature engineering steps.\n",
    "* Explanation of your model.\n",
    "\n",
    "* **`Bonus (5 pts):`**\n",
    "    * You will have to describe more detail in the previous steps.\n",
    "    * Mention different things you tried.\n",
    "    * Mention insights you gained. \n",
    "\n",
    "[Markdown Guide - Basic Syntax](https://www.markdownguide.org/basic-syntax/)\n",
    "\n",
    "**`Things to note for Phase 3:`**\n",
    "\n",
    "* **The code used for the competition should be in this Jupyter Notebook File** `DM2025-Lab2-Homework.ipynb`.\n",
    "\n",
    "* **Push the code used for the competition to your repository**.\n",
    "\n",
    "* **The code should have a clear separation for the same sections of the report, preprocessing, feature engineering and model explanation. Briefly comment your code for easier understanding, we provide a template at the end of this notebook.**\n",
    "\n",
    "* Showing the kaggle screenshot of the ranking plus the code in this notebook will ensure the validity of your participation and the report to obtain the corresponding points.\n",
    "\n",
    "After the competition ends you will have two days more to submit the `DM2025-Lab2-Homework.ipynb` with your report in markdown format and your code. Do everything **`BEFORE the deadline (Nov. 26th, 11:59 pm, Wednesday) to obtain 100% of the available points.`**\n",
    "\n",
    "Upload your files to your repository then submit the link to it on the corresponding NTU Cool assignment.\n",
    "\n",
    "## **Deadlines:**\n",
    "\n",
    "![lab2_deadlines](./pics/lab2_deadlines.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`From here on starts the code section for the competition.`**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Competition Code**\n",
    "\n",
    "## 1. Preprocessing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0+cu126\n",
      "12.6\n",
      "True\n",
      "NVIDIA GeForce RTX 4070 SUPER\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Step 1: Data Preprocessing ============\n",
      "Train set size: 47890\n",
      "Test set size: 16281\n",
      "\n",
      "--- Emotion Distribution ---\n",
      "          Count  Percentage (%)\n",
      "emotion                        \n",
      "joy       23797           49.69\n",
      "anger     10694           22.33\n",
      "surprise   6281           13.12\n",
      "sadness    3926            8.20\n",
      "fear       2009            4.20\n",
      "disgust    1183            2.47\n",
      "\n",
      "--- Sample Output ---\n",
      "                                                                                                   text  \\\n",
      "14  Rap that will Cut other raper's throat. Who said that? @Paedeezy #badd #wicked. #bright city lights   \n",
      "15                She‚Äôs a good person who stands up for people not like her, and they can‚Äôt stand that.   \n",
      "16                            Okay I can see this looking really cool for a festival or photos though üòÑ   \n",
      "17                                     I do but I like my job. I just hate the fact I HAVE to go do it.   \n",
      "\n",
      "                                                                                                 text_cleaned  \n",
      "14            Rap that will Cut other raper's throat. Who said that? @user #badd #wicked. #bright city lights  \n",
      "15                      She‚Äôs a good person who stands up for people not like her, and they can‚Äôt stand that.  \n",
      "16  Okay I can see this looking really cool for a festival or photos though  grinning_face_with_smiling_eyes   \n",
      "17                                           I do but I like my job. I just hate the fact I HAVE to go do it.  \n",
      "\n",
      "=== Step 1 Complete! =============================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "import emoji\n",
    "\n",
    "# --- Configuration ---\n",
    "PATH_JSON = \"C:/Users/User/Desktop/Paper/kaggle/dm-lab-2-private-competition/final_posts.json\"\n",
    "PATH_SPLIT = \"C:/Users/User/Desktop/Paper/kaggle/dm-lab-2-private-competition/data_identification.csv\"\n",
    "PATH_EMOTION = \"C:/Users/User/Desktop/Paper/kaggle/dm-lab-2-private-competition/emotion.csv\"\n",
    "PATH_SUBMISSION = \"submission.csv\"\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Normalize user mentions\n",
    "    text = re.sub(r'@\\w+', '@user', text)\n",
    "    # Convert emojis to text description\n",
    "    text = emoji.demojize(text, delimiters=(\" \", \" \"))\n",
    "    \n",
    "    return text\n",
    "\n",
    "print(\"=== Step 1: Data Preprocessing ============\")\n",
    "\n",
    "# --- Load Data ---\n",
    "\n",
    "# Load JSON\n",
    "with open(PATH_JSON, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Extract nested post data\n",
    "post_data = []\n",
    "for item in data:\n",
    "    post = item.get('root', {}).get('_source', {}).get('post', {})\n",
    "    if post:\n",
    "        post_data.append({\n",
    "            'id': post.get('post_id'),\n",
    "            'text': post.get('text')\n",
    "        })\n",
    "df_posts = pd.DataFrame(post_data)\n",
    "\n",
    "# Load CSVs\n",
    "df_split = pd.read_csv(PATH_SPLIT, sep=',')\n",
    "df_emotion = pd.read_csv(PATH_EMOTION, sep=',')\n",
    "\n",
    "# --- Merge & Clean ---\n",
    "\n",
    "# Merge datasets\n",
    "df_merged = pd.merge(df_posts, df_split, on='id', how='left')\n",
    "df_merged = pd.merge(df_merged, df_emotion, on='id', how='left')\n",
    "\n",
    "# Handle missing values\n",
    "df_merged = df_merged.dropna(subset=['text'])\n",
    "df_merged['text'] = df_merged['text'].astype(str)\n",
    "\n",
    "# Apply text preprocessing\n",
    "df_merged['text_cleaned'] = df_merged['text'].apply(preprocess_text)\n",
    "\n",
    "# --- Split Data ---\n",
    "df_train_full = df_merged[df_merged['split'] == 'train'].copy()\n",
    "df_test = df_merged[df_merged['split'] == 'test'].copy()\n",
    "\n",
    "print(f\"Train set size: {len(df_train_full)}\")\n",
    "print(f\"Test set size: {len(df_test)}\")\n",
    "\n",
    "# --- Analysis ---\n",
    "print(\"\\n--- Emotion Distribution ---\")\n",
    "if 'emotion' in df_train_full.columns:\n",
    "    distribution_df = pd.DataFrame({\n",
    "        'Count': df_train_full['emotion'].value_counts(),\n",
    "        'Percentage (%)': (df_train_full['emotion'].value_counts(normalize=True) * 100).round(2)\n",
    "    })\n",
    "    print(distribution_df)\n",
    "else:\n",
    "    print(\"[Error] 'emotion' column missing.\")\n",
    "\n",
    "# --- Verification ---\n",
    "print(\"\\n--- Sample Output ---\")\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(df_merged[['text', 'text_cleaned']].iloc[14:18])\n",
    "\n",
    "print(\"\\n=== Step 1 Complete! =============================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Step 1: Data Preprocessing & Augmentation ============\n",
      "Original Train set size: 47890\n",
      "\n",
      "--- Applying Minority Oversampling ---\n",
      "Target sample count per class: 2967\n",
      "Augmented Train set size: 50632\n",
      "All classes after augmentation:\n",
      "emotion\n",
      "joy         23797\n",
      "anger       10694\n",
      "surprise     6281\n",
      "sadness      3926\n",
      "fear         2967\n",
      "disgust      2967\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Emotion Distribution ---\n",
      "emotion\n",
      "joy         0.469999\n",
      "anger       0.211210\n",
      "surprise    0.124052\n",
      "sadness     0.077540\n",
      "fear        0.058599\n",
      "disgust     0.058599\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "=== Step 1 Complete!  ===================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "import emoji\n",
    "\n",
    "# --- Configuration ---\n",
    "PATH_JSON = \"C:/Users/User/Desktop/Paper/kaggle/dm-lab-2-private-competition/final_posts.json\"\n",
    "PATH_SPLIT = \"C:/Users/User/Desktop/Paper/kaggle/dm-lab-2-private-competition/data_identification.csv\"\n",
    "PATH_EMOTION = \"C:/Users/User/Desktop/Paper/kaggle/dm-lab-2-private-competition/emotion.csv\"\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = re.sub(r'@\\w+', '@user', text)\n",
    "    text = emoji.demojize(text, delimiters=(\" \", \" \"))\n",
    "    return text\n",
    "\n",
    "print(\"=== Step 1: Data Preprocessing & Augmentation ============\")\n",
    "\n",
    "# --- Load Data ---\n",
    "with open(PATH_JSON, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "post_data = [{'id': item['root']['_source']['post']['post_id'], 'text': item['root']['_source']['post']['text']} \n",
    "             for item in data if item.get('root', {}).get('_source', {}).get('post', {})]\n",
    "df_posts = pd.DataFrame(post_data)\n",
    "\n",
    "df_split = pd.read_csv(PATH_SPLIT, sep=',')\n",
    "df_emotion = pd.read_csv(PATH_EMOTION, sep=',')\n",
    "\n",
    "# --- Merge & Clean ---\n",
    "df_merged = pd.merge(df_posts, df_split, on='id', how='left')\n",
    "df_merged = pd.merge(df_merged, df_emotion, on='id', how='left')\n",
    "df_merged = df_merged.dropna(subset=['text'])\n",
    "df_merged['text'] = df_merged['text'].astype(str)\n",
    "df_merged['text_cleaned'] = df_merged['text'].apply(preprocess_text)\n",
    "\n",
    "# --- Split Data ---\n",
    "df_train_raw = df_merged[df_merged['split'] == 'train'].copy()\n",
    "df_test = df_merged[df_merged['split'] == 'test'].copy()\n",
    "\n",
    "print(f\"Original Train set size: {len(df_train_raw)}\")\n",
    "\n",
    "# --- Data Augmentation ---\n",
    "print(\"\\n--- Applying Minority Oversampling ---\")\n",
    "\n",
    "class_counts = df_train_raw['emotion'].value_counts()\n",
    "target_count = int(class_counts.quantile(0.3))\n",
    "print(f\"Target sample count per class: {target_count}\")\n",
    "\n",
    "dfs_augmented = []\n",
    "\n",
    "for emotion, count in class_counts.items():\n",
    "    df_class = df_train_raw[df_train_raw['emotion'] == emotion]\n",
    "    \n",
    "    if count < target_count:\n",
    "        df_class_over = resample(df_class, \n",
    "                                 replace=True, \n",
    "                                 n_samples=target_count, \n",
    "                                 random_state=42)\n",
    "        dfs_augmented.append(df_class_over)\n",
    "    else:\n",
    "        dfs_augmented.append(df_class)\n",
    "\n",
    "df_train_full = pd.concat(dfs_augmented).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(f\"Augmented Train set size: {len(df_train_full)}\")\n",
    "print(\"All classes after augmentation:\")\n",
    "print(df_train_full['emotion'].value_counts()) \n",
    "\n",
    "# --- Analysis ---\n",
    "print(\"\\n--- Emotion Distribution ---\")\n",
    "if 'emotion' in df_train_full.columns:\n",
    "    print(df_train_full['emotion'].value_counts(normalize=True))\n",
    "\n",
    "print(\"\\n=== Step 1 Complete!  ===================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Step 2: Feature Engineering (7-Model Ensemble) =========\n",
      "\n",
      "Encoding Labels...\n",
      "Num Classes: 6\n",
      "\n",
      "--- Creating Validation Split ---\n",
      "Train samples: 30379, Validation samples: 20253\n",
      "\n",
      "------------------------------------------------------\n",
      "Processing Model: BERT (monologg/bert-base-cased-goemotions-original)\n",
      "------------------------------------------------------\n",
      "Tokenizing...\n",
      "Saving to preprocessed_bert.pt...\n",
      "\n",
      "------------------------------------------------------\n",
      "Processing Model: ROBERTA (SamLowe/roberta-base-go_emotions)\n",
      "------------------------------------------------------\n",
      "Tokenizing...\n",
      "Saving to preprocessed_roberta.pt...\n",
      "\n",
      "------------------------------------------------------\n",
      "Processing Model: TWITTER_ROBERTA (cardiffnlp/twitter-roberta-base-emotion)\n",
      "------------------------------------------------------\n",
      "Tokenizing...\n",
      "Saving to preprocessed_twitter_roberta.pt...\n",
      "\n",
      "------------------------------------------------------\n",
      "Processing Model: DISTILBERT_STUDENT (joeddav/distilbert-base-uncased-go-emotions-student)\n",
      "------------------------------------------------------\n",
      "Tokenizing...\n",
      "Saving to preprocessed_distilbert_student.pt...\n",
      "\n",
      "------------------------------------------------------\n",
      "Processing Model: DISTIL_EMOTION (j-hartmann/emotion-english-distilroberta-base)\n",
      "------------------------------------------------------\n",
      "Tokenizing...\n",
      "Saving to preprocessed_distil_emotion.pt...\n",
      "\n",
      "------------------------------------------------------\n",
      "Processing Model: BERT_GROUP (monologg/bert-base-cased-goemotions-group)\n",
      "------------------------------------------------------\n",
      "Tokenizing...\n",
      "Saving to preprocessed_bert_group.pt...\n",
      "\n",
      "------------------------------------------------------\n",
      "Processing Model: BERT_EKMAN (monologg/bert-base-cased-goemotions-ekman)\n",
      "------------------------------------------------------\n",
      "Tokenizing...\n",
      "Saving to preprocessed_bert_ekman.pt...\n",
      "\n",
      "=== Step 2 Complete! All 7 datasets prepared. ====\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# --- Configuration List (7-Model Ensemble) ---\n",
    "print(\"\\n=== Step 2: Feature Engineering (7-Model Ensemble) =========\\n\")\n",
    "\n",
    "MODEL_CONFIGS = [\n",
    "    # 1. BERT Original\n",
    "    {\"name\": \"bert\",             \"model_id\": \"monologg/bert-base-cased-goemotions-original\"},\n",
    "    \n",
    "    # 2. RoBERTa\n",
    "    {\"name\": \"roberta\",          \"model_id\": \"SamLowe/roberta-base-go_emotions\"},\n",
    "    \n",
    "    # 3. Twitter RoBERTa\n",
    "    {\"name\": \"twitter_roberta\",  \"model_id\": \"cardiffnlp/twitter-roberta-base-emotion\"},\n",
    "    \n",
    "    # 4. DistilBERT Student\n",
    "    {\"name\": \"distilbert_student\", \"model_id\": \"joeddav/distilbert-base-uncased-go-emotions-student\"},\n",
    "    \n",
    "    # 5. DistilRoBERTa\n",
    "    {\"name\": \"distil_emotion\",   \"model_id\": \"j-hartmann/emotion-english-distilroberta-base\"},\n",
    "    \n",
    "    # 6. BERT Group\n",
    "    {\"name\": \"bert_group\",       \"model_id\": \"monologg/bert-base-cased-goemotions-group\"},\n",
    "    \n",
    "    # 7. BERT Ekman\n",
    "    {\"name\": \"bert_ekman\",       \"model_id\": \"monologg/bert-base-cased-goemotions-ekman\"}\n",
    "]\n",
    "\n",
    "MAX_LENGTH = 64\n",
    "\n",
    "# --- Check Data Availability ---\n",
    "if 'df_train_full' not in locals():\n",
    "    print(\"[Error] 'df_train_full' variable not found.\")\n",
    "    print(\"Please run Step 1 (Data Loading) first, or uncomment the manual loading block below.\")\n",
    "\n",
    "if 'df_train_full' in locals():\n",
    "    # --- Label Encoding ---\n",
    "    print(\"Encoding Labels...\")\n",
    "    label_encoder = LabelEncoder()\n",
    "    df_train_full['emotion_encoded'] = label_encoder.fit_transform(df_train_full['emotion'])\n",
    "    num_classes = len(label_encoder.classes_)\n",
    "    print(f\"Num Classes: {num_classes}\")\n",
    "\n",
    "    # --- Split Data ---\n",
    "    print(\"\\n--- Creating Validation Split ---\")\n",
    "\n",
    "    df_train, df_val = train_test_split(\n",
    "        df_train_full,\n",
    "        test_size=0.4,\n",
    "        random_state=42,\n",
    "        stratify=df_train_full['emotion_encoded']\n",
    "    )\n",
    "\n",
    "    # Extract raw texts\n",
    "    train_texts = df_train['text_cleaned'].tolist()\n",
    "    val_texts = df_val['text_cleaned'].tolist()\n",
    "    test_texts = df_test['text_cleaned'].tolist()\n",
    "\n",
    "    y_train = df_train['emotion_encoded'].values\n",
    "    y_val = df_val['emotion_encoded'].values\n",
    "    test_ids = df_test['id'].values\n",
    "\n",
    "    print(f\"Train samples: {len(train_texts)}, Validation samples: {len(val_texts)}\")\n",
    "\n",
    "    # --- Loop Through Each Model ---\n",
    "    for config in MODEL_CONFIGS:\n",
    "        short_name = config[\"name\"]\n",
    "        model_name = config[\"model_id\"]\n",
    "        output_path = f\"preprocessed_{short_name}.pt\"\n",
    "        \n",
    "        print(f\"\\n------------------------------------------------------\")\n",
    "        print(f\"Processing Model: {short_name.upper()} ({model_name})\")\n",
    "        print(f\"------------------------------------------------------\")\n",
    "\n",
    "        # 1. Load Tokenizer\n",
    "        try:\n",
    "            tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        except OSError as e:\n",
    "            print(f\"[Error] Failed to load tokenizer for {model_name}.\")\n",
    "            continue\n",
    "\n",
    "        # 2. Tokenize\n",
    "        print(\"Tokenizing...\")\n",
    "        train_encodings = tokenizer(train_texts, padding='max_length', truncation=True, max_length=MAX_LENGTH)\n",
    "        val_encodings = tokenizer(val_texts, padding='max_length', truncation=True, max_length=MAX_LENGTH)\n",
    "        test_encodings = tokenizer(test_texts, padding='max_length', truncation=True, max_length=MAX_LENGTH)\n",
    "\n",
    "        # 3. Save Artifacts\n",
    "        print(f\"Saving to {output_path}...\")\n",
    "        data_to_save = {\n",
    "            'train_encodings': train_encodings,\n",
    "            'val_encodings': val_encodings,\n",
    "            'test_encodings': test_encodings,\n",
    "            'y_train': torch.tensor(y_train, dtype=torch.long),\n",
    "            'y_val': torch.tensor(y_val, dtype=torch.long),\n",
    "            'test_ids': test_ids,\n",
    "            'label_encoder': label_encoder,\n",
    "            'num_classes': num_classes,\n",
    "            'MODEL_NAME': model_name,\n",
    "            'SHORT_NAME': short_name\n",
    "        }\n",
    "        \n",
    "        torch.save(data_to_save, output_path)\n",
    "\n",
    "    print(\"\\n=== Step 2 Complete! All 7 datasets prepared. ====\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Implementation Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Step 3: Training 7 Models =========\n",
      "\n",
      "\n",
      "========================================================\n",
      "Loading Data: preprocessed_bert.pt\n",
      "Target Output: ./results_bert\n",
      "========================================================\n",
      "Backbone Model: monologg/bert-base-cased-goemotions-original\n",
      "Loading Model Weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/bert-base-cased-goemotions-original and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([28, 768]) in the checkpoint and torch.Size([6, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([28]) in the checkpoint and torch.Size([6]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training for monologg/bert-base-cased-goemotions-original...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4000' max='9500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4000/9500 16:49 < 23:09, 3.96 it/s, Epoch 8/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.366800</td>\n",
       "      <td>1.332194</td>\n",
       "      <td>0.111009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.924100</td>\n",
       "      <td>0.880230</td>\n",
       "      <td>0.219410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.721600</td>\n",
       "      <td>0.669033</td>\n",
       "      <td>0.488438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.610300</td>\n",
       "      <td>0.590577</td>\n",
       "      <td>0.556133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.608000</td>\n",
       "      <td>0.562402</td>\n",
       "      <td>0.569779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.535200</td>\n",
       "      <td>0.552861</td>\n",
       "      <td>0.575040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.571500</td>\n",
       "      <td>0.536539</td>\n",
       "      <td>0.582628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.544600</td>\n",
       "      <td>0.524449</td>\n",
       "      <td>0.594941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.552500</td>\n",
       "      <td>0.515638</td>\n",
       "      <td>0.592872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.520600</td>\n",
       "      <td>0.510535</td>\n",
       "      <td>0.599396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.474200</td>\n",
       "      <td>0.501701</td>\n",
       "      <td>0.608575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.467400</td>\n",
       "      <td>0.501032</td>\n",
       "      <td>0.615362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.432900</td>\n",
       "      <td>0.497175</td>\n",
       "      <td>0.617307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.491800</td>\n",
       "      <td>0.476873</td>\n",
       "      <td>0.627019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.397000</td>\n",
       "      <td>0.489404</td>\n",
       "      <td>0.627451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.358300</td>\n",
       "      <td>0.484221</td>\n",
       "      <td>0.638463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.405900</td>\n",
       "      <td>0.469354</td>\n",
       "      <td>0.648758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.396900</td>\n",
       "      <td>0.479027</td>\n",
       "      <td>0.649483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.401900</td>\n",
       "      <td>0.473474</td>\n",
       "      <td>0.648205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.302800</td>\n",
       "      <td>0.491451</td>\n",
       "      <td>0.643064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.337600</td>\n",
       "      <td>0.478944</td>\n",
       "      <td>0.658893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.321100</td>\n",
       "      <td>0.507863</td>\n",
       "      <td>0.639501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.323200</td>\n",
       "      <td>0.471584</td>\n",
       "      <td>0.661244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.286700</td>\n",
       "      <td>0.476756</td>\n",
       "      <td>0.666661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.286500</td>\n",
       "      <td>0.495604</td>\n",
       "      <td>0.659162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500865</td>\n",
       "      <td>0.657091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.272000</td>\n",
       "      <td>0.486168</td>\n",
       "      <td>0.670123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.261000</td>\n",
       "      <td>0.495740</td>\n",
       "      <td>0.665777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.221400</td>\n",
       "      <td>0.506948</td>\n",
       "      <td>0.670978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.219700</td>\n",
       "      <td>0.510892</td>\n",
       "      <td>0.666097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.236500</td>\n",
       "      <td>0.511689</td>\n",
       "      <td>0.670789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.514206</td>\n",
       "      <td>0.670250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.211600</td>\n",
       "      <td>0.510189</td>\n",
       "      <td>0.667089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.172200</td>\n",
       "      <td>0.537699</td>\n",
       "      <td>0.671567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.188100</td>\n",
       "      <td>0.539115</td>\n",
       "      <td>0.676958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.200400</td>\n",
       "      <td>0.540805</td>\n",
       "      <td>0.676187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.186800</td>\n",
       "      <td>0.540252</td>\n",
       "      <td>0.672809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.204200</td>\n",
       "      <td>0.542537</td>\n",
       "      <td>0.674575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.160400</td>\n",
       "      <td>0.574283</td>\n",
       "      <td>0.671425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.137500</td>\n",
       "      <td>0.579865</td>\n",
       "      <td>0.675793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model to ./results_bert...\n",
      "Model monologg/bert-base-cased-goemotions-original Training Complete!\n",
      "\n",
      "\n",
      "========================================================\n",
      "Loading Data: preprocessed_roberta.pt\n",
      "Target Output: ./results_roberta\n",
      "========================================================\n",
      "Backbone Model: SamLowe/roberta-base-go_emotions\n",
      "Loading Model Weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at SamLowe/roberta-base-go_emotions and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.bias: found shape torch.Size([28]) in the checkpoint and torch.Size([6]) in the model instantiated\n",
      "- classifier.out_proj.weight: found shape torch.Size([28, 768]) in the checkpoint and torch.Size([6, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training for SamLowe/roberta-base-go_emotions...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2100' max='19000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 2100/19000 08:13 < 1:06:14, 4.25 it/s, Epoch 2/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.183200</td>\n",
       "      <td>1.158320</td>\n",
       "      <td>0.128024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.977100</td>\n",
       "      <td>0.948592</td>\n",
       "      <td>0.200514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.864600</td>\n",
       "      <td>0.794215</td>\n",
       "      <td>0.282244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.732800</td>\n",
       "      <td>0.695735</td>\n",
       "      <td>0.379248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.634600</td>\n",
       "      <td>0.640131</td>\n",
       "      <td>0.456935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.654100</td>\n",
       "      <td>0.610887</td>\n",
       "      <td>0.503061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.631200</td>\n",
       "      <td>0.586069</td>\n",
       "      <td>0.528112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.595600</td>\n",
       "      <td>0.568564</td>\n",
       "      <td>0.542868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.594400</td>\n",
       "      <td>0.562482</td>\n",
       "      <td>0.547231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.582200</td>\n",
       "      <td>0.555533</td>\n",
       "      <td>0.555559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.526000</td>\n",
       "      <td>0.550923</td>\n",
       "      <td>0.553239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.523100</td>\n",
       "      <td>0.543947</td>\n",
       "      <td>0.553863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.567000</td>\n",
       "      <td>0.541620</td>\n",
       "      <td>0.562253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.610900</td>\n",
       "      <td>0.534818</td>\n",
       "      <td>0.564052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.583400</td>\n",
       "      <td>0.526450</td>\n",
       "      <td>0.559614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.591000</td>\n",
       "      <td>0.524170</td>\n",
       "      <td>0.569343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.517900</td>\n",
       "      <td>0.522263</td>\n",
       "      <td>0.568713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.516135</td>\n",
       "      <td>0.568124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.503300</td>\n",
       "      <td>0.523293</td>\n",
       "      <td>0.568000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.510900</td>\n",
       "      <td>0.534185</td>\n",
       "      <td>0.561740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.534000</td>\n",
       "      <td>0.542108</td>\n",
       "      <td>0.558868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model to ./results_roberta...\n",
      "Model SamLowe/roberta-base-go_emotions Training Complete!\n",
      "\n",
      "\n",
      "========================================================\n",
      "Loading Data: preprocessed_twitter_roberta.pt\n",
      "Target Output: ./results_twitter_roberta\n",
      "========================================================\n",
      "Backbone Model: cardiffnlp/twitter-roberta-base-emotion\n",
      "Loading Model Weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-emotion and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([4, 768]) in the checkpoint and torch.Size([6, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([4]) in the checkpoint and torch.Size([6]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training for cardiffnlp/twitter-roberta-base-emotion...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5900' max='19000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 5900/19000 23:33 < 52:19, 4.17 it/s, Epoch 6/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.139500</td>\n",
       "      <td>1.068083</td>\n",
       "      <td>0.154221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.902200</td>\n",
       "      <td>0.831236</td>\n",
       "      <td>0.198781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.825200</td>\n",
       "      <td>0.759876</td>\n",
       "      <td>0.222678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.756800</td>\n",
       "      <td>0.724465</td>\n",
       "      <td>0.301849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.673200</td>\n",
       "      <td>0.683454</td>\n",
       "      <td>0.390079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.662200</td>\n",
       "      <td>0.656179</td>\n",
       "      <td>0.418916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.690400</td>\n",
       "      <td>0.644646</td>\n",
       "      <td>0.460284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.637600</td>\n",
       "      <td>0.613069</td>\n",
       "      <td>0.482088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.624600</td>\n",
       "      <td>0.611735</td>\n",
       "      <td>0.492689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.614600</td>\n",
       "      <td>0.600768</td>\n",
       "      <td>0.509354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.540800</td>\n",
       "      <td>0.594350</td>\n",
       "      <td>0.521250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.542000</td>\n",
       "      <td>0.588545</td>\n",
       "      <td>0.504715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.582700</td>\n",
       "      <td>0.581771</td>\n",
       "      <td>0.536521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.612400</td>\n",
       "      <td>0.569909</td>\n",
       "      <td>0.536466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.614200</td>\n",
       "      <td>0.554954</td>\n",
       "      <td>0.537659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.609800</td>\n",
       "      <td>0.549765</td>\n",
       "      <td>0.549127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.550842</td>\n",
       "      <td>0.555964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.572700</td>\n",
       "      <td>0.544780</td>\n",
       "      <td>0.544376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.501900</td>\n",
       "      <td>0.552474</td>\n",
       "      <td>0.555238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.544000</td>\n",
       "      <td>0.549751</td>\n",
       "      <td>0.545583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.504900</td>\n",
       "      <td>0.557944</td>\n",
       "      <td>0.549253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.485600</td>\n",
       "      <td>0.542828</td>\n",
       "      <td>0.556198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.535764</td>\n",
       "      <td>0.567775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.498200</td>\n",
       "      <td>0.516536</td>\n",
       "      <td>0.576146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.499900</td>\n",
       "      <td>0.523235</td>\n",
       "      <td>0.571044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.454900</td>\n",
       "      <td>0.563019</td>\n",
       "      <td>0.557506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.453100</td>\n",
       "      <td>0.525560</td>\n",
       "      <td>0.575847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.426500</td>\n",
       "      <td>0.544218</td>\n",
       "      <td>0.575794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.454000</td>\n",
       "      <td>0.554304</td>\n",
       "      <td>0.579613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.447200</td>\n",
       "      <td>0.543308</td>\n",
       "      <td>0.583906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.439600</td>\n",
       "      <td>0.538767</td>\n",
       "      <td>0.591641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.531501</td>\n",
       "      <td>0.589104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.415400</td>\n",
       "      <td>0.538254</td>\n",
       "      <td>0.574924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.420400</td>\n",
       "      <td>0.527008</td>\n",
       "      <td>0.597906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.392000</td>\n",
       "      <td>0.541645</td>\n",
       "      <td>0.589270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.431400</td>\n",
       "      <td>0.529861</td>\n",
       "      <td>0.600048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.418300</td>\n",
       "      <td>0.527043</td>\n",
       "      <td>0.592200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.421400</td>\n",
       "      <td>0.510123</td>\n",
       "      <td>0.590404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.325400</td>\n",
       "      <td>0.543259</td>\n",
       "      <td>0.601115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.320500</td>\n",
       "      <td>0.552262</td>\n",
       "      <td>0.604275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.347500</td>\n",
       "      <td>0.555442</td>\n",
       "      <td>0.601164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.552800</td>\n",
       "      <td>0.595337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.375600</td>\n",
       "      <td>0.521353</td>\n",
       "      <td>0.606925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.360800</td>\n",
       "      <td>0.536955</td>\n",
       "      <td>0.612189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.372000</td>\n",
       "      <td>0.528894</td>\n",
       "      <td>0.616003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.327900</td>\n",
       "      <td>0.530147</td>\n",
       "      <td>0.613344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>0.362100</td>\n",
       "      <td>0.521653</td>\n",
       "      <td>0.622906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.296000</td>\n",
       "      <td>0.547402</td>\n",
       "      <td>0.617546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>0.269200</td>\n",
       "      <td>0.566571</td>\n",
       "      <td>0.617306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.298500</td>\n",
       "      <td>0.554796</td>\n",
       "      <td>0.624625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>0.288100</td>\n",
       "      <td>0.571388</td>\n",
       "      <td>0.615919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.264400</td>\n",
       "      <td>0.563764</td>\n",
       "      <td>0.614870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5300</td>\n",
       "      <td>0.273300</td>\n",
       "      <td>0.566961</td>\n",
       "      <td>0.616069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.546983</td>\n",
       "      <td>0.627233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.317600</td>\n",
       "      <td>0.566587</td>\n",
       "      <td>0.612238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.322000</td>\n",
       "      <td>0.541100</td>\n",
       "      <td>0.625607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5700</td>\n",
       "      <td>0.273300</td>\n",
       "      <td>0.547366</td>\n",
       "      <td>0.624718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.210700</td>\n",
       "      <td>0.605195</td>\n",
       "      <td>0.623303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5900</td>\n",
       "      <td>0.256300</td>\n",
       "      <td>0.621944</td>\n",
       "      <td>0.616993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model to ./results_twitter_roberta...\n",
      "Model cardiffnlp/twitter-roberta-base-emotion Training Complete!\n",
      "\n",
      "\n",
      "========================================================\n",
      "Loading Data: preprocessed_distilbert_student.pt\n",
      "Target Output: ./results_distilbert_student\n",
      "========================================================\n",
      "Backbone Model: joeddav/distilbert-base-uncased-go-emotions-student\n",
      "Loading Model Weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at joeddav/distilbert-base-uncased-go-emotions-student and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([28]) in the checkpoint and torch.Size([6]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([28, 768]) in the checkpoint and torch.Size([6, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training for joeddav/distilbert-base-uncased-go-emotions-student...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6800' max='19000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 6800/19000 15:32 < 27:53, 7.29 it/s, Epoch 7/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.219700</td>\n",
       "      <td>1.194885</td>\n",
       "      <td>0.191122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.010100</td>\n",
       "      <td>0.966486</td>\n",
       "      <td>0.227562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.868300</td>\n",
       "      <td>0.801162</td>\n",
       "      <td>0.311946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.751700</td>\n",
       "      <td>0.716810</td>\n",
       "      <td>0.380735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.657900</td>\n",
       "      <td>0.671752</td>\n",
       "      <td>0.432689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.641900</td>\n",
       "      <td>0.641591</td>\n",
       "      <td>0.470594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.653800</td>\n",
       "      <td>0.620959</td>\n",
       "      <td>0.487392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.613000</td>\n",
       "      <td>0.600084</td>\n",
       "      <td>0.499141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.619600</td>\n",
       "      <td>0.589363</td>\n",
       "      <td>0.505817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.580087</td>\n",
       "      <td>0.522571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.515100</td>\n",
       "      <td>0.571301</td>\n",
       "      <td>0.529926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.506300</td>\n",
       "      <td>0.571707</td>\n",
       "      <td>0.521418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.544800</td>\n",
       "      <td>0.564791</td>\n",
       "      <td>0.534974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.598400</td>\n",
       "      <td>0.557803</td>\n",
       "      <td>0.540991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.576400</td>\n",
       "      <td>0.542883</td>\n",
       "      <td>0.530373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.569500</td>\n",
       "      <td>0.536509</td>\n",
       "      <td>0.551752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.517400</td>\n",
       "      <td>0.531034</td>\n",
       "      <td>0.551702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.566400</td>\n",
       "      <td>0.525328</td>\n",
       "      <td>0.546323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.488100</td>\n",
       "      <td>0.522948</td>\n",
       "      <td>0.559734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.463800</td>\n",
       "      <td>0.537863</td>\n",
       "      <td>0.557912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.466900</td>\n",
       "      <td>0.535503</td>\n",
       "      <td>0.564059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.456500</td>\n",
       "      <td>0.522833</td>\n",
       "      <td>0.574965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.478200</td>\n",
       "      <td>0.526462</td>\n",
       "      <td>0.571979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.444900</td>\n",
       "      <td>0.517309</td>\n",
       "      <td>0.574468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.467900</td>\n",
       "      <td>0.513491</td>\n",
       "      <td>0.588178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.429600</td>\n",
       "      <td>0.514958</td>\n",
       "      <td>0.579451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.449400</td>\n",
       "      <td>0.510678</td>\n",
       "      <td>0.582078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.407600</td>\n",
       "      <td>0.497596</td>\n",
       "      <td>0.596393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.371300</td>\n",
       "      <td>0.527801</td>\n",
       "      <td>0.591621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.417000</td>\n",
       "      <td>0.515919</td>\n",
       "      <td>0.595140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.385400</td>\n",
       "      <td>0.538392</td>\n",
       "      <td>0.591179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.307300</td>\n",
       "      <td>0.527080</td>\n",
       "      <td>0.597284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.347700</td>\n",
       "      <td>0.524304</td>\n",
       "      <td>0.602995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.515545</td>\n",
       "      <td>0.601045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.332000</td>\n",
       "      <td>0.508970</td>\n",
       "      <td>0.612542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>0.522139</td>\n",
       "      <td>0.605625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.397700</td>\n",
       "      <td>0.516342</td>\n",
       "      <td>0.606343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.354600</td>\n",
       "      <td>0.516029</td>\n",
       "      <td>0.602061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.271400</td>\n",
       "      <td>0.535837</td>\n",
       "      <td>0.607145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.268000</td>\n",
       "      <td>0.542171</td>\n",
       "      <td>0.615877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.255200</td>\n",
       "      <td>0.547816</td>\n",
       "      <td>0.605908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.279600</td>\n",
       "      <td>0.531313</td>\n",
       "      <td>0.618690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.303100</td>\n",
       "      <td>0.531264</td>\n",
       "      <td>0.617791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.278000</td>\n",
       "      <td>0.528427</td>\n",
       "      <td>0.619288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.307700</td>\n",
       "      <td>0.567590</td>\n",
       "      <td>0.609583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.294100</td>\n",
       "      <td>0.529989</td>\n",
       "      <td>0.620781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>0.284700</td>\n",
       "      <td>0.536915</td>\n",
       "      <td>0.624987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.213200</td>\n",
       "      <td>0.556810</td>\n",
       "      <td>0.619289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>0.231200</td>\n",
       "      <td>0.582789</td>\n",
       "      <td>0.622004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.193900</td>\n",
       "      <td>0.603676</td>\n",
       "      <td>0.613648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>0.223300</td>\n",
       "      <td>0.595437</td>\n",
       "      <td>0.627927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.206400</td>\n",
       "      <td>0.592101</td>\n",
       "      <td>0.613358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5300</td>\n",
       "      <td>0.219000</td>\n",
       "      <td>0.591810</td>\n",
       "      <td>0.623398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.220600</td>\n",
       "      <td>0.591946</td>\n",
       "      <td>0.626923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.246300</td>\n",
       "      <td>0.585802</td>\n",
       "      <td>0.623709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.228600</td>\n",
       "      <td>0.581344</td>\n",
       "      <td>0.631729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5700</td>\n",
       "      <td>0.221400</td>\n",
       "      <td>0.591600</td>\n",
       "      <td>0.629750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.142500</td>\n",
       "      <td>0.636615</td>\n",
       "      <td>0.625285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5900</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>0.652104</td>\n",
       "      <td>0.625516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.152100</td>\n",
       "      <td>0.648158</td>\n",
       "      <td>0.631797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6100</td>\n",
       "      <td>0.146900</td>\n",
       "      <td>0.656621</td>\n",
       "      <td>0.632789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.158200</td>\n",
       "      <td>0.673716</td>\n",
       "      <td>0.616154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6300</td>\n",
       "      <td>0.137200</td>\n",
       "      <td>0.631942</td>\n",
       "      <td>0.645164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.656940</td>\n",
       "      <td>0.627375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.172900</td>\n",
       "      <td>0.642493</td>\n",
       "      <td>0.639261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6600</td>\n",
       "      <td>0.176500</td>\n",
       "      <td>0.638758</td>\n",
       "      <td>0.633192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6700</td>\n",
       "      <td>0.129500</td>\n",
       "      <td>0.671978</td>\n",
       "      <td>0.637929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>0.113500</td>\n",
       "      <td>0.707599</td>\n",
       "      <td>0.629983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model to ./results_distilbert_student...\n",
      "Model joeddav/distilbert-base-uncased-go-emotions-student Training Complete!\n",
      "\n",
      "\n",
      "========================================================\n",
      "Loading Data: preprocessed_distil_emotion.pt\n",
      "Target Output: ./results_distil_emotion\n",
      "========================================================\n",
      "Backbone Model: j-hartmann/emotion-english-distilroberta-base\n",
      "Loading Model Weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at j-hartmann/emotion-english-distilroberta-base and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([7, 768]) in the checkpoint and torch.Size([6, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([7]) in the checkpoint and torch.Size([6]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training for j-hartmann/emotion-english-distilroberta-base...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7000' max='19000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 7000/19000 17:25 < 29:52, 6.69 it/s, Epoch 7/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.230300</td>\n",
       "      <td>1.207226</td>\n",
       "      <td>0.130862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.981800</td>\n",
       "      <td>0.935549</td>\n",
       "      <td>0.167629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.855000</td>\n",
       "      <td>0.786472</td>\n",
       "      <td>0.233903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.770700</td>\n",
       "      <td>0.710336</td>\n",
       "      <td>0.363637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.687000</td>\n",
       "      <td>0.663320</td>\n",
       "      <td>0.423667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.668100</td>\n",
       "      <td>0.633687</td>\n",
       "      <td>0.486265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.682000</td>\n",
       "      <td>0.614401</td>\n",
       "      <td>0.505620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.639700</td>\n",
       "      <td>0.598434</td>\n",
       "      <td>0.519208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.617400</td>\n",
       "      <td>0.594853</td>\n",
       "      <td>0.520351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.625700</td>\n",
       "      <td>0.587450</td>\n",
       "      <td>0.528651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.551900</td>\n",
       "      <td>0.576777</td>\n",
       "      <td>0.530956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.565900</td>\n",
       "      <td>0.574152</td>\n",
       "      <td>0.527942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.593200</td>\n",
       "      <td>0.568279</td>\n",
       "      <td>0.535154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.629000</td>\n",
       "      <td>0.562387</td>\n",
       "      <td>0.541061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.619300</td>\n",
       "      <td>0.550787</td>\n",
       "      <td>0.541737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.596600</td>\n",
       "      <td>0.544708</td>\n",
       "      <td>0.549804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.544800</td>\n",
       "      <td>0.548119</td>\n",
       "      <td>0.550885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.587100</td>\n",
       "      <td>0.541205</td>\n",
       "      <td>0.547233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.500600</td>\n",
       "      <td>0.540251</td>\n",
       "      <td>0.558604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.549200</td>\n",
       "      <td>0.558678</td>\n",
       "      <td>0.545366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.544575</td>\n",
       "      <td>0.555656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.525800</td>\n",
       "      <td>0.548840</td>\n",
       "      <td>0.557226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.531100</td>\n",
       "      <td>0.542307</td>\n",
       "      <td>0.562036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.516900</td>\n",
       "      <td>0.531791</td>\n",
       "      <td>0.564400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.534000</td>\n",
       "      <td>0.540458</td>\n",
       "      <td>0.569821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.516300</td>\n",
       "      <td>0.538690</td>\n",
       "      <td>0.567989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.502600</td>\n",
       "      <td>0.526827</td>\n",
       "      <td>0.570651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.470600</td>\n",
       "      <td>0.521689</td>\n",
       "      <td>0.568182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.492800</td>\n",
       "      <td>0.536943</td>\n",
       "      <td>0.576231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.485000</td>\n",
       "      <td>0.522911</td>\n",
       "      <td>0.569417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.468900</td>\n",
       "      <td>0.554656</td>\n",
       "      <td>0.568090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.430100</td>\n",
       "      <td>0.529382</td>\n",
       "      <td>0.575731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.482000</td>\n",
       "      <td>0.533457</td>\n",
       "      <td>0.575008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.470200</td>\n",
       "      <td>0.517106</td>\n",
       "      <td>0.585030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.455200</td>\n",
       "      <td>0.518893</td>\n",
       "      <td>0.577404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.437200</td>\n",
       "      <td>0.523527</td>\n",
       "      <td>0.588436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.476200</td>\n",
       "      <td>0.520672</td>\n",
       "      <td>0.581936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.455900</td>\n",
       "      <td>0.512068</td>\n",
       "      <td>0.585188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.384200</td>\n",
       "      <td>0.526816</td>\n",
       "      <td>0.591986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.395500</td>\n",
       "      <td>0.526705</td>\n",
       "      <td>0.589719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.410100</td>\n",
       "      <td>0.528964</td>\n",
       "      <td>0.590216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.429900</td>\n",
       "      <td>0.520304</td>\n",
       "      <td>0.591335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.462000</td>\n",
       "      <td>0.513389</td>\n",
       "      <td>0.594551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.427900</td>\n",
       "      <td>0.518985</td>\n",
       "      <td>0.594486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.438100</td>\n",
       "      <td>0.526861</td>\n",
       "      <td>0.589016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.417900</td>\n",
       "      <td>0.514537</td>\n",
       "      <td>0.601540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>0.398000</td>\n",
       "      <td>0.506995</td>\n",
       "      <td>0.604609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.407700</td>\n",
       "      <td>0.515477</td>\n",
       "      <td>0.601619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>0.365100</td>\n",
       "      <td>0.516936</td>\n",
       "      <td>0.605459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.368900</td>\n",
       "      <td>0.525854</td>\n",
       "      <td>0.603332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>0.366300</td>\n",
       "      <td>0.517698</td>\n",
       "      <td>0.608715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.339400</td>\n",
       "      <td>0.534688</td>\n",
       "      <td>0.596713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5300</td>\n",
       "      <td>0.378300</td>\n",
       "      <td>0.520312</td>\n",
       "      <td>0.605545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.360100</td>\n",
       "      <td>0.517137</td>\n",
       "      <td>0.608057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.407900</td>\n",
       "      <td>0.536813</td>\n",
       "      <td>0.595689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.402100</td>\n",
       "      <td>0.511368</td>\n",
       "      <td>0.616867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5700</td>\n",
       "      <td>0.381200</td>\n",
       "      <td>0.509227</td>\n",
       "      <td>0.617977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.329400</td>\n",
       "      <td>0.521799</td>\n",
       "      <td>0.616426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5900</td>\n",
       "      <td>0.370300</td>\n",
       "      <td>0.545913</td>\n",
       "      <td>0.608723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.335400</td>\n",
       "      <td>0.537447</td>\n",
       "      <td>0.612610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6100</td>\n",
       "      <td>0.325400</td>\n",
       "      <td>0.531432</td>\n",
       "      <td>0.618798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.350700</td>\n",
       "      <td>0.517829</td>\n",
       "      <td>0.622329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6300</td>\n",
       "      <td>0.287200</td>\n",
       "      <td>0.520862</td>\n",
       "      <td>0.624070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.319000</td>\n",
       "      <td>0.535961</td>\n",
       "      <td>0.613717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.347500</td>\n",
       "      <td>0.525821</td>\n",
       "      <td>0.627283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6600</td>\n",
       "      <td>0.348500</td>\n",
       "      <td>0.550697</td>\n",
       "      <td>0.597470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6700</td>\n",
       "      <td>0.333000</td>\n",
       "      <td>0.549790</td>\n",
       "      <td>0.615755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>0.303200</td>\n",
       "      <td>0.555277</td>\n",
       "      <td>0.613192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6900</td>\n",
       "      <td>0.339300</td>\n",
       "      <td>0.550857</td>\n",
       "      <td>0.617143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.313800</td>\n",
       "      <td>0.552546</td>\n",
       "      <td>0.616160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model to ./results_distil_emotion...\n",
      "Model j-hartmann/emotion-english-distilroberta-base Training Complete!\n",
      "\n",
      "\n",
      "========================================================\n",
      "Loading Data: preprocessed_bert_group.pt\n",
      "Target Output: ./results_bert_group\n",
      "========================================================\n",
      "Backbone Model: monologg/bert-base-cased-goemotions-group\n",
      "Loading Model Weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/bert-base-cased-goemotions-group and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([4, 768]) in the checkpoint and torch.Size([6, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([4]) in the checkpoint and torch.Size([6]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training for monologg/bert-base-cased-goemotions-group...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5400' max='19000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 5400/19000 21:18 < 53:40, 4.22 it/s, Epoch 5/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.355800</td>\n",
       "      <td>1.302610</td>\n",
       "      <td>0.054457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.024400</td>\n",
       "      <td>0.951505</td>\n",
       "      <td>0.213721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.818900</td>\n",
       "      <td>0.752854</td>\n",
       "      <td>0.300845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.738200</td>\n",
       "      <td>0.702761</td>\n",
       "      <td>0.309137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.675300</td>\n",
       "      <td>0.682001</td>\n",
       "      <td>0.309091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.698300</td>\n",
       "      <td>0.665529</td>\n",
       "      <td>0.324491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.721600</td>\n",
       "      <td>0.649404</td>\n",
       "      <td>0.362303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.662500</td>\n",
       "      <td>0.635677</td>\n",
       "      <td>0.376065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.671900</td>\n",
       "      <td>0.628985</td>\n",
       "      <td>0.403456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.616200</td>\n",
       "      <td>0.610979</td>\n",
       "      <td>0.460583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.582200</td>\n",
       "      <td>0.600573</td>\n",
       "      <td>0.451028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.548300</td>\n",
       "      <td>0.585737</td>\n",
       "      <td>0.463516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.573500</td>\n",
       "      <td>0.576592</td>\n",
       "      <td>0.485596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.618800</td>\n",
       "      <td>0.564447</td>\n",
       "      <td>0.499334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.602200</td>\n",
       "      <td>0.551360</td>\n",
       "      <td>0.507455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.587600</td>\n",
       "      <td>0.547554</td>\n",
       "      <td>0.537892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.513600</td>\n",
       "      <td>0.535266</td>\n",
       "      <td>0.550599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.566400</td>\n",
       "      <td>0.530700</td>\n",
       "      <td>0.530008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.527100</td>\n",
       "      <td>0.530931</td>\n",
       "      <td>0.543051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.483500</td>\n",
       "      <td>0.528127</td>\n",
       "      <td>0.540647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.475400</td>\n",
       "      <td>0.532658</td>\n",
       "      <td>0.555014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.501500</td>\n",
       "      <td>0.525269</td>\n",
       "      <td>0.560961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.478400</td>\n",
       "      <td>0.524801</td>\n",
       "      <td>0.567981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.468400</td>\n",
       "      <td>0.512260</td>\n",
       "      <td>0.557369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.462900</td>\n",
       "      <td>0.517626</td>\n",
       "      <td>0.582996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.458200</td>\n",
       "      <td>0.524327</td>\n",
       "      <td>0.574742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.443100</td>\n",
       "      <td>0.511707</td>\n",
       "      <td>0.572958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.409400</td>\n",
       "      <td>0.502760</td>\n",
       "      <td>0.584244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.396100</td>\n",
       "      <td>0.514081</td>\n",
       "      <td>0.593819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.426000</td>\n",
       "      <td>0.510581</td>\n",
       "      <td>0.589821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.368000</td>\n",
       "      <td>0.527051</td>\n",
       "      <td>0.595951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.348600</td>\n",
       "      <td>0.519104</td>\n",
       "      <td>0.592174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.372100</td>\n",
       "      <td>0.508206</td>\n",
       "      <td>0.599955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.358300</td>\n",
       "      <td>0.501873</td>\n",
       "      <td>0.606675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.363000</td>\n",
       "      <td>0.506058</td>\n",
       "      <td>0.612434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.388000</td>\n",
       "      <td>0.509094</td>\n",
       "      <td>0.609516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.414100</td>\n",
       "      <td>0.503366</td>\n",
       "      <td>0.609557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.399700</td>\n",
       "      <td>0.491992</td>\n",
       "      <td>0.612307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.281900</td>\n",
       "      <td>0.528471</td>\n",
       "      <td>0.616785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.258900</td>\n",
       "      <td>0.525698</td>\n",
       "      <td>0.625335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.327900</td>\n",
       "      <td>0.528795</td>\n",
       "      <td>0.613117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.321200</td>\n",
       "      <td>0.514672</td>\n",
       "      <td>0.622231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.303500</td>\n",
       "      <td>0.520880</td>\n",
       "      <td>0.617287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.285900</td>\n",
       "      <td>0.523075</td>\n",
       "      <td>0.626195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.310100</td>\n",
       "      <td>0.543126</td>\n",
       "      <td>0.615579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.288600</td>\n",
       "      <td>0.516884</td>\n",
       "      <td>0.622326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>0.289400</td>\n",
       "      <td>0.516727</td>\n",
       "      <td>0.630989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.228500</td>\n",
       "      <td>0.531283</td>\n",
       "      <td>0.622717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>0.240800</td>\n",
       "      <td>0.554797</td>\n",
       "      <td>0.641789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.243700</td>\n",
       "      <td>0.554679</td>\n",
       "      <td>0.633765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>0.244000</td>\n",
       "      <td>0.558642</td>\n",
       "      <td>0.639811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.224000</td>\n",
       "      <td>0.569066</td>\n",
       "      <td>0.623647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5300</td>\n",
       "      <td>0.212600</td>\n",
       "      <td>0.565666</td>\n",
       "      <td>0.639087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.209600</td>\n",
       "      <td>0.584356</td>\n",
       "      <td>0.622753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model to ./results_bert_group...\n",
      "Model monologg/bert-base-cased-goemotions-group Training Complete!\n",
      "\n",
      "\n",
      "========================================================\n",
      "Loading Data: preprocessed_bert_ekman.pt\n",
      "Target Output: ./results_bert_ekman\n",
      "========================================================\n",
      "Backbone Model: monologg/bert-base-cased-goemotions-ekman\n",
      "Loading Model Weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/bert-base-cased-goemotions-ekman and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([7, 768]) in the checkpoint and torch.Size([6, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([7]) in the checkpoint and torch.Size([6]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training for monologg/bert-base-cased-goemotions-ekman...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3900' max='19000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 3900/19000 15:25 < 59:44, 4.21 it/s, Epoch 4/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.237700</td>\n",
       "      <td>1.191894</td>\n",
       "      <td>0.135779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.941000</td>\n",
       "      <td>0.883296</td>\n",
       "      <td>0.327799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.773000</td>\n",
       "      <td>0.711090</td>\n",
       "      <td>0.397944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.696400</td>\n",
       "      <td>0.641618</td>\n",
       "      <td>0.459575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.597600</td>\n",
       "      <td>0.611353</td>\n",
       "      <td>0.500441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.603500</td>\n",
       "      <td>0.592125</td>\n",
       "      <td>0.529579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.617300</td>\n",
       "      <td>0.576207</td>\n",
       "      <td>0.539245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.602900</td>\n",
       "      <td>0.563379</td>\n",
       "      <td>0.543398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.599200</td>\n",
       "      <td>0.557456</td>\n",
       "      <td>0.547285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.549500</td>\n",
       "      <td>0.548415</td>\n",
       "      <td>0.553131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.489500</td>\n",
       "      <td>0.542810</td>\n",
       "      <td>0.552060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.502900</td>\n",
       "      <td>0.532933</td>\n",
       "      <td>0.555712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.523800</td>\n",
       "      <td>0.532326</td>\n",
       "      <td>0.560076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.582100</td>\n",
       "      <td>0.524709</td>\n",
       "      <td>0.568663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.558000</td>\n",
       "      <td>0.517870</td>\n",
       "      <td>0.554421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.559000</td>\n",
       "      <td>0.510927</td>\n",
       "      <td>0.574273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.469700</td>\n",
       "      <td>0.507113</td>\n",
       "      <td>0.576203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.535900</td>\n",
       "      <td>0.503753</td>\n",
       "      <td>0.573535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.500600</td>\n",
       "      <td>0.497555</td>\n",
       "      <td>0.583028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.435200</td>\n",
       "      <td>0.516246</td>\n",
       "      <td>0.580590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.456400</td>\n",
       "      <td>0.518804</td>\n",
       "      <td>0.582462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.473900</td>\n",
       "      <td>0.508648</td>\n",
       "      <td>0.585960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.448000</td>\n",
       "      <td>0.496788</td>\n",
       "      <td>0.598835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.443300</td>\n",
       "      <td>0.492224</td>\n",
       "      <td>0.604808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.427100</td>\n",
       "      <td>0.493178</td>\n",
       "      <td>0.607444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.439200</td>\n",
       "      <td>0.501231</td>\n",
       "      <td>0.603681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.401400</td>\n",
       "      <td>0.489710</td>\n",
       "      <td>0.603175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.383500</td>\n",
       "      <td>0.475558</td>\n",
       "      <td>0.607020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.383300</td>\n",
       "      <td>0.494880</td>\n",
       "      <td>0.614036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.407200</td>\n",
       "      <td>0.486298</td>\n",
       "      <td>0.617564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.379300</td>\n",
       "      <td>0.514813</td>\n",
       "      <td>0.609328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.342100</td>\n",
       "      <td>0.502243</td>\n",
       "      <td>0.618432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.356100</td>\n",
       "      <td>0.486909</td>\n",
       "      <td>0.620249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.339900</td>\n",
       "      <td>0.473975</td>\n",
       "      <td>0.631640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.329200</td>\n",
       "      <td>0.489833</td>\n",
       "      <td>0.629615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.383800</td>\n",
       "      <td>0.487593</td>\n",
       "      <td>0.625738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.405800</td>\n",
       "      <td>0.494778</td>\n",
       "      <td>0.617225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.367800</td>\n",
       "      <td>0.482050</td>\n",
       "      <td>0.629046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.259900</td>\n",
       "      <td>0.522628</td>\n",
       "      <td>0.621650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model to ./results_bert_ekman...\n",
      "Model monologg/bert-base-cased-goemotions-ekman Training Complete!\n",
      "\n",
      "\n",
      "=== Step 3 Complete! All 7 models trained successfully. =============\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import evaluate\n",
    "from transformers import (AutoModelForSequenceClassification, TrainingArguments, Trainer, EarlyStoppingCallback, AutoTokenizer, AutoConfig)\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import gc \n",
    "\n",
    "# --- Dataset Class ---\n",
    "class EmotionDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels=None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        if self.labels is not None:\n",
    "            item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])\n",
    "\n",
    "# --- Custom Trainer ---\n",
    "class CustomTrainer(Trainer):\n",
    "    def __init__(self, class_weights=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.class_weights = class_weights\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        forward_inputs = {k: v for k, v in inputs.items() if k != \"labels\"}\n",
    "        outputs = model(**forward_inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        \n",
    "        # Focal Loss Calculation\n",
    "        gamma = 2.0\n",
    "        if self.class_weights is not None:\n",
    "             weight = self.class_weights.to(logits.device)\n",
    "        else:\n",
    "             weight = None\n",
    "\n",
    "        ce_loss = F.cross_entropy(logits, labels, reduction='none', weight=weight)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = ((1 - pt) ** gamma * ce_loss).mean()\n",
    "        \n",
    "        return (focal_loss, outputs) if return_outputs else focal_loss\n",
    "\n",
    "# --- Configuration Queue (7-Model Ensemble) ---\n",
    "print(\"\\n=== Step 3: Training 7 Models =========\\n\")\n",
    "\n",
    "TRAINING_QUEUE = [\n",
    "    # 1. BERT Original\n",
    "    {\"data_path\": \"preprocessed_bert.pt\", \"output_dir\": \"./results_bert\", \"batch_size\": 32, \"grad_accum\": 2, \"grad_checkpoint\": False},\n",
    "    \n",
    "    # 2. RoBERTa\n",
    "    {\"data_path\": \"preprocessed_roberta.pt\", \"output_dir\": \"./results_roberta\", \"batch_size\": 16, \"grad_accum\": 2, \"grad_checkpoint\": False},\n",
    "    \n",
    "    # 3. Twitter RoBERTa\n",
    "    {\"data_path\": \"preprocessed_twitter_roberta.pt\", \"output_dir\": \"./results_twitter_roberta\", \"batch_size\": 16, \"grad_accum\": 2, \"grad_checkpoint\": False},\n",
    "    \n",
    "    # 4. DistilBERT Student (Replaced DeBERTa)\n",
    "    {\"data_path\": \"preprocessed_distilbert_student.pt\", \"output_dir\": \"./results_distilbert_student\", \"batch_size\": 16, \"grad_accum\": 2, \"grad_checkpoint\": False},\n",
    "    \n",
    "    # 5. DistilRoBERTa\n",
    "    {\"data_path\": \"preprocessed_distil_emotion.pt\", \"output_dir\": \"./results_distil_emotion\", \"batch_size\": 16, \"grad_accum\": 2, \"grad_checkpoint\": False},\n",
    "    \n",
    "    # 6. BERT Group\n",
    "    {\"data_path\": \"preprocessed_bert_group.pt\", \"output_dir\": \"./results_bert_group\", \"batch_size\": 16, \"grad_accum\": 2, \"grad_checkpoint\": False},\n",
    "    \n",
    "    # 7. BERT Ekman\n",
    "    {\"data_path\": \"preprocessed_bert_ekman.pt\", \"output_dir\": \"./results_bert_ekman\", \"batch_size\": 16, \"grad_accum\": 2, \"grad_checkpoint\": False},\n",
    "]\n",
    "\n",
    "metric = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    f1_macro = metric.compute(predictions=predictions, references=labels, average=\"macro\")\n",
    "    return f1_macro\n",
    "\n",
    "# --- Main Training Loop ---\n",
    "for config in TRAINING_QUEUE:\n",
    "    # Clean up memory from previous iteration\n",
    "    if 'model' in locals(): del model\n",
    "    if 'trainer' in locals(): del trainer\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    data_path = config[\"data_path\"]\n",
    "    model_output_dir = config[\"output_dir\"]\n",
    "\n",
    "    print(f\"\\n========================================================\")\n",
    "    print(f\"Loading Data: {data_path}\")\n",
    "    print(f\"Target Output: {model_output_dir}\")\n",
    "    print(f\"========================================================\")\n",
    "\n",
    "    # 1. Load Data\n",
    "    try:\n",
    "        data = torch.load(data_path, weights_only=False)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"[Warning] File {data_path} not found. Skipping.\")\n",
    "        continue\n",
    "        \n",
    "    train_encodings = data['train_encodings']\n",
    "    val_encodings = data['val_encodings']\n",
    "    y_train = data['y_train']\n",
    "    y_val = data['y_val']\n",
    "    label_encoder = data['label_encoder']\n",
    "    num_classes = data['num_classes']\n",
    "    MODEL_NAME = data['MODEL_NAME']\n",
    "\n",
    "    print(f\"Backbone Model: {MODEL_NAME}\")\n",
    "\n",
    "    # 2. Weights\n",
    "    train_labels_np = y_train.cpu().numpy()\n",
    "    unique_classes, class_counts = np.unique(train_labels_np, return_counts=True)\n",
    "    n_classes = len(unique_classes)\n",
    "    weights = (1.0 - 0.995) / (1.0 - np.power(0.995, class_counts))\n",
    "    weights = weights / np.sum(weights) * n_classes\n",
    "    class_weights_tensor = torch.tensor(weights, dtype=torch.float)\n",
    "\n",
    "    # 3. Datasets\n",
    "    train_dataset = EmotionDataset(train_encodings, y_train)\n",
    "    val_dataset = EmotionDataset(val_encodings, y_val)\n",
    "\n",
    "    # 4. Load Model (Robust Loading)\n",
    "    print(\"Loading Model Weights...\")\n",
    "    try:\n",
    "        # A. Load Config first to handle different parameter names\n",
    "        config_obj = AutoConfig.from_pretrained(\n",
    "            MODEL_NAME,\n",
    "            num_labels=num_classes,\n",
    "            id2label={i: label for i, label in enumerate(label_encoder.classes_)},\n",
    "            label2id={label: i for i, label in enumerate(label_encoder.classes_)},\n",
    "        )\n",
    "\n",
    "        # B. Smartly Set Dropout based on Architecture\n",
    "        # BERT / RoBERTa uses 'hidden_dropout_prob'\n",
    "        if hasattr(config_obj, \"hidden_dropout_prob\"):\n",
    "            config_obj.hidden_dropout_prob = 0.2\n",
    "            config_obj.attention_probs_dropout_prob = 0.2\n",
    "        \n",
    "        # DistilBERT uses 'dropout' or 'seq_class_dropout'\n",
    "        elif hasattr(config_obj, \"dropout\"):\n",
    "            config_obj.dropout = 0.2\n",
    "            if hasattr(config_obj, \"attention_dropout\"):\n",
    "                config_obj.attention_dropout = 0.2\n",
    "        \n",
    "        # C. Load Model with the modified config\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            MODEL_NAME, \n",
    "            config=config_obj,\n",
    "            ignore_mismatched_sizes=True \n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model {MODEL_NAME}: {e}\")\n",
    "        continue\n",
    "\n",
    "    if config[\"grad_checkpoint\"]:\n",
    "        model.gradient_checkpointing_enable()\n",
    "        model.config.use_cache = False\n",
    "    \n",
    "    # 5. Training Arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=model_output_dir,\n",
    "        per_device_train_batch_size=config[\"batch_size\"],       \n",
    "        gradient_accumulation_steps=config[\"grad_accum\"],\n",
    "        gradient_checkpointing=config[\"grad_checkpoint\"],\n",
    "        \n",
    "        fp16=True,                          \n",
    "        num_train_epochs=20, \n",
    "        learning_rate=2e-5, \n",
    "        warmup_ratio=0.1,\n",
    "        weight_decay=0.3,\n",
    "        lr_scheduler_type=\"cosine\",\n",
    "        \n",
    "        eval_strategy=\"steps\",             \n",
    "        eval_steps=100,                     \n",
    "        save_strategy=\"steps\",              \n",
    "        save_steps=100, \n",
    "        save_total_limit=1,                \n",
    "        load_best_model_at_end=True,        \n",
    "        metric_for_best_model=\"f1\",        \n",
    "        \n",
    "        logging_dir=f'./logs_{config[\"output_dir\"]}',\n",
    "        logging_steps=20,\n",
    "        report_to=\"none\",                 \n",
    "    )\n",
    "\n",
    "    # 6. Trainer\n",
    "    early_stopping = EarlyStoppingCallback(early_stopping_patience=5)\n",
    "\n",
    "    trainer = CustomTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[early_stopping],\n",
    "        class_weights=class_weights_tensor\n",
    "    )\n",
    "\n",
    "    # 7. Start Training\n",
    "    print(f\"Starting Training for {MODEL_NAME}...\")\n",
    "    trainer.train()\n",
    "\n",
    "    # 8. Save\n",
    "    print(f\"Saving best model to {model_output_dir}...\")\n",
    "    trainer.save_model(model_output_dir)\n",
    "    try:\n",
    "        model.config.save_pretrained(model_output_dir)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "        tokenizer.save_pretrained(model_output_dir)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    print(f\"Model {MODEL_NAME} Training Complete!\\n\")\n",
    "\n",
    "print(\"\\n=== Step 3 Complete! All 7 models trained successfully. =============\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Step 4: 7-Model Ensemble Visualization & Confusion Matrix =========\n",
      "\n",
      "--- Loading Validation Data ---\n",
      "Loading data from: preprocessed_bert.pt\n",
      "Validation samples: 20253\n",
      "Classes (6): ['anger' 'disgust' 'fear' 'joy' 'sadness' 'surprise']\n",
      "Restoring raw text using: monologg/bert-base-cased-goemotions-original...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Decoding Text: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20253/20253 [00:00<00:00, 48403.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Ensemble Inference on Validation Set ---\n",
      "\n",
      "Processing: BERT Original\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Predicting BERT Original: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 633/633 [00:12<00:00, 49.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Output Shape: (20253, 6)\n",
      "\n",
      "Processing: RoBERTa Go\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Predicting RoBERTa Go: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 633/633 [00:11<00:00, 53.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Output Shape: (20253, 6)\n",
      "\n",
      "Processing: Twitter RoBERTa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Predicting Twitter RoBERTa: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 633/633 [00:11<00:00, 52.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Output Shape: (20253, 6)\n",
      "\n",
      "Processing: DistilBERT Student\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Predicting DistilBERT Student: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 633/633 [00:06<00:00, 94.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Output Shape: (20253, 6)\n",
      "\n",
      "Processing: DistilEmotion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Predicting DistilEmotion: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 633/633 [00:06<00:00, 95.28it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Output Shape: (20253, 6)\n",
      "\n",
      "Processing: BERT Group\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Predicting BERT Group: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 633/633 [00:12<00:00, 49.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Output Shape: (20253, 6)\n",
      "\n",
      "Processing: BERT Ekman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Predicting BERT Ekman: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 633/633 [00:12<00:00, 49.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Output Shape: (20253, 6)\n",
      "\n",
      "--- Generating Visualization ---\n",
      "Models Used: ['BERT Original', 'RoBERTa Go', 'Twitter RoBERTa', 'DistilBERT Student', 'DistilEmotion', 'BERT Group', 'BERT Ekman']\n",
      "Effective Weights: [0.3 0.  0.1 0.2 0.1 0.2 0.1]\n",
      "Confusion matrix saved to: confusion_matrix_ensemble_7models.png\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABQgAAASlCAYAAADklTTqAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjUsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvWftoOwAAAAlwSFlzAAAPYQAAD2EBqD+naQABAABJREFUeJzs3Xd4FOXXxvF700NCQuidhCK9GZAaeg9NmoAFkC5FepHeOwIiTRFQmgKKAlKlqiiIgvQivYcWOmnz/sGb/bHZTUggsIT9fq5rL9iZZ2fPlJ3dOXmeMybDMAwBAAAAAAAAcEhO9g4AAAAAAAAAgP2QIAQAAAAAAAAcGAlCAAAAAAAAwIGRIAQAAAAAAAAcGAlCAAAAAAAAwIGRIAQAAAAAAAAcGAlCAAAAAAAAwIGRIAQAAAAAAAAcGAlCAAAAAAAAwIGRIAQAwM5atmwpf3//Z3pthQoVVKFChUSNJyny9/dX7dq1n9pu69atMplM2rp164sP6iW5e/eu2rRpo/Tp08tkMqlbt26J/h7+/v5q2bJloi83qRo6dKhMJpO9wwAAAEg0JAgBAK+Fli1bymQyxfq4cOHCU5cR3bZNmzY25w8YMMDc5tq1a4m9Ci+Uv79/rNumRo0a9g4vybt9+7aGDRumwoULy9vbW56enipQoID69u2rixcvvtD3Hj16tObPn6+OHTvqm2++0fvvv/9C3+9lmj9/vvk4/fXXX63mG4ahLFmyyGQyxStBbMvo0aO1cuXK54wUAAAgaXOxdwAAACSG9u3bq0qVKhbTDMNQhw4d5O/vr0yZMsVrOR4eHlqxYoVmzJghNzc3i3lLliyRh4eHHj58mGhxv0xFihRRz549raZnzJjRDtG8Pk6ePKkqVaro7Nmzaty4sdq1ayc3Nzf9+++/mjt3rn744QcdO3bshb3/5s2bVbJkSQ0ZMuSFvcfRo0fl5GS/vyt7eHho8eLFKlu2rMX0bdu26fz583J3d3/mZY8ePVqNGjVS/fr14/2agQMHql+/fs/8ngAAAK8aEoQAgNdCqVKlVKpUKYtpv/76q+7fv69333033supUaOGfvrpJ61du1b16tUzT//999916tQpNWzYUCtWrEi0uF+mTJky6b333rN3GK+ViIgINWjQQFeuXNHWrVutElijRo3SuHHjXmgMV69eVb58+V7oezxPAi4x1KpVS8uWLdO0adPk4vK/n6+LFy9WYGDgS+vRe+/ePXl5ecnFxcUiDgAAgKSOIcYAgNfW4sWLZTKZ1Lx583i/JlOmTCpXrpwWL15sMX3RokUqWLCgChQoYPN1y5YtU2BgoDw9PZU6dWq99957Noc1r1y5UgUKFJCHh4cKFCigH374webyoqKiNGXKFOXPn18eHh5Kly6d2rdvr5s3b8Z7XZ5Fy5Yt5e3trQsXLqh+/fry9vZWmjRp1KtXL0VGRlq0Xbp0qQIDA5U8eXL5+PioYMGCmjp1qkWbW7duqVu3bsqSJYvc3d2VM2dOjRs3TlFRUeY2p0+flslk0sSJE/X5558re/bsSpYsmapVq6Zz587JMAyNGDFCmTNnlqenp+rVq6cbN27YjH/Dhg0qUqSIPDw8lC9fPn3//ffxWu8///xTNWrUkK+vr5IlS6by5cvrt99+e+rrVqxYoX379mnAgAFWyUFJ8vHx0ahRoyymxedYic9+iK6neOrUKa1Zs8Y8FPf06dPmobmnT5+2WK6tGozHjx9Xw4YNlT59enl4eChz5sxq2rSpQkNDzW1s1SA8efKkGjdurJQpUypZsmQqWbKk1qxZY/P9vvvuO40aNUqZM2eWh4eHKleurBMnTjx1+0Zr1qyZrl+/ro0bN5qnhYWFafny5bF+vidOnKjSpUsrVapU8vT0VGBgoJYvX27RxmQy6d69e1qwYIF5+0WvZ3SdwUOHDql58+by8/Mz7+OYNQjnzZsnk8mkr776ymL5o0ePlslk0s8//xzvdQUAALAHEoQAgNdSeHi4vvvuO5UuXTrBNwBp3ry5Vq1apbt370p63Ets2bJlsSYi5s+fryZNmsjZ2VljxoxR27Zt9f3336ts2bK6deuWud2GDRvUsGFDmUwmjRkzRvXr11erVq30119/WS2zffv26t27t8qUKaOpU6eqVatWWrRokapXr67w8PAErU+08PBwXbt2zerx4MEDi3aRkZGqXr26UqVKpYkTJ6p8+fKaNGmS5syZY26zceNGNWvWTH5+fho3bpzGjh2rChUqWCTV7t+/r/Lly2vhwoX64IMPNG3aNJUpU0b9+/dXjx49rOJbtGiRZsyYoS5duqhnz57atm2bmjRpooEDB2rdunXq27ev2rVrp1WrVqlXr15Wrz9+/Ljeeecd1axZU2PGjJGLi4saN25skVSyZfPmzSpXrpxu376tIUOGaPTo0bp165YqVaqkXbt2xfnan376SZLiXfcvvseK9PT9kDdvXn3zzTdKnTq1ihQpom+++UbffPON0qRJE69YpMdJturVq+uPP/5Qly5d9Pnnn6tdu3Y6efKkVTxPunLlikqXLq3169fro48+0qhRo/Tw4UPVrVvXZtJ77Nix+uGHH9SrVy/1799ff/zxR4J69vr7+6tUqVJasmSJedratWsVGhqqpk2b2nzN1KlTVbRoUQ0fPlyjR482Hw9PJjG/+eYbubu7KygoyLz92rdvb7Gcxo0b6/79+xo9erTatm1r871atWql2rVrq0ePHjp37pwkaf/+/Ro2bJhat26tWrVqxXtdAQAA7MIAAOA1tGrVKkOSMWPGjHi/RpLRqVMn48aNG4abm5vxzTffGIZhGGvWrDFMJpNx+vRpY8iQIYYkIyQkxDAMwwgLCzPSpk1rFChQwHjw4IF5WatXrzYkGYMHDzZPK1KkiJEhQwbj1q1b5mkbNmwwJBnZsmUzT9uxY4chyVi0aJFFfOvWrbOaXr58eaN8+fJPXbds2bIZkmw+xowZY27XokULQ5IxfPhwi9cXLVrUCAwMND//+OOPDR8fHyMiIiLW9xwxYoTh5eVlHDt2zGJ6v379DGdnZ+Ps2bOGYRjGqVOnDElGmjRpLLZN//79DUlG4cKFjfDwcPP0Zs2aGW5ubsbDhw+t1m/FihXmaaGhoUaGDBmMokWLmqdt2bLFkGRs2bLFMAzDiIqKMnLlymVUr17diIqKMre7f/++ERAQYFStWjXW9YveLr6+vnG2iZaQYyW++yF63YODgy2mzZs3z5BknDp1ymJ6zPX/559/DEnGsmXL4ow9W7ZsRosWLczPu3XrZkgyduzYYZ52584dIyAgwPD39zciIyMt3i9v3rzGo0ePzG2nTp1qSDL2798f5/tGr8fu3buN6dOnG8mTJzfu379vGIZhNG7c2KhYsWKs2yC6XbSwsDCjQIECRqVKlSyme3l5WaxbtOjPerNmzWKd96RLly4ZKVOmNKpWrWo8evTIKFq0qJE1a1YjNDQ0znUEAAB4FdCDEADwWlq8eLFcXV3VpEmTBL/Wz89PNWrUMPdWWrx4sUqXLq1s2bJZtf3rr7909epVffTRR/Lw8DBPDw4OVp48ecy9lS5duqS9e/eqRYsW8vX1NberWrWqVf24ZcuWydfXV1WrVrXo6RcYGChvb29t2bIlweskSSVKlNDGjRutHs2aNbNq26FDB4vnQUFBOnnypPl5ihQpdO/evTh75y1btkxBQUHy8/OzWI8qVaooMjJS27dvt2jfuHFji21TokQJSdJ7771nUe+tRIkSCgsLsxqWmzFjRr399tvm5z4+Pvrggw/0zz//6PLlyzZj3Lt3r44fP67mzZvr+vXr5hjv3bunypUra/v27RbDoWO6ffu2kidPHuv8J8X3WHnS0/bD84re3uvXr9f9+/fj/bqff/5Zb731lsWwam9vb7Vr106nT5/WoUOHLNq3atXK4qY/QUFBkpSgdWnSpIkePHig1atX686dO1q9enWc5QM8PT3N/79586ZCQ0MVFBSkv//+O97vKVnvg9ikT59en3/+uTZu3KigoCDt3btXX331lXx8fBL0fgAAAPZAdWUAwGvn7t27+vHHH83DM59048YNhYWFmZ97enpaJKWiNW/eXO+//77Onj2rlStXavz48Tbf68yZM5Kk3LlzW83LkyePfv31V4t2uXLlsmqXO3dui6TF8ePHFRoaqrRp09p8z6tXr9qc/jSpU6e2utOzLR4eHlbDVP38/CzqH3700Uf67rvvVLNmTWXKlEnVqlVTkyZNVKNGDYv1+Pfff2Md8hpzPbJmzWrxPHq/ZMmSxeb0mPUYc+bMaVEXTpLeeOMNSY/rHKZPn94qhuPHj0uSWrRoYTNGSQoNDZWfn5/NeT4+PvFOcsX3WIkWn/3wvAICAtSjRw9NnjxZixYtUlBQkOrWrav33nvP5uci2pkzZ8wJ3CflzZvXPP/Jep0x92309kzIuqRJk0ZVqlTR4sWLdf/+fUVGRqpRo0axtl+9erVGjhypvXv36tGjR+bpMY+RpwkICIh326ZNm2rhwoVas2aN2rVrp8qVKyfovQAAAOyFBCEA4LWzcuXKWO9e3KBBA23bts38vEWLFpo/f75Vu7p168rd3V0tWrTQo0ePnqkn4rOKiopS2rRptWjRIpvzE1Jj7lk4Ozs/tU3atGm1d+9erV+/XmvXrtXatWs1b948ffDBB1qwYIGkx+tRtWpV9enTx+YyopN3T3vf2KYbhvHUOJ8munfghAkTVKRIEZttvL29Y319njx59M8//+jcuXNWicznFZ/9EJvYkmAxbzQjSZMmTVLLli31448/asOGDeratavGjBmjP/74Q5kzZ37mGJ6UWPuwefPmatu2rS5fvqyaNWsqRYoUNtvt2LFDdevWVbly5TRjxgxlyJBBrq6umjdvntUNiJ7myZ6IT3P9+nVzTdFDhw4pKipKTk4M2AEAAK8+EoQAgNfOokWL5O3trbp161rNmzRpkkWvpYwZM9pchqenp+rXr6+FCxeqZs2aSp06tc120cOOjx49qkqVKlnMO3r0qHl+9L/RPdZitntSjhw5tGnTJpUpUyZByYmXzc3NTXXq1FGdOnUUFRWljz76SLNnz9agQYOUM2dO5ciRQ3fv3o1Xr8XEcOLECRmGYZEcO3bsmCTFeqOaHDlySHrcE/BZ4qxTp46WLFmihQsXqn///nG2je+xkhiie+jFvNFIdC/GmAoWLKiCBQtq4MCB+v3331WmTBnNmjVLI0eOtNk+W7ZsVsetJB05csQ8/0V4++231b59e/3xxx/69ttvY223YsUKeXh4aP369XJ3dzdPnzdvnlXbhPYojEunTp10584djRkzRv3799eUKVNs3pAHAADgVcOfNAEAr5WQkBBt2rRJb7/9tpIlS2Y1PzAwUFWqVDE/Ytb/e1KvXr00ZMgQDRo0KNY2xYoVU9q0aTVr1iyLYYxr167V4cOHFRwcLEnKkCGDihQpogULFig0NNTcbuPGjVb12po0aaLIyEiNGDHC6v0iIiLivLvsy3L9+nWL505OTipUqJAkmbdDkyZNtHPnTq1fv97q9bdu3VJERESixnTx4kWLO+jevn1bX3/9tYoUKWJzeLH0+HjIkSOHJk6caL5r9ZNCQkLifM9GjRqpYMGCGjVqlHbu3Gk1/86dOxowYICk+B8riSE68flkncfIyEiLO1FLj7dRzP1QsGBBOTk5WcQYU61atbRr1y6Ldb53757mzJkjf3//OD9Xz8Pb21szZ87U0KFDVadOnVjbOTs7y2QyWfSYPH36tFauXGnV1svLK1E+U8uXL9e3336rsWPHql+/fmratKkGDhxoTlIDAAC8yuhBCAB4rXz77beKiIiwObw4oQoXLqzChQvH2cbV1VXjxo1Tq1atVL58eTVr1kxXrlzR1KlT5e/vr+7du5vbjhkzRsHBwSpbtqw+/PBD3bhxQ5999pny589vkZwqX7682rdvrzFjxmjv3r2qVq2aXF1ddfz4cS1btkxTp06Ns/ZabC5cuKCFCxdaTff29lb9+vUTtKw2bdroxo0bqlSpkjJnzqwzZ87os88+U5EiRcx16Hr37q2ffvpJtWvXVsuWLRUYGKh79+5p//79Wr58uU6fPh1rz8xn8cYbb6h169bavXu30qVLp6+++kpXrlyx2WssmpOTk7788kvVrFlT+fPnV6tWrZQpUyZduHBBW7ZskY+Pj1atWhXr611dXfX999+rSpUqKleunJo0aaIyZcrI1dVVBw8e1OLFi+Xn56dRo0Yl6Fh5Xvnz51fJkiXVv39/3bhxQylTptTSpUutkoGbN29W586d1bhxY73xxhuKiIjQN998I2dnZzVs2DDW5ffr109LlixRzZo11bVrV6VMmVILFizQqVOntGLFihc6rDauepHRgoODNXnyZNWoUUPNmzfX1atX9fnnnytnzpz6999/LdoGBgZq06ZNmjx5sjJmzKiAgACb9RXjcvXqVXXs2FEVK1ZU586dJUnTp0/Xli1b1LJlS/36668MNQYAAK80EoQAgNfKokWLlDZt2pc2rFWSWrZsqWTJkmns2LHq27evvLy89Pbbb2vcuHEWNdJq1KihZcuWaeDAgerfv79y5MihefPm6ccff9TWrVstljlr1iwFBgZq9uzZ+uSTT+Ti4iJ/f3+99957KlOmzDPFuXfvXr3//vtW07Nly5bgBOF7772nOXPmaMaMGbp165bSp0+vd955R0OHDjUnQpIlS6Zt27Zp9OjRWrZsmb7++mv5+PjojTfe0LBhw+K8CcazyJUrlz777DP17t1bR48eVUBAgL799ltVr149ztdVqFBBO3fu1IgRIzR9+nTdvXtX6dOnV4kSJdS+ffunvm/OnDm1d+9effrpp/rhhx+0cuVKRUVFKWfOnGrTpo26du1qbhvfYyUxLFq0SO3bt9fYsWOVIkUKtW7dWhUrVlTVqlXNbQoXLqzq1atr1apVunDhgpIlS6bChQtr7dq1KlmyZKzLTpcunX7//Xf17dtXn332mR4+fKhChQpp1apVidoT8llVqlRJc+fO1dixY9WtWzcFBARo3LhxOn36tFWCcPLkyWrXrp0GDhyoBw8eqEWLFglOEHbs2FGPHj3SvHnzzEOWU6VKpTlz5qhevXqaOHFirLU4AQAAXgUmIzEqfAMAAAAAAABIkhjrAAAAAAAAADgwEoQAAAAAAACAAyNBCAAAAAAAADgwEoQAAAAAAACAAyNBCAAAAAAAADgwEoQAAAAAAACAAyNBiOdiMpk0dOjQBL/u9OnTMplMmj9/fqLHBGtbt26VyWTS1q1bE/zal7Wv/P391bJlyxf6Hnj9cRzBlpYtW8rf3z/RllehQgVVqFDB/JzvtBdj6NChMplM9g7jhUjsY8bW93xiH/cvW8zPGQBr0Z/95cuX2zsUAK8BEoSvgfnz58tkMslkMunXX3+1mm8YhrJkySKTyaTatWvbIUL7qFChgnm7mEwmubm5KSAgQO3atdO5c+cs2j65DW09/vjjD3PbmPN8fHxUvnx5rVmzRtL/vqjj83ia69evq3fv3sqdO7c8PDyUMmVKVa9eXatXr07cjZXEtWzZ0mK7uru764033tDgwYP18OHDRFmmi4uLsmTJoqZNm+rQoUMWbZ+2z5cuXWpu6+/vbzHPy8tLb731lr7++mtJ/7tojM/j9OnTz7zNJGnHjh1q0qSJMmXKJDc3N/n6+qpEiRIaPny4rly58lzLjkvMbRvbIzESfYcOHdLQoUNtbqsZM2a89ITO0/Z/YizTw8NDuXLlUu/evXXjxg2LttEJl9gely9flmR9HDo5OSllypSqWbOmdu7cKenp583oR2InKGKuQ7JkyZQ1a1bVqVNH8+bN06NHjxLlfeI6dp4lTicnJ2XIkEG1a9e2+E6Rnv65Hzt2rLltzO82T09PFSpUSFOmTFFUVJQk6++p2B5x/dEoLCxMU6dOVdGiReXj46MUKVIof/78ateunY4cOWJu9/vvv2vo0KG6devWM20ne7t48aKGDh2qvXv3PtdyYn5fpEyZUoGBgfr444+tvjOex/Oet+I6Hjp06JBoccbX837OXqbX4Vx79epV9evXTwULFpS3t7c8PDyUM2dOtWrVyuY1RFJm67zq4+OjIkWKaPr06YqMjLRoH/Pc+uQjT5485nYx94eLi4syZcqkli1b6sKFC5IS53dOfI8hAEhMLvYOAInHw8NDixcvVtmyZS2mb9u2TefPn5e7u7udIrOfzJkza8yYMZIeX+wcOnRIs2bN0vr163X48GElS5bMov3w4cMVEBBgtZycOXNaPK9atao++OADGYahM2fOaObMmapTp47Wrl2rIkWK6JtvvrFo379/f3l7e2vAgAHxjv3o0aOqXLmyQkJC1KpVKxUrVky3bt3SokWLVKdOHfXq1UsTJkyI17LKlSunBw8eyM3NLd7vHy1btmx68OCBXF1dE/zal8nd3V1ffvmlJCk0NFQ//vijRowYof/++0+LFi167mVGRETov//+06xZs7Ru3TodOnRIGTNmtGjftWtXFS9e3Go5pUqVsnhepEgR9ezZU5J06dIlffnll2rRooUePXqk5s2bWx0/kyZN0vnz5/Xpp59aTE+TJs0zrZckDR48WCNGjFD27NnVsmVLZc+eXQ8fPtSePXs0adIkLViwQP/9998zLz8u7du3V5UqVczPT506pcGDB6tdu3YKCgoyT8+RI0eCl3306FE5Of3vb1+HDh3SsGHDVKFCBauLpxkzZih16tQvvcdhXPu/bdu2z73M6P04ZcoUbdu2Tbt27bJqP3PmTHl7e1tNT5EihcXzZs2aqVatWoqMjNSxY8c0Y8YMVaxYUbt371a5cuWsjtU2bdrorbfeUrt27czTbL1PYoheh0ePHunChQtav369PvzwQ02ZMkWrV69WlixZzG2/+OILc/IsvuI6djZs2JDgOKOionTu3Dl98cUXKleunHbt2qUiRYpYtI3e3jEVLVrU4vmT323Xrl3T4sWL1b17d4WEhGjUqFFW++Xrr7/Wxo0brabnzZs31rgbNmyotWvXqlmzZmrbtq3Cw8N15MgRrV69WqVLlzZfMP/+++8aNmyYWrZsaXX8JAUXL17UsGHD5O/vb7U/EurJ3wahoaHat2+fFixYoBkzZmjcuHHq0aOHue2zfrfGdt5KyPd8dJwxvfHGGwmKJTEk1ufsZUnK59pdu3YpODhYd+7cUdOmTdWhQwe5u7vr1KlTWrlypebPn69t27apXLly8d0cScKT59XQ0FD9/PPP6tKli86cOWP1O/rJc+uTfH19raZFXzM8fPhQf/zxh+bPn69ff/1VBw4cSNTfOfE9hgAgURhI8ubNm2dIMho0aGCkTp3aCA8Pt5jftm1bIzAw0MiWLZsRHBycqO8tyRgyZEiCX3fq1ClDkjFv3rxEjedJ5cuXN/Lnz281ffr06YYkY8OGDeZp0dtw9+7dT12uJKNTp04W0w4dOmRIMmrWrGnzNfnz5zfKly8f79jDwsKMAgUKGMmSJTP++OMPi3kRERHGO++8Y0gyli5dGudyHjx4YERGRsb7fe0pW7ZsRosWLZ7ptS1atDC8vLwspkVFRRklS5Y0TCaTcfny5URZpmEYxurVqw1Jxpw5c8zTtmzZYkgyli1b9tTl2vocXr161fD29jby5s1r8zXBwcFGtmzZErYCcVi6dKkhyWjSpInx6NEjq/m3bt16ps/1s9q9e/cLOx8sW7bMkGRs2bLFal5CP5fxER4ebnObRnuW/f80sZ3be/XqZUgyjh07Zp42ZMgQQ5IREhIS5zKjz9ETJkywmL527VpDktGxY0ebr/Py8nrmz3F8xbUOCxcuNJycnIwSJUo89/vEdezEZOs7LbY4Dxw4YEgyPvnkE6vXx9zettj6bnvw4IGRLVs2I3ny5EZERITVazp16mQk5Cffrl27DEnGqFGjrOZFREQY165dMz+fMGGCIck4depUvJcfX9Hb8EVKrPOPrd8GhmEY165dM0qVKmVIMtasWfNc72EYCTtvtWjRwuq7I7Y47SUhnzN7S8rn2hs3bhgZMmQw0qdPbxw+fNhqflRUlLF48WJj165dcS7n7t278X5Pe4tt20ZFRRnFixc3MmbMaDE9tuuGmGK7Zujbt68hyfj222+tXvMs55n4HkMJ+Q0KAE/DEOPXSLNmzXT9+nVt3LjRPC0sLEzLly9X8+bNbb7m3r176tmzp7JkySJ3d3flzp1bEydOlGEYFu0ePXqk7t27K02aNEqePLnq1q2r8+fP21zmhQsX9OGHHypdunRyd3dX/vz59dVXXz01/suXL6tVq1bKnDmz3N3dlSFDBtWrV89i2EloaKiOHDmi0NDQeGwR29KnTy9JcnFJvA60efPmVerUqROtx9WKFSt04MAB9evXTyVKlLCY5+zsrNmzZytFihQW9R+jh7kuXbpUAwcOVKZMmZQsWTLdvn071hqEn3/+ubJnzy5PT0+99dZb2rFjhyrEo7ZWy5Yt5e3trQsXLqh+/fry9vZWmjRp1KtXL6shGxMnTlTp0qWVKlUqeXp6KjAw8KXUSTGZTCpbtqwMw9DJkyct5s2YMUP58+eXu7u7MmbMqE6dOsV7eNyLOH7SpEmjPHnyJOj4eZ7tOnjwYKVOnVpz58612dvE19fXZm3R59luCfHTTz/JZDLp33//NU9bsWKFTCaTGjRoYNE2b968euedd8zPn6xBOH/+fDVu3FiSVLFiRYthlf7+/jp48KC2bdtmnv7kcX/r1i1169bNfG7MmTOnxo0bZ9ELLfqzMXHiRE2ZMkU5cuSQu7t7gocTxrb/43t+js2LOFajez7E91i9ceOGevXqZR7O5uPjo5o1a2rfvn2JFtOT3n33XbVp00Z//vmnxXehrVpsS5cuVWBgoJInTy4fHx8VLFhQU6dOlRT3sSM9X220F7FfPDw8VLx4cd25c0dXr1597uVF798yZcpYzXN2dlaqVKkkPR4C17t3b0lSQECAeTudPn06zhp7JpN1/eJff/1VxYsXl4eHh3LkyKHZs2fHGt/ChQsVGBgoT09PpUyZUk2bNrUqHVKhQgUVKFBAhw4dUsWKFZUsWTJlypRJ48ePN7fZunWrudd3q1atzPEnZumBVKlSaenSpXJxcdGoUaPM021tn6f9DorrvPU8tYZtid5+//77r8qXL69kyZIpZ86c5u+Zbdu2qUSJEvL09FTu3Lm1adMmq2X8888/qlmzpnx8fOTt7a3KlStbDK9/ls/Z1atX1bp1a6VLl04eHh4qXLiwFixYYNHmyXPznDlzzOfm4sWLa/fu3YmyfZ70Kpxrn2bWrFm6dOmSpkyZYjFcNprJZFKzZs0sRkFED3E9dOiQmjdvLj8/P/MopYiICI0YMcK8bf39/fXJJ59YlXiw9VmXrOsFRw/b3b59u9q3b69UqVLJx8dHH3zwgW7evJko2+DJmNKlS5eo+0tK/H32PB49eqTatWvL19dXv//+u6T/7c9jx47pvffek6+vr9KkSaNBgwbJMAydO3dO9erVk4+Pj9KnT69JkyZZLDMsLEyDBw9WYGCgfH195eXlpaCgIG3ZssWi3cv+/AFIXAwxfo34+/urVKlSWrJkiWrWrClJWrt2rUJDQ9W0aVNNmzbNor1hGKpbt662bNmi1q1bq0iRIlq/fr169+6tCxcuWAxnbNOmjRYuXKjmzZurdOnS2rx5s4KDg61iuHLlikqWLCmTyaTOnTsrTZo0Wrt2rVq3bq3bt2+rW7duscbfsGFDHTx4UF26dJG/v7+uXr2qjRs36uzZs+YLux9++EGtWrXSvHnz4jUsMDIyUteuXZMkhYeH6/DhwxoyZIhy5sxp88InNDTU3D6ayWQyXwzFJjQ0VDdv3nymIZG2rFq1SpJsDgGSHidw6tWrpwULFujEiRMWQ6BHjBghNzc39erVS48ePYp1uNHMmTPVuXNnBQUFqXv37jp9+rTq168vPz8/Zc6c+akxRkZGqnr16ipRooQmTpyoTZs2adKkScqRI4c6duxobjd16lTVrVtX7777rsLCwrR06VI1btxYq1evtnkMJaboiyo/Pz/ztKFDh2rYsGGqUqWKOnbsqKNHj2rmzJnavXu3fvvtN6vhXtHHQ2RkpE6ePKm+ffsqVapUNut53rlzx+r4kR5fIJpMsdecjIiI0Pnz5y3ifJpn3a7Hjh3TsWPH1KZNmwQN/UzodnseZcuWNV8oFCpUSNLjeolOTk4WNZJCQkJ05MgRde7c2eZyypUrp65du2ratGn65JNPzMMp8+bNqylTpqhLly4WQ//TpUsnSbp//77Kly+vCxcuqH379sqaNat+//139e/f33yB9aR58+bp4cOHateundzd3ZUyZcoEra+t/Z+Q87P0+PwWfew9fPhQ//zzjyZPnqxy5crZLJsQs16W9Pji9mlDlmx9puJy8uRJrVy5Uo0bN1ZAQICuXLmi2bNnq3z58jaH6SeG999/X3PmzNGGDRtUtWpVm202btyoZs2aqXLlyho3bpwk6fDhw/rtt9/08ccfx3nsJFT0to6KitKFCxc0YsQIeXh4qEmTJlZt79+/b/MckiJFiqdezEZflCXGsLNs2bJJkhYtWqQyZcrE+t4NGjTQsWPHtGTJEn366adKnTq1pMdJ75CQkHi/3/79+1WtWjWlSZNGQ4cOVUREhIYMGWL+TD5p1KhRGjRokJo0aaI2bdooJCREn332mcqVK6d//vnHYv1v3rypGjVqqEGDBmrSpImWL1+uvn37qmDBgqpZs6by5s2r4cOHWw39K126dLxjj4+sWbOqfPny2rJli27fvi0fHx+b7Z72Oyiu81ZCPHz40OZx5uPjY/Gb4ebNm6pdu7aaNm2qxo0ba+bMmWratKkWLVqkbt26qUOHDmrevLkmTJigRo0a6dy5c0qePLkk6eDBgwoKCpKPj4/69OkjV1dXzZ49WxUqVDAnFxP6OXvw4IEqVKigEydOqHPnzgoICNCyZcvUsmVL3bp1Sx9//LFF+8WLF+vOnTtq3769TCaTxo8frwYNGujkyZPP/J31qp5rn2bVqlXy9PS0+iNbfDRu3Fi5cuXS6NGjzX+gatOmjRYsWKBGjRqpZ8+e+vPPPzVmzBgdPnxYP/zwwzPH2blzZ/MfwKN/Z5w5c8acAH8WT55Xb9++rbVr12rdunXq37+/Vdsnrxue5OnpKS8vrzjfJ7H3WbSEHkMPHjxQvXr19Ndff2nTpk1WpW/eeecd5c2bV2PHjtWaNWs0cuRIpUyZUrNnz1alSpU0btw4LVq0SL169VLx4sXNQ85v376tL7/80lx24s6dO5o7d66qV69us2TGi/j8AXgJ7Nh7EYnkya7u06dPN5InT27cv3/fMAzDaNy4sVGxYkXDMKyHRqxcudKQZIwcOdJieY0aNTJMJpNx4sQJwzAMY+/evYYk46OPPrJo17x5c6shxq1btzYyZMhgMfzIMAyjadOmhq+vrzmumMOxbt68Ga/hVdHrGp8u+uXLlzckWT3y5s1rnDx50uZybT3c3d0t2koyWrdubYSEhBhXr141/vrrL6NGjRpxxp/QoYxFihQxfH1942wzefJkQ5Lx008/GYbxvyEG2bNnN2/naNHzoofwPHr0yEiVKpVRvHhxiyHp8+fPNyRZxGpr6FyLFi0MScbw4cMt3qdo0aJGYGCgxbSYsUQPn65UqZLF9MQYYhwSEmKEhIQYJ06cMCZOnGiYTCajQIECRlRUlGEYj4dyurm5GdWqVbMYeh097Pyrr76yWseYj0yZMhl79uyxeP/o7Rvb49KlSxbrWa1aNXOs+/fvN95///04h33ZGmIc3+0a048//mhIMqZMmWIxPSoqyhxT9CP62EjIdnsWtobe5M+f32jSpIn5+Ztvvmk0btzYkGQeHvX9998bkox9+/aZ28U8jp5liPGIESMMLy8vi+FihmEY/fr1M5ydnY2zZ88ahvG/z4aPj49x9erVeK1rfPd/fM/P0cu0ddyVKVPG6lwcPWTJ1iN37tzmdtHrNmzYMCMkJMS4fPmysWPHDqN48eJxDmWKOezt4cOHVmUOTp06Zbi7u1udP+LracOuor9P3n77bfO0mEMtP/74Y8PHx8fmcNxocR075cuXf+p5MrZtnSJFCmPdunUWy4t+fWyPnTt3Wrx3njx5zMfQkSNHjN69exuSYi0jktAhxlFRUebv0HTp0hnNmjUzPv/8c+PMmTNWbWMbYhxXKZGYvx3q169veHh4WCz/0KFDhrOzs0Xcp0+fNpydna2GPu/fv99wcXGxmB4d/9dff22e9ujRIyN9+vRGw4YNzdNe9BDjaB9//LHF+epZfwfFdt6K+T1vGLEPMY7tsWTJEnO76O23ePFi87QjR44YkgwnJyeL8ifr16+32ob169c33NzcjP/++8887eLFi0by5MmNcuXKmacl5HM2ZcoUQ5KxcOFC87SwsDCjVKlShre3t3H79m3DMP63bVOlSmXcuHHD3Db6+2/VqlVW7xUfr/K59mn8/PyMIkWKWE2/ffu2xff+k0OIo9ehWbNmFq+Jvi5o06aNxfToodabN282T4v5WY8W87s6+nd4YGCgERYWZp4+fvx4Q5Lx448/xntdo8V1Xu3YsaP5t2G02K4bJBnt27e3inXTpk1GSEiIce7cOWP58uVGmjRpDHd3d+PcuXNWsTzPEOOnHUNPDjG+c+eOUb58eSN16tTGP//8Y3N57dq1M0+LiIgwMmfObJhMJmPs2LHm6Tdv3jQ8PT0t9lFERIRVCZWbN28a6dKlMz788EPztBf1+QPwctCD8DXTpEkTdevWTatXr1aNGjW0evVqq56D0X7++Wc5Ozura9euFtN79uyp5cuXa+3atercubN+/vlnSbJq161bNy1evNj83DAMrVixQk2aNJFhGBZ/gatevbqWLl2qv//+22bPPU9PT7m5uWnr1q1q3bp1rH99a9myZYJuKODv768vvvhC0uNeOkePHtX48eNVs2ZN7dixw+omD59//rlVkW5nZ2er5c6dO1dz5841P3d1dVWfPn0sCpA/jzt37pj/Ch+b6Pm3b9+2mN6iRQt5enrG+dq//vpL169f15gxYyx6hrz77rvq3r17vOOMecfDoKAgq0LaT8Zy8+ZNRUZGKigoSEuWLIn3+8THvXv3rPZn2bJltWDBAvNfnTdt2qSwsDB169bN4kYWbdu21SeffKI1a9aoVatW5ukeHh7m3pxRUVE6ffq0Jk+erFq1amn79u1Wx8rgwYMtik9Hi9mjbMOGDVaxtmrVKt43nZGefbtGHy8xew+GhoZaxbR7924VK1YswdstMQQFBenHH3+U9PjzsG/fPo0bN05btmzRjh07lCdPHu3YsUMpUqRQgQIFEvW9ly1bpqCgIPn5+Vmcx6pUqaKxY8dq+/btevfdd83TGzZsmKAbxsRn/8f3/BytRIkSGjlypKTHQ4v27dunCRMmqG7dutq0aZPVOWHFihVWvZhs9Y4YMmSIhgwZYn7u7e2tSZMmqVGjRvFa1ydvjhUZGalbt27J29tbuXPn1t9//x2vZSRU9LF9586dWNukSJFC9+7d08aNG1WjRo0XEke06G1tGIYuXLigmTNnqmHDhtqwYYNVT7V27dqZh1w+KV++fBbPjxw5YnUM1a1b1+J76XmYTCatX79eEydO1MKFC7VkyRItWbJEnTp1UpMmTcxlLhJDZGSk1q9fr/r16ytr1qzm6Xnz5lX16tXNv0Ek6fvvv1dUVJSaNGli8dlMnz69cuXKpS1btuiTTz4xT/f29tZ7771nfu7m5qa33nrLquzEy/C04zK+v4MSQ7169Wz2vC5YsKDFc29vbzVt2tT8PHfu3EqRIoUyZcpkUf4k+v/R2zUyMlIbNmxQ/fr1lT17dnO7DBkyqHnz5vriiy/i7EkZm59//lnp06dXs2bNzNNcXV3VtWtXNWvWTNu2bbPo3f/OO+9YbMfo7+fn2f+v6rn2aW7fvm1z1MD7779v/q6VpE6dOmn69OkWbWL+1ov+TMb8zduzZ09NnDhRa9asUcWKFZ8pznbt2ln0LuvYsaM++eQT/fzzz6pbt+4zLzP6vHr79m1t3rxZM2fOlLu7u1Vv/CevG55ka2TNkzchiX7twoUL4zUKJyHiewyFhoaqWrVqOnnypLZu3ar8+fPbXF6bNm3M/3d2dlaxYsV0/vx5tW7d2jw9RYoUyp07t8VnxdnZ2XxNFBUVpVu3bikqKkrFihWz+X3+Ij5/AF48EoSvmTRp0qhKlSpavHix7t+/r8jIyFh/XJw5c0YZM2a0SkRFD+04c+aM+V8nJyer4bO5c+e2eB4SEqJbt25pzpw5mjNnjs33jK02kru7u8aNG6eePXsqXbp0KlmypGrXrq0PPvjAXNvlWXh5eVl8gdeoUUNly5ZVsWLFNHbsWKv6Gm+99ZaKFSv21OVG/7gOCwvT7t27NXr0aN2/f98iefI8kidPbnOIw5OiLzJi7j9bQ1xiit63Me/O7OLiYlWnKzYeHh5WF6h+fn5WtWJWr16tkSNHau/evRa1aZ51qEhc8UQn886fP6/x48fr6tWrFj/Wo9c75rHr5uam7Nmzm+dHc3Z2tvoBWKtWLeXKlUv9+/fXihUrLOYVLFjQqr0t0RcYkZGROnDggEaOHKmbN28m6C7Tz7pdo4+Xu3fvWkz39vY212zbsGGDRbIqodstMQQFBWnWrFk6ceKE/vvvP5lMJpUqVUpBQUHasWOH2rZtqx07dqhMmTKJ9rmLdvz4cf3777+xJv1insfi85l7Unz2f3zPz9FSp05tcewFBwcrd+7catSokb788kt16dLFon25cuXMw0HjEn1h9fDhQ23evFnTpk2zqjMal6ioKE2dOlUzZszQqVOnLF77tNINzyr62I7rjywfffSRvvvuO9WsWVOZMmVStWrV1KRJkxeSLIy5rRs1aqRcuXKpS5cu2rNnj0XbXLlyxescEn0RGxUVpf/++0+jRo1SSEiIPDw8Ei1ud3d3DRgwQAMGDNClS5e0bds2TZ06Vd99951cXV21cOHCRHmfkJAQPXjwQLly5bKalzt3bosE4fHjx2UYhs22kqyGrWXOnNnqnOjn52dR3/Rledpx+aJ+B9mSOXPmeB1ntrafr6+vxR3Co6dJMn//h4SE6P79+1bfGdLjc1j0Hb1jS2DE5syZM8qVK5fVOT+28+KTCWfpf0M/n6em3at6rn2a5MmTW33vS4/vxBudLI6tJEPM77jo64KYvyHTp0+vFClSPNdvgpifbW9vb2XIkMGiHvmzLPPJfdagQQOZTCZNmTJFH374oUViPOZ1Q1yiOxWEhobqq6++0vbt2y3+KJZY4nsMdevWzTzsPa7PVszPha+vrzw8PKzew9fXV9evX7eYtmDBAk2aNElHjhxReHi4ebqt30Ev4vMH4MUjQfgaat68udq2bavLly+rZs2aifZX/qeJLt7/3nvvqUWLFjbbRNcTs6Vbt26qU6eOVq5cqfXr12vQoEEaM2aMNm/erKJFiyZanNHFdbdv3/7My3jyx3WtWrWUOnVqde7cWRUrVnym+i4x5c2bV3v37tXZs2etvmCjRV/gxOxZ8rTeg4nFVs/KmHbs2KG6deuqXLlymjFjhjJkyCBXV1fNmzfPovdpYsXz5I+66tWrK0+ePGrfvr1++umnRHufzJkzK3fu3M91/Dx5gREdZ+3atTV16tR49UJ9nu0aXZz8wIEDFtNdXFzMMcV2A6KXKboQ+vbt23Xy5Em9+eab5oLY06ZN0927d/XPP/9YFP1PLFFRUapatar69Oljc37MnqMJ/cw97/6Pr8qVK0t6vA1jXrTG15MXVrVr15azs7P69eunihUrxuuPKaNHj9agQYP04YcfasSIEUqZMqWcnJzUrVs3ixu+JKboYzvmxeuT0qZNq71792r9+vVau3at1q5dq3nz5umDDz6wuuFBYvP29laJEiX0448/6t69e0+ta2VLzIvYMmXK6M0339Qnn3wS66iB55EhQwY1bdpUDRs2VP78+fXdd99p/vz5cdZFjO2PFc+T9IiKipLJZNLatWttfgfF7CEV2/eUEc8b/SSmAwcOyNnZOc4/KLys30HxFdv2e5W2a1xeVpyvwrn2afLkyaN9+/YpPDzcIpEe1+/yaLF9xz3PH3oTM/n5LCpXrqzp06dr+/btVj1n4+vJTgX169dX2bJl1bx5cx09ejRBNZ4TS7169bR06VKNHTtWX3/9dax/PLX1uYjPZ2XhwoVq2bKl6tevr969eytt2rRydnbWmDFjbN6YJamcJwBY4i7Gr6G3335bTk5O+uOPP2K9e7H0uAj5xYsXrYa7HDlyxDw/+t/oXgpPOnr0qMXz6DscR0ZGqkqVKjYfadOmjTP2HDlyqGfPntqwYYMOHDigsLAwq15+iSEyMtLmX1KfVfv27ZUjRw4NHDgwUb74oofIfP311zbn3759Wz/++KPy5MkT50VwbKL37YkTJyymR0REPNdfaWNasWKFPDw8tH79en344YeqWbNmvP8y+7wyZMig7t27a9WqVea7Jkavd8xjNywsTKdOnTLPf5qIiIhEPX6Cg4NVvnx5jR49Wvfu3Xtq++fZrrlz51auXLm0cuXKeL2XlHjbLSGyZs2qrFmzaseOHdqxY4d5aEq5cuV0+vRpLVu2TJGRkebi2bGJ6wImtnk5cuTQ3bt3Yz2PxZa0f1a29n98z89xiYiIkGTdW/R5DBgwQMmTJ9fAgQPj1X758uWqWLGi5s6dq6ZNm6patWqqUqXKC7n7dbToMgfVq1ePs52bm5vq1KmjGTNm6L///lP79u319ddfm8+Lid3L+UmJvW8KFSqk9957T7Nnz9bZs2cTZZm2uLq6qlChQhY3aohtO0X3Fom5r2P2LkqTJo08PT11/Phxq2XEPOfkyJFDhmEoICDA5mezZMmSCV6nF7mfo509e1bbtm1TqVKlnlo+5Gm/g15GvM8rTZo0SpYsmdX+kx6fw5ycnMy9EBOyPtmyZdPx48et/riQkPPii/AqnGufpnbt2nrw4MFz3UAkWvR1QczP7JUrV3Tr1i2L/eDn52d1DggLC9OlS5dsLjvmMu/evatLly7Fe3RLfCX2PotOlF28eNFqiPbLUr9+fX311VdavHixOnXqlOjLX758ubJnz67vv/9e77//vqpXr64qVaro4cOHif5eAOyHBOFryNvbWzNnztTQoUNVp06dWNvVqlVLkZGRVl9kn376qUwmk/lOyNH/xuyVEPNOns7OzmrYsKFWrFhh1TtJUpx3NLx//77VF0yOHDmUPHlyi+GToaGhOnLkiEJDQ2Nd1tNs2bJFd+/eVeHChZ95GTG5uLioZ8+eOnz4sEUtl2fVqFEj5cuXT2PHjtVff/1lMS8qKkodO3bUzZs3LerVJESxYsWUKlUqffHFF+YfSdLjO1YmZtd/Z2dnmUwmi78Unz59WitXrky094hLly5dlCxZMo0dO1bS43oxbm5umjZtmkUid+7cuQoNDY3XXZWPHTumo0ePJurxI0l9+/bV9evXbda+iel5t+vQoUN17do1tW3b1mKISLSYSe7E2G7PIigoSJs3b9auXbvMCcIiRYooefLkGjt2rDw9PRUYGBjnMqJ7Z9lKSHl5edmc3qRJE+3cuVPr16+3mnfr1i2Lz0xiibn/43t+jkv0kPvEPFZTpEih9u3ba/369dq7d+9T2zs7O1sdT8uWLdOFCxcSLaYnLV68WF9++aVKlSpl7tVjS8xhU05OTuaeNNHfOXEdO8/jxo0b+v3335U+ffqn/tEsIfr06aPw8HBNnjz5uZd1/Phxm4nGW7duaefOnfLz8zMPwY9tO/n4+Ch16tRWva1nzJhh8dzZ2VnVq1fXypUrLd7z8OHDVp/BBg0ayNnZWcOGDbM6rgzDsNqv8fGi9nO0GzduqFmzZoqMjDTfediW+P4Oiu289SpxdnZWtWrV9OOPP1r80fHKlStavHixypYta66plpDtX6tWLV2+fFnffvuteVpERIQ+++wzeXt7q3z58om6HvH1Kpxrn6Zjx45Kly6dunfvrmPHjlnNT8gft2vVqiXJ+jog+tzz5G+CHDlyWJ0D5syZE2sPwjlz5lj8Lpk5c6YiIiLi9Z2XEC9in1WoUEFvvfWWpkyZYrek2QcffKBp06Zp1qxZ6tu3b6IuO7pH4JPHyp9//qmdO3cm6vsAsC+GGL+mYhvi+6Q6deqoYsWKGjBggE6fPq3ChQtrw4YN+vHHH9WtWzdzzcEiRYqoWbNmmjFjhkJDQ1W6dGn98ssvVr3PJGns2LHasmWLSpQoobZt2ypfvny6ceOG/v77b23atEk3btywGcuxY8dUuXJlNWnSRPny5ZOLi4t++OEHXblyxaJA9g8//KBWrVpp3rx58bpZSWhoqLlOUvRNSmbOnClPT0/169fPqv3atWvNf4l+UunSpS0KbdvSsmVLDR48WOPGjVP9+vWfGltc3NzctHz5clWuXFlly5ZVq1atVKxYMd26dUuLFy/W33//rZ49e1psm4Quf+jQoerSpYsqVaqkJk2a6PTp05o/f75y5MiRaD0UgoODNXnyZNWoUUPNmzfX1atX9fnnnytnzpzxqgEV/RfjZ+3VmCpVKrVq1UozZszQ4cOHlTdvXvXv31/Dhg1TjRo1VLduXR09elQzZsxQ8eLFLYrZS4+PmejjJ/omJbNmzVJUVJTN5OyOHTts/igsVKjQU4fx1KxZUwUKFNDkyZPVqVMnq1paT3re7dq8eXMdOHBAY8aM0a5du9S0aVMFBATo3r17OnDggJYsWaLkyZObewClSZMm3ttt69atqlixooYMGaKhQ4c+NZa4BAUFadGiRTKZTOYhx87OzipdurTWr1+vChUqPLVuY5EiReTs7Kxx48YpNDRU7u7uqlSpktKmTavAwEDNnDlTI0eOVM6cOZU2bVpVqlRJvXv31k8//aTatWurZcuWCgwM1L1797R//34tX75cp0+fjlc9oISIuf/je36OduHCBfOxGhYWpn379mn27NlKnTq1zSFvy5cvtzkEqmrVqkqXLl2csX788ceaMmWKxo4dq6VLl8bZtnbt2ho+fLhatWql0qVLa//+/Vq0aJHN82mFChW0bdu2eF+oRq9DWFiYLly4oPXr1+u3335T4cKFtWzZsjhf26ZNG924cUOVKlVS5syZdebMGX322WcqUqSIuZ5ZXMdOQkTHaRiGLl68qLlz5+rmzZuaNWuW1bn277//tlnbL0eOHCpVqlSc75MvXz7VqlVLX375pQYNGvRcNR737dun5s2bq2bNmgoKClLKlCl14cIFLViwQBcvXtSUKVPMF4vRSfoBAwaoadOmcnV1VZ06deTl5aU2bdpo7NixatOmjYoVK6bt27fbTE4MGzZM69atU1BQkD766CNz0id//vwW57QcOXJo5MiR6t+/v06fPq369esrefLkOnXqlH744Qe1a9dOvXr1StC65siRQylSpNCsWbOUPHlyeXl5qUSJEgoICEjw+ezYsWNauHChDMPQ7du3tW/fPi1btkx37941n7Pjem18fgfFdt5KiOg4Y0qXLl2sdegSauTIkdq4caPKli2rjz76SC4uLpo9e7YePXqk8ePHm9sl5HPWrl07zZ49Wy1bttSePXvk7++v5cuX67ffftOUKVOe2jvTltOnTysgIEAtWrTQ/Pnzn9r+VT3XPk3KlCn1ww8/qE6dOipcuLCaNm2q4sWLy9XVVefOnTOfM+PTQ75w4cJq0aKF5syZo1u3bql8+fLatWuXFixYoPr161vcoKRNmzbq0KGDGjZsqKpVq2rfvn1av359rN+hYWFh5s9B9O+MsmXLWtygZP78+Qm6FnjyvHrnzh398ssvWrFihUqXLq1q1apZtH3yuiGmmL8Rbendu7caN26s+fPnW93c5Vkl9Bjq3Lmzbt++rQEDBsjX19fixk3Po3bt2vr+++/19ttvKzg4WKdOndKsWbOUL1++RO09C8DOXuYtk/FizJs3z5Bk7N69O8522bJlM4KDgy2m3blzx+jevbuRMWNGw9XV1ciVK5cxYcIEIyoqyqLdgwcPjK5duxqpUqUyvLy8jDp16hjnzp0zJBlDhgyxaHvlyhWjU6dORpYsWQxXV1cjffr0RuXKlY05c+aY25w6dcqQZMybN88wDMO4du2a0alTJyNPnjyGl5eX4evra5QoUcL47rvvbK5r9OviUr58eUOS+WEymYyUKVMadevWNfbs2WNzubE9nnw/SUanTp1svufQoUMNScaWLVsspufPn98oX778U2OO6erVq0aPHj2MnDlzGu7u7kaKFCmMKlWqGD/99JNV2y1bthiSjGXLlsU6L2Zc06ZNM7Jly2a4u7sbb731lvHbb78ZgYGBRo0aNcxtYu4rwzCMFi1aGF5eXlbvM2TIECPmaWXu3LlGrly5DHd3dyNPnjzGvHnzbLbLli2b0aJFC4tpqVOnNkqWLBnb5nlqPIZhGP/995/h7Oxssezp06cbefLkMVxdXY106dIZHTt2NG7evGm1zJjHgY+Pj1G5cmVj06ZNFm2jt29sjyc/I7Y+h9Hmz59v8/gODg42smXLZjEtvts1Llu3bjUaNWpkZMiQwXB1dTV8fHyMYsWKGUOGDDEuXbpk1T4+223VqlWGJGPWrFnxjmP37t021/vgwYOGJCNv3rwW00eOHGlIMgYNGmS1LFvH0RdffGFkz57dcHZ2tvgcXL582QgODjaSJ09uSLL4jN65c8fo37+/kTNnTsPNzc1InTq1Ubp0aWPixIlGWFiYYRj/+2xMmDAh3uuakP0f3/NztmzZLI43JycnI23atEazZs2MEydOWLSNPkZie0Rvm6etW8uWLQ1nZ2er5Xt5eVls/4cPHxo9e/Y0MmTIYHh6ehplypQxdu7caZQvX97qnBgYGGikT5/+KVvQeh08PDyMzJkzG7Vr1za++uor4+HDh1avadGihcVnaPny5Ua1atWMtGnTGm5ubkbWrFmN9u3bWx33sR07MeO3dZ60ta29vLyMUqVKWX23Rb8+tseT27R8+fJG/vz5bW6brVu32vxe7tSpU4LODVeuXDHGjh1rlC9f3siQIYPh4uJi+Pn5GZUqVTKWL19u1X7EiBFGpkyZDCcnJ0OScerUKcMwDOP+/ftG69atDV9fXyN58uRGkyZNjKtXr9qMcdu2bUZgYKDh5uZmZM+e3Zg1a1as57QVK1YYZcuWNby8vAwvLy8jT548RqdOnYyjR48+dTvFPBYMwzB+/PFHI1++fIaLi4vFfkzI+SzmZzBFihRG0aJFjY8//tg4ePCgVftn/R0U23nL1ve8rXWN6zh78piObfvFdg6z9dvo77//NqpXr254e3sbyZIlMypWrGj8/vvvVq+N7+fMMB4fm61atTJSp05tuLm5GQULFrT67ojr/BXz2Nu/f78hyejXr59VW1vr/qqea+Pr0qVLRu/evY18+fIZnp6ehru7u5E9e3bjgw8+MLZv325zHUJCQqyWEx4ebgwbNswICAgwXF1djSxZshj9+/e3Ov9GRkYaffv2NVKnTm0kS5bMqF69unHixAmr7+ro3+Hbtm0z2rVrZ/j5+Rne3t7Gu+++a1y/ft1imZ999pkhyVi3bl2c62rrvOri4mJkz57d6N27t3Hnzh2L9jGvG2I+YsZq67orMjLSyJEjh5EjRw4jIiLCPD223zlxie8xFNvv/z59+hiSjOnTp1ssL+b+jO03dMxzQFRUlDF69GjzdUPRokWN1atXW51nEvL5A/DqMRkGlUIBPBYVFaU0adKoQYMG8Rrq+iIdOnRI+fPn1+rVq1/YEFYkvj59+mjJkiU6ceLEC7mbH15Pd+7cUcqUKTVlypQXUjsJeBacz15/M2bMUJ8+ffTff/89tUcfXpzoXoG7d+9+6k1Zoke97Nq16yVFBwCOgyHGgIN6+PCh3N3dLYa4ff3117px44YqVKhgv8D+35YtW1SqVCmSg0nMli1bNGjQIC6mkSDbt29XpkyZ1LZtW3uHAphxPnv9bdmyRV27diU5mEQYhqGtW7fGOgwYAPB86EEIOKitW7eqe/fuaty4sVKlSqW///5bc+fOVd68ebVnz56n1nYDAAAAnldCehACAF4cehACDsrf319ZsmTRtGnTdOPGDaVMmVIffPCBxo4dS3IQAAAAAAAHQg9CAAAAAAAAwIE52TsAAAAAAAAAAPZDghAAAAAAAABwYK9lDcJFe87bOwTgubxdMJO9QwAAhxb6INzeIQDPxdvjtfyZDwdCISwkdT4e9MeSJM+ine0dQqJ68M90e4fwwnDEAgAAAAAAAA6MBCEAAAAAAADgwEgQAgAAAAAAAA6M4iQAAAAAAABIfCb6pSUV7CkAAAAAAADAgZEgBAAAAAAAABwYCUIAAAAAAADAgVGDEAAAAAAAAInPZLJ3BIgnehACAAAAAAAADowEIQAAAAAAAODASBACAAAAAAAADowahAAAAAAAAEh8JvqlJRXsKQAAAAAAAMCBkSAEAAAAAAAAHBgJQgAAAAAAAMCBkSAEAAAAAAAAHBg3KQEAAAAAAEDiM5nsHQHiiR6EAAAAAAAAgAMjQQgAAAAAAAA4MBKEAAAAAAAAgAOjBiEAAAAAAAASn4l+aUkFewoAAAAAAABwYCQIAQAAAAAAAAdGghAAAAAAAABwYNQgBAAAAAAAQOIzmewdAeKJHoQAAAAAAACAAyNBCAAAAAAAADgwEoQAAAAAAACAA6MGIQAAAAAAABKfiX5pSQV7CgAAAAAAAHBgJAgBAAAAAAAAB0aCEAAAAAAAAHBg1CAEAAAAAABA4jOZ7B0B4okehAAAAAAAAIADI0EIAAAAAAAAODAShAAAAAAAAIADowYhAAAAAAAAEp+JfmlJBXsKAAAAAAAAcGAkCAEAAAAAAAAHRoIQAAAAAAAAcGDUIAQAAAAAAEDiM5nsHQHiiR6EAAAAAAAAgAMjQQgAAAAAAAA4MBKEAAAAAAAAgAOjBiEAAAAAAAASn4l+aUkFewoAAAAAAABwYCQIAQAAAAAAAAdGghAAAAAAAABwYNQgBAAAAAAAQOIzmewdAeKJHoQAAAAAAACAAyNBCAAAAAAAADgwEoQAAAAAAACAA6MGIQAAAAAAABKfiX5pSQV7CgAAAAAAAHBgJAgBAAAAAAAAB0aCEAAAAAAAAHBg1CAEAAAAAABA4qMGYZLBngIAAAAAAAAcGAlCAAAAAAAAwIGRIAQAAAAAAAAcGAlCAAAAAAAAwIFxkxIAAAAAAAAkPieTvSNAPNGDEAAAAAAAAHBgJAgBAAAAAAAAB0aCEAAAAAAAAHBg1CAEAAAAAABA4jPRLy2pYE8BAAAAAAAADowEIQAAAAAAAODASBACAAAAAAAADsyuCcKIiAgNHz5c58+ft2cYAAAAAAAASGwm0+v1eI3ZNUHo4uKiCRMmKCIiwp5hAAAAAAAAAA7L7kOMK1WqpG3bttk7DAAAAAAAAMAhudg7gJo1a6pfv37av3+/AgMD5eXlZTG/bt26dooMAAAAAAAAeP3ZPUH40UcfSZImT55sNc9kMikyMvJlhwQAAAAAAIDnZbL7wFXEk90ThFFRUfYOAQAAAAAAAHBYr1Qq9+HDh/YOAQAAAAAAAHAodk8QRkZGasSIEcqUKZO8vb118uRJSdKgQYM0d+5cO0cHAAAAAAAAvN7sniAcNWqU5s+fr/Hjx8vNzc08vUCBAvryyy/tGBkAAAAAAACemcn0ej1eY3ZPEH799deaM2eO3n33XTk7O5unFy5cWEeOHLFjZAAAAAAAAMDrz+4JwgsXLihnzpxW06OiohQeHm6HiAAAAAAAAADHYfcEYb58+bRjxw6r6cuXL1fRokXtEBEAAAAAAADgOFzsHcDgwYPVokULXbhwQVFRUfr+++919OhRff3111q9erW9w3st/frjYh3Z/auuXTwrFzd3ZcmVT5WbtVPqjFnMbe7euqGNi2fr5P49Cnv4QKkyZFZQ/XeV961y5jZLJw7U5TP/6d7tm/L0Sq6AAm+qSrO2Su6XWpJ07eI5rfnqU107f0YPH9xT8hSpVaBMJZVv8IGcXex+6OE1s+ev3fp6/lwdOnRQ10JCNHnKdFWsXMU8/5dNG7T8u6U6fOigQkNDtXTZD8qdJ695fmjoLc38/DP9sfM3Xb50SX5+KVWhUmV91PljJU+e3B6rBAcT1zEcHh6uGZ9N1a87tun8hfPy9vZWiZKl1bVbD6VNm85qWWFhYXq/eRMdO3rE6lgHXoR36lXXlUsXrabXb/SOuvUZqEePHmnm1AnavGGdwsLD9FbJMurWZ4BSpnr8myH01i2NHNxPJ08c0+3QW0rhl1JlyldU244fy8vb+2WvDhzQvC/naMsvG3X61Em5u3uoUJGi6tKtp/wDAsxtvl/+ndb9vFpHDx/SvXv3tOXXP5Xcx8diOUcOHdS0KZN06OABOTs5qVKVaureu6+SJfN62asEBzNv7uNj+MwTx3Dnbj3l7/+/Y/jatRBNmzxBf/6xU/fv3VM2f3992LaDKlWpJknas3uXOrRpYXP58xd9p/wFCr6UdcFrxmT3fmmIJ7vvqXr16mnVqlXatGmTvLy8NHjwYB0+fFirVq1S1apV7R3ea+nM4X9VrGpdfTh8ut7rP16RkZFaNLaPwh4+MLdZOXOsrl88p6Y9R6rD2C+Up3iQlk8doUunj5vb+OcrokZdB6nTxAVq3G2obl65qGVThpnnOzs7q3DZanq3/3h1mrhA1T/4SP9sXqOty+e/zNWFg3jw4IHeeCOP+g8YHOv8IkUD1bV7L5vzQ65eVUjIVXXv2UfLflilYSPH6PffdmjYkAEvMmzALK5j+OHDhzp8+JDatv9IS75doUmffqYzp0+pW5ePbC5ryuQJSpMm7YsOGTCbPX+JVvy8xfyYOH2OJKl85eqSpM8/Ha/fd2zT0DGTNHXWPF0LuarBfbubX+/kZFLZchU1auJn+mb5avUbPFJ7dv2hyWOH22V94Hj+/mu3GjdtrnkLl+rzOXMVERGuzh1a68H9++Y2Dx88UOkyQWrVpr3NZYRcvaqP2rVWlixZNX/ht5o28wv9998JDR34yctaDTiwv//arcbvNNdX3yzV9NmPj+EuMY7hoQP66czp05o89XMtWfGjKlauqv69u+vo4UOSpEJFimjtL9stHvUaNFLGTJmVL38Be60agJfklejGFRQUpI0bN9o7DIfxbr+xFs/rdeijSR0a6tKp48qWt5Ak6dyxgwr+sJsy5cwjSSr39nv6c+1yXTp1TBn8c0mSStZqZF5GijTpVKZuM307ebAiIyLk7OIiv3QZ5Zcuo0Wb04f26uzR/S96FeGAygaVU9mgcrHOr12nniTp4oXzNufnzPWGJn36mfl5lixZ1blLdw3o31sRERFyodcrXrC4juHkyZNr1hdfWUzr98kgvdessS5duqgMGf53rv11x3b98ftvmvDpNP326/YXGjMQLYVfSovni7+eq4yZs6jIm8V09+4d/fzT9xo4YpzeLF5CktR38Ai1aFJPB/fvU/6ChZXcx1f1Gr1jfn36DBlVv1FTLf1m3ktdDziuz2Z9YfF86IgxqlqhjA4fOqg3ixWXJDV//3HPqr9277K5jB3bt8rFxUV9BwyWk9PjfhifDByqpo3q6dzZM8qSNdsLXAM4us9mWh7DQ4aPUbWKZXT48EG9Gfj4GP533171GzBY+Qs+vuZr3a6jlixcoMOHDyp33nxydXVT6tRpzMuICA/X9i2b1aTZuzK95ndvBfAK9CCE/T26f0+S5On9v2GUWd7Ir4N/bNGDu7dlREXpwO+bFREeLv+8RWwu48Hd29r/2y/Kkit/rMOHb1y+oP/+3a1seQsn+joAL8Kdu3fk5e1NchCvpDt37shkMil58v8Nb7t+7ZpGDB2kEWPGydPDw47RwZGFh4dr49rVqlXnbZlMJh07fEgREREKfKukuU02/+xKlz6DDu3fZ3MZ10KuavuWTSr8ZrGXFTZg4e7dO5IkH1/feL8mLCxMrq6u5uSgJLl7uEuS9v7zd+IGCDyF+Rj2+d8xXKhwEW1cv1ahobcUFRWlDWvX6NGjMAUWe8vmMrZv26LQ0FuqU7/BS4kZgH3Z/arXz8/P5l8jTCaTPDw8lDNnTrVs2VKtWrWy+fpHjx7p0aNHFtPCwx7J1c39hcT7ujGiorT+m8+V5Y0CSpvlf/UpGnUdrOXTRmhCu7fl5OwsVzcPNek+TCnTZ7J4/aYlc7R7w48Kf/RQmXLmVbPeo6ze46shXXTp9HFFhofrzUrBqtio5YteLeC53bx5U1/MnqmGjZrYOxTAyqNHjzTt04mqUTNY3v9fn80wDA0e2F+NmjRV/vwFY+0tC7xov279RXfv3lGN2o97bt+4fk2urq4WyWxJ8kuZSjeuX7OYNnxgH/22bYsePXqo0kEV1HvAMAEvW1RUlCaNH6PCRd9UzlxvxPt1xd8qoU8njtPX8+aq2Xvv68GDB/psymRJ0rWQkBcVLmAlKipKk8ePUeEilsfwmAmf6pM+PVSlXCk5u7jIw8NDEz79LNberT/+sFwlS5dRunTpX1boeB3R+zTJsHsPwsGDH3fBDw4O1rBhwzRs2DAFBwfLyclJnTp10htvvKGOHTvqiy++sPn6MWPGyNfX1+Lx07zPX/JaJF0/z5umq+dOq2GXgRbTtyybp4f37+q9TyaozciZKlmrkZZPG64rZ09atCsd/I7ajZ6ld/uPk5OTs1bOHCfDMCzaNOw6SO1GzVKDzgN0fO+f+n3Ndy98vYDncffuXXXt1F7Zs+dQ+46d7R0OYCE8PFx9enWTIemTQUPN05cs/kb379/Th23a2S02QJJ+/ukHlShVVqmfoQ5mp259NOebbzVq4jRdPH9OM6ZMeAERAnEbN2q4/jtxXKPHTUrQ63LkzKVhI8Zo0dfzVfatN1W9YpAyZcqsVKlSy+TEBTJenvGjh+u//45r1HjLY3jW59N0584dfT7nK329eJnefb+l+vfprhPHj1kt48qVy/rj999U7+1GVvMAvJ7s3oPw119/1ciRI9WhQweL6bNnz9aGDRu0YsUKFSpUSNOmTVPbtm2tXt+/f3/16NHDYtr3B/kLXXysnTdNx//5Qy0GfyqfVP+rNXHjykXt3rBSHcbPVdrM/pKk9Nly6OyR/fpr448Kbv2/ouLJfHyVzMdXqTJkUZqM2TSlS1OdP35IWd7Ib27jm+rxBUKazP6KiorU6i8/VangxnJycn45KwokwL17d9WpQxslS+alyVOny9XV1d4hAWbh4eHq26u7Ll28qDlz55t7D0rS7j//1L/79qpEYCGL17zbtJFqBtfWiFHjXna4cECXL13Unt1/aPi4T83TUqZKrfDwcN25c9uiF+HNG9fNdzGOlip1aqVKnVrZ/LMruY+vurZroQ9at1eqJ2piAS/SuNEj9Ov2bZoz7xulS5/wXlM1gmurRnBtXb9+TZ6enjLJpEXfzFfmzFleQLSAtfGjR2jH9m2a89U3Fj3/zp87q++WLtLSFT8pR87HNeXfyJ1H//z9l5YtXaz+T/zRUZJWrfxevr4pVK58xZcZPgA7snsPwvXr16tKlSpW0ytXrqz169dLkmrVqqWTJ09atZEkd3d3+fj4WDwYXhw3wzC0dt40HfnrV70/YKL80mawmB/+6KEkWQ39Njk5yYiy7B1oudwoSVJkRHjsbaIMRUVGxLkcwF7u3r2rju1ay9XVVVM+myF3d84leHVEJwfPnj2jWV/MU4oUfhbz+/QfoG+Xr9TSZT9o6bIf9NmM2ZKksRMmq3OX7rYWCSS6tatWKoVfSpUs878b7ryRN59cXFz09+4/zdPOnjmlK5cvKV/B2OsSG1GPf1eEhYW9uICB/2cYhsaNHqGtmzdp5pfzlClz5udaXqpUqZUsmZc2rF8rNzd3lShZOpEiBWwzDEPjo4/hL6yP4YcPH1/jPVkjU5KcnZwV9f/XcU8ua9WPP6hWnXpy4Y/lgMOwew/ClClTatWqVere3fLiZdWqVUqZ8vEd8e7du6fkyZPbejmewdp507T/91/0Ts8RcvdMpru3bkiS3JN5ydXNXakzZlXKdJm0Zu6nqtq8gzyT++joX7/q5IE9atbrcY3B8ycO6+J/R5U1dwF5eCXXzasXtWXZPPmly6jMufJJkvb/uklOLi5KmyVALi6uunjqmDZ/+6Xyl6wQ641MgGd1//49nTt71vz8woXzOnrksHx8fZUhQ0aFht7S5UuXdPXqVUnS6dOnJD3urZI6dRrdvXtXH7VvrYcPHmjU2Am6d++u7t27K0ny80spZ2d6vOLFiusYTp06jXr3+FhHDh/S1M9nKSoqUteuPe4t7+vrK1dXN4s7GUtSsmTJJD2+I/ez9IIBEioqKkrrVq9U9eC6Fjd38vZOrlp1G2jGlAny8fFVMi8vTZs4RvkLFlb+/08Q/vHbdt28cV258xWQp2cynT75n2Z9NkkFChdVhoyZYntLINGMGzVc69au0aSp05XMy8t8jvX2Ti6P/7/p07VrIbp+7ZrOnz0jSTpx/JiSeXkpfYYM8vVNIUn6dskiFS5cRJ7JkunPP37X1MkT1eXjHkru42PzfYHEMm70cK1fu0YTp9g+hv39A5Qla1aNGTFEH/foI98UKbR18y/684/f9elnMy2WtXvXH7p44bzqN2B4MRKBye790hBPJiNmwbiX7IsvvlDHjh1Vq1YtvfXW47sn7d69Wz///LNmzZql1q1ba9KkSdq1a5e+/fbbeC1z0R4Ks8dlePPKNqfXbd9bRcrXkCRdv3Revyz9UueO7lfYo4dKmS6jSgU3UaGgqpKkK2dPav3Xn+vK2f8U9uihkqdIpRyFiivo7Xflk/LxMKCDO7fo91Xf6vrl8zIMQylSp1PBslVUsmYjubi5vZyVTaLeLsjFUEL9tftPtf2whdX0OnXra/iosfpp5fcaMugTq/ntO3ZSh4+6xPp6SVqzbpMyZnq+ngTA08R1DHf4qLOCa1j3tpekL75aoGLFS1hNv3jhvIJrVNHSZT8od568iR7v6y70Qey94WHb7j9+V++u7fXNslXKks3fYt6jR480c+oE/bJhrcLDwlW8ZGl16zNQqVI/HmL8z1+79OXMaTp96qTCw8OUNm16BVWsrOYtWlvd3ATx4+3BH2MTolgh2+fJISNGq069tyVJs2dM1xezrGudP9lm8Cd99duObbp//778A7LrvRatFFyn3osL/DVm36vUpKd4YdvH8ODh/zs+z545relTJ2vfP3/r/v37ypI1q977oJVqxThGB/brpUuXLmrugsUvPO7XmY8HiTFJ8qwx2d4hJKoH63o8vVESZfcEoST99ttvmj59uo4ePSpJyp07t7p06aLSpZ+tKz4JQiR1JAgBwL5IECKpI0GIpM7+V6nA8yFB+BgJwqTjlfjlUKZMGZUpU8beYQAAAAAAAAAO55VIEEZFRenEiRO6evWqoqIsC6SWK1cullcBAAAAAADglRXj5qd4ddk9QfjHH3+oefPmOnPmjGKOdjaZTIqMjLRTZAAAAAAAAMDrz+4Jwg4dOqhYsWJas2aNMmTIIBPZZQAAAAAAAOClsXuC8Pjx41q+fLly5sxp71AAAAAAAAAAh2P3BGGJEiV04sQJEoQAAAAAAACvExN3c04q7J4g7NKli3r27KnLly+rYMGCcnV1tZhfqFAhO0UGAAAAAAAAvP7sniBs2LChJOnDDz+0msdNSgAAAAAAAIAXy+4JwlOnTtk7BAAAAAAAAMBh2T1BmC1bNknSoUOHdPbsWYWFhZnnmUwm83wAAAAAAAAkISaTvSNAPNk9QXjy5Em9/fbb2r9/v0wmkwzDkPQ4OSiJIcYAAAAAAADAC2T328l8/PHHCggI0NWrV5UsWTIdOHBA27dvV7FixbR161Z7hwcAAAAAAAC81uzeg3Dnzp3avHmzUqdOLScnJzk7O6ts2bIaM2aMunbtqn/++cfeIQIAAAAAAACvLbv3IIyMjFTy5MklSalTp9bFixclPa5NePToUXuGBgAAAAAAALz27N6DsECBAtq3b58CAgJUokQJjR8/Xm5ubpozZ46yZ89u7/AAAAAAAADwLEx275eGeLJ7gnDgwIG6d++eJGn48OGqXbu2goKClCpVKn377bd2jg4AAAAAAAB4vdk9QVi9enXz/3PmzKkjR47oxo0b8vPzM9/JGAAAAAAAAMCLYfcEoS0pU6a0dwgAAAAAAACAQ3glE4QAAAAAAABI4qhBmGSwpwAAAAAAAAAHRoIQAAAAAAAAcGAkCAEAAAAAAAAHRg1CAAAAAAAAJD6Tyd4RIJ7oQQgAAAAAAAA4MBKEAAAAAAAAgAMjQQgAAAAAAAA4MGoQAgAAAAAAIPGZ6JeWVLCnAAAAAAAAAAdGghAAAAAAAABIRP7+/jKZTFaPTp06SZIePnyoTp06KVWqVPL29lbDhg115coVi2WcPXtWwcHBSpYsmdKmTavevXsrIiLCos3WrVv15ptvyt3dXTlz5tT8+fOfKV4ShAAAAAAAAEAi2r17ty5dumR+bNy4UZLUuHFjSVL37t21atUqLVu2TNu2bdPFixfVoEED8+sjIyMVHByssLAw/f7771qwYIHmz5+vwYMHm9ucOnVKwcHBqlixovbu3atu3bqpTZs2Wr9+fYLjNRmGYTznOr9yFu05b+8QgOfydsFM9g4BABxa6INwe4cAPBdvD0qNI2l7/a5S4Wh8POiPJUme9efYO4RE9WBlu2d+bbdu3bR69WodP35ct2/fVpo0abR48WI1atRIknTkyBHlzZtXO3fuVMmSJbV27VrVrl1bFy9eVLp06SRJs2bNUt++fRUSEiI3Nzf17dtXa9as0YEDB8zv07RpU926dUvr1q1LUHwcsQAAAAAAAMBTPHr0SLdv37Z4PHr06KmvCwsL08KFC/Xhhx/KZDJpz549Cg8PV5UqVcxt8uTJo6xZs2rnzp2SpJ07d6pgwYLm5KAkVa9eXbdv39bBgwfNbZ5cRnSb6GUkBAlCAAAAAAAA4CnGjBkjX19fi8eYMWOe+rqVK1fq1q1batmypSTp8uXLcnNzU4oUKSzapUuXTpcvXza3eTI5GD0/el5cbW7fvq0HDx4kaN0YewAAAAAAAAA8Rf/+/dWjRw+Lae7u7k993dy5c1WzZk1lzJjxRYX23EgQAgAAAAAAIPGZXq+Bq+7u7vFKCD7pzJkz2rRpk77//nvztPTp0yssLEy3bt2y6EV45coVpU+f3txm165dFsuKvsvxk21i3vn4ypUr8vHxkaenZ4LifL32FAAAAAAAAPCKmDdvntKmTavg4GDztMDAQLm6uuqXX34xTzt69KjOnj2rUqVKSZJKlSql/fv36+rVq+Y2GzdulI+Pj/Lly2du8+QyottELyMhSBACAAAAAAAAiSwqKkrz5s1TixYt5OLyv0G8vr6+at26tXr06KEtW7Zoz549atWqlUqVKqWSJUtKkqpVq6Z8+fLp/fff1759+7R+/XoNHDhQnTp1Mvdi7NChg06ePKk+ffroyJEjmjFjhr777jt17949wbEyxBgAAAAAAABIZJs2bdLZs2f14YcfWs379NNP5eTkpIYNG+rRo0eqXr26ZsyYYZ7v7Oys1atXq2PHjipVqpS8vLzUokULDR8+3NwmICBAa9asUffu3TV16lRlzpxZX375papXr57gWE2GYRjPtpqvrkV7zts7BOC5vF0wk71DAACHFvog3N4hAM/F24N+AEjaXr+rVDgaHw8GbEqSZ4O59g4hUT34vrW9Q3hhOGIBAAAAAAAAB0aCEAAAAAAAAHBgJAgBAAAAAAAAB0ZxEgAAAAAAACQ6k8lk7xAQT/QgBAAAAAAAABwYCUIAAAAAAADAgZEgBAAAAAAAABwYNQgBAAAAAACQ6KhBmHTQgxAAAAAAAABwYCQIAQAAAAAAAAdGghAAAAAAAABwYNQgBAAAAAAAQOKjBGGSQQ9CAAAAAAAAwIGRIAQAAAAAAAAcGAlCAAAAAAAAwIGRIAQAAAAAAAAcGDcpAQAAAAAAQKIzmbhLSVJBD0IAAAAAAADAgZEgBAAAAAAAABwYCUIAAAAAAADAgVGDEAAAAAAAAImOGoRJBz0IAQAAAAAAAAdGghAAAAAAAABwYCQIAQAAAAAAAAdGDUIAAAAAAAAkOmoQJh30IAQAAAAAAAAcGAlCAAAAAAAAwIGRIAQAAAAAAAAcGDUIAQAAAAAAkOioQZh00IMQAAAAAAAAcGAkCAEAAAAAAAAHRoIQAAAAAAAAcGDUIAQAAAAAAEDiowRhkkEPQgAAAAAAAMCBkSAEAAAAAAAAHBgJQgAAAAAAAMCBUYMQAAAAAAAAic5koghhUkEPQgAAAAAAAMCBkSAEAAAAAAAAHBgJQgAAAAAAAMCBUYMQAAAAAAAAiY4ahEkHPQgBAAAAAAAAB0aCEAAAAAAAAHBgr+UQ43oFMtk7BOC5XLsbZu8QgOeS1sfd3iEAzyVFMjd7hwA8F0Z0AQCAhHgtE4QAAAAAAACwL2oQJh0MMQYAAAAAAAAcGAlCAAAAAAAAwIGRIAQAAAAAAAAcGDUIAQAAAAAAkOioQZh00IMQAAAAAAAAcGAkCAEAAAAAAAAHRoIQAAAAAAAAcGDUIAQAAAAAAEDiowRhkkEPQgAAAAAAAMCBkSAEAAAAAAAAHBgJQgAAAAAAAMCBUYMQAAAAAAAAic5koghhUkEPQgAAAAAAAMCBkSAEAAAAAAAAHBgJQgAAAAAAAMCBkSAEAAAAAAAAHBg3KQEAAAAAAECi4yYlSQc9CAEAAAAAAAAHRoIQAAAAAAAAcGAkCAEAAAAAAAAHRg1CAAAAAAAAJDpqECYd9CAEAAAAAAAAHBgJQgAAAAAAAMCBkSAEAAAAAAAAHBg1CAEAAAAAAJD4KEGYZNCDEAAAAAAAAHBgJAgBAAAAAAAAB0aCEAAAAAAAAHBg1CAEAAAAAABAojOZKEKYVNCDEAAAAAAAAHBgJAgBAAAAAAAAB0aCEAAAAAAAAHBg1CAEAAAAAABAoqMGYdJBD0IAAAAAAADAgZEgBAAAAAAAABwYCUIAAAAAAADAgVGDEAAAAAAAAImOGoRJBz0IAQAAAAAAAAdGghAAAAAAAABwYCQIAQAAAAAAAAdGDUIAAAAAAAAkOmoQJh30IAQAAAAAAAAcGAlCAAAAAAAAwIGRIAQAAAAAAAAcGDUIAQAAAAAAkPgoQZhk0IMQAAAAAAAAcGAkCAEAAAAAAAAHRoIQAAAAAAAAcGDUIAQAAAAAAECiM5koQphU0IMQAAAAAAAAcGAkCAEAAAAAAAAHRoIQAAAAAAAAcGDUIAQAAAAAAECiowZh0kEPQgAAAAAAAMCBkSAEAAAAAAAAHBgJQgAAAAAAAMCBUYMQAAAAAAAAiY4ahEkHPQgBAAAAAAAAB0aCEAAAAAAAAHBgJAgBAAAAAAAAB0aCEAAAAAAAAHBg3KQEAAAAAAAAiY97lCQZ9CAEAAAAAAAAHJjdE4SVKlXSrVu3rKbfvn1blSpVevkBAQAAAAAAAA7E7gnCrVu3KiwszGr6w4cPtWPHDjtEBAAAAAAAADgOu9Ug/Pfff83/P3TokC5fvmx+HhkZqXXr1ilTpkz2CA0AAAAAAADPyWSiCGFSYbcEYZEiRWQymWQymWwOJfb09NRnn31mh8gAAAAAAAAAx2G3BOGpU6dkGIayZ8+uXbt2KU2aNOZ5bm5uSps2rZydne0VHgAAAAAAAOAQ7JYgzJYtmyQpKirKXiEAAAAAAAAADs/uNylZsGCB1qxZY37ep08fpUiRQqVLl9aZM2fsGBkAAAAAAACeVXRpudfl8Tqze4Jw9OjR8vT0lCTt3LlT06dP1/jx45U6dWp1797dztEBAAAAAAAArze7DTGOdu7cOeXMmVOStHLlSjVq1Ejt2rVTmTJlVKFCBfsGBwAAAAAAALzm7N6D0NvbW9evX5ckbdiwQVWrVpUkeXh46MGDB/YMDQAAAAAAAHjt2b0HYdWqVdWmTRsVLVpUx44dU61atSRJBw8elL+/v32DAwAAAAAAwDN53ev2vU7s3oPw888/V6lSpRQSEqIVK1YoVapUkqQ9e/aoWbNmdo4OAAAAAAAAeL2ZDMMw7B1EYrv76LVbJTiYG/fC7B0C8FzS+rjbOwTgubx+v47gaOiwAQD25WH38ZqvBv+PV9s7hER1empte4fwwtj9kN2+fXuc88uVK/eSIgEAAAAAAAAcj92HGFeoUMHqUbFiRfMDAAAAAAAASY/JZHqtHgl14cIFvffee0qVKpU8PT1VsGBB/fXXX+b5hmFo8ODBypAhgzw9PVWlShUdP37cYhk3btzQu+++Kx8fH6VIkUKtW7fW3bt3Ldr8+++/CgoKkoeHh7JkyaLx48cnOFa7Jwhv3rxp8bh69arWrVun4sWLa8OGDfYODwAAAAAAAEiQmzdvqkyZMnJ1ddXatWt16NAhTZo0SX5+fuY248eP17Rp0zRr1iz9+eef8vLyUvXq1fXw4UNzm3fffVcHDx7Uxo0btXr1am3fvl3t2rUzz799+7aqVaumbNmyac+ePZowYYKGDh2qOXPmJCjeV7YG4bZt29SjRw/t2bMnwa+lBiGSOmoQIqmjBiGSulfz1xEQf9QgBAD7ogbhYwHd1tg7hER1ZFwVPXr0yGKau7u73N2tr3/69eun3377TTt27LC5LMMwlDFjRvXs2VO9evWSJIWGhipdunSaP3++mjZtqsOHDytfvnzavXu3ihUrJklat26datWqpfPnzytjxoyaOXOmBgwYoMuXL8vNzc383itXrtSRI0fivW5270EYm3Tp0uno0aP2DsNh/P3XbnXr3EHVKwcpsFAebdm8yWJ+YKE8Nh9fz5srSbp44byGDxmgOjUqq3Txwqpbq6pmfT5N4eEkuvDiRUZGav7s6Xq/QQ0Fly+uDxrV0sKvZuvJv3/cvHFd40cM1Dt1Kqt2hbfUv1sHnT93xmI5N65f09hhn6hJcEXVqfiWOrZooh1bNr7s1QEkSXO/mK3mTRqqVPGiqhBUSt26fKTTp06a54feuqUxo0aobnB1vfVmIVWvXEFjR4/UnTt37Bg1YNtXX85RkQK5NX7sKPO0a9dCNKBfb1UuX0YlixdR08Zva9PG9XaMErD03dLFavR2HZV+602VfutNvd/8Hf26Y5t5/vChgxVco4reerOQKpQtqY87d9Spk//ZMWLA0p6/dqvLRx1UpUJZFc6fW5t/2RRr2xHDBqtw/txa+PX8lxcgkASNGTNGvr6+Fo8xY8bYbPvTTz+pWLFiaty4sdKmTauiRYvqiy++MM8/deqULl++rCpVqpin+fr6qkSJEtq5c6ckaefOnUqRIoU5OShJVapUkZOTk/78809zm3LlypmTg5JUvXp1HT16VDdv3oz3utk9p/3vv/9aPDcMQ5cuXdLYsWNVpEgR+wTlgB48eKA3cudR3bcbqnf3Llbz12+2zHj//ut2DR8yUJWqVpMknT51SlFRUfpk8DBlyZpN/x0/rpHDBunBgwfq3qvvS1kHOK5vv/lKq374Tn0GjVS27Dl07PBBTRw1WF7e3nq7ybsyDEND+n4sFxcXDR83Vcm8vLRiyTfq27Wdvlz8gzw9k0mSxg0foHt37mj4+GnyTeGnzRt+1siBvfX5V0uUM3deO68lHM1fu3fpnWbvKn/BgoqMiNRnUyerQ9vW+v6nNUqWLJmuhlxVyNWr6tGrr3LkyKmLFy9o5PChCrl6VZOmTLN3+IDZgf3/avmypXrjjdwW0wf276s7d25ryvSZ8kvhp7U/r1Kfnt20+NsVypM3n52iBf4nbbr0+rh7L2XNlk2GYWjVjyv1cedO+nbFD8qZM5fy5cuv4Np1lD5DBt0ODdXMzz9Th7at9fOGX+Ts7Gzv8AE9eHBfuXPnVv0GDdXj486xtvtl00bt37dPadKmfYnRwWG8Zj3a+/fvrx49elhMs9V7UJJOnjypmTNnqkePHvrkk0+0e/dude3aVW5ubmrRooUuX74s6XEHuSelS5fOPO/y5ctKG+Oz6eLiopQpU1q0CQgIsFpG9LwnhzTHxe4JwiJFishkMinmSOeSJUvqq6++slNUjqdMUDmVCYr9jtGpU6exeL51y2YVK15CmTNnkSSVLhuk0mWDzPMzZ86iM6dPafl3S0gQ4oU7tH+fSgdVVIkyj4/h9BkyacvGtTp66IAk6cK5Mzp84F99seh7+WfPKUnq2meg3qldUVs2rlWtug3/fzl71bX3QOXJX1CS9G6rdlqx9BsdO3qIBCFeuplz5lo8Hz5qrCoGldLhQwcVWKy4cuV6Q5OnfmaenyVrVnX5uJs+6dtbERERcnGx+1c8oPv37+mTfr01eOhIfTF7psW8fXv/0YBBQ1SwYCFJUtv2H2nh1wt06OBBEoR4JVSoWMnieZePu+u7pUv07769ypkzlxo1ecc8L1OmzOrctZsaN6inixcuKEvWrC87XMBK2aDyKhtUPs42V65c0djRIzRzzlx16dj+JUUGJF2xDSe2JSoqSsWKFdPo0aMlSUWLFtWBAwc0a9YstWjR4kWG+UzsPsT41KlTOnnypE6dOqVTp07pzJkzun//vn7//XflyZPH3uHBhuvXr+nXHdtU7+2Gcba7e/eOfHx9X1JUcGT5ChbWP3/9qfNnT0uS/jt+VAf2/aPipcpKksLDHg91d3P734ncyclJrq5uOrDvnyeWU0TbNq3X7dBQRUVFacvGtQoPe6TCRYu/vJUBYnH3/4cOx3VevXvnrry9vUkO4pUxeuRwBZUrr5KlSlvNK1ykqNavW6vQ0FuKiorSup/X6FHYIxV76y07RArELTIyUmt/XqMHD+6rcOGiVvPv37+vH3/4XpkyZ1b69OntECGQcFFRURrQr7datmqtnDlz2Tsc4LWTIUMG5ctn+UfPvHnz6uzZs5Jk/r64cuWKRZsrV66Y56VPn15Xr161mB8REaEbN25YtLG1jCffIz7sfgWRLVu253r9o0ePrApEhsst3hldJNzqH1fKK5mXKlWpFmubc2fPaOmSherWo89LjAyOqukHrXX//j192LSenJycFRUVqVbtu6hy9WBJUhb/AKVNn0FzZ05Vt76D5eHpqRVLv1HI1Su6cf2aeTmDRk7QyEF91LBGkJydXeTu4aEhY6coUxZ6AcC+oqKiNH7caBUp+qZy5XrDZpubN29ozqwZatj4HZvzgZdt3c9rdOTwIS1autzm/PGTpqhvr+4qX6aEXFxc5OHhoclTpitr1uf7bQgkpuPHjur95k0VFvZIyZIl06fTPleOnDnN879dskifTpqoBw/uyz8gQLO/mCfXJ2pAAa+yeXO/kLOLi5q/94G9QwFeS2XKlLG6t8axY8fMebCAgAClT59ev/zyi7nE3u3bt/Xnn3+qY8eOkqRSpUrp1q1b2rNnjwIDAyVJmzdvVlRUlEqUKGFuM2DAAIWHh8vV1VWStHHjRuXOnTvew4ulVyBBOG2a7TpJJpNJHh4eypkzp8qVKxdrHY8xY8Zo2LBhFtP6DxisTwYNTexQ8f9+XLlCNYNrx5qEvXrlijp3bKsqVWuoQaMmLzk6OKJtv6zX5vVr1H/YWPkH5NCJ40c1c8p4pUqdRtWC68nFxVVDxnyqSaOHqEH1snJydtabxUo87mH4RHmD+XM+1707tzVu2hz5pvDT79s3a+TA3vp05jwF5LSdlAFehtEjh+m/48c1/5vFNuffvXtXnTu2V/YcOdTho9hrDAEvy+VLlzR+7CjN+uKrWH8vzJg+VXfu3NbsL+crRQo/bdm8SX16ddO8BYuUK0a9QsBe/P0D9N2Klbp79442blivQZ/01dz5C81Jwlq166pk6TK6FhKiBfPmqnfPblqwcAmdFfDKO3TwgBZ987WWLv9eJm57jhfIkY+v7t27q3Tp0ho9erSaNGmiXbt2ac6cOZozZ46kx9umW7duGjlypHLlyqWAgAANGjRIGTNmVP369SU97nFYo0YNtW3bVrNmzVJ4eLg6d+6spk2bKmPGjJKk5s2ba9iwYWrdurX69u2rAwcOaOrUqfr0008TFK/JiFn87yULCAhQSEiI7t+/b85s3rx5U8mSJZO3t7euXr2q7Nmza8uWLcqSJYvV6+lBmPgCC+XRxCnTVbFSFat5/+z5S21avacly1bqjdzWQ8BDrl5Ru9YfqGDBIho6coycnOw+ij1JunGPuz8nRPN6VfXO+61Vr1FT87RF8+bol3Wr9dW3P1m0vXf3jsLDw5XCL6W6tG6uXHnyq2vvAbp4/pxaNA62qFMoSX26tFXGzFnVre+gl7Y+r4O0PpyDE8vokcO1dcsv+mrBQnPd1yfdu3dXHdu1kYeHhz6bMZvvv0Ri319HSd/mXzapx8edLP7AGxkZKZPJJCcnJ61ctU51alXV8pWrLYa1tW/TUlmyZNXAIcPtEfZrxYGvx16odq1bKnOWrBo81PoYDQ8LU9nSb2nosJGqGVzbDtEBsSucP7c+nfa5KlV+fI238Ov5mjh+rMX1WmRkpJycnJQ+fQat3bjZXqG+Njzs3h3r1ZC9x8/2DiFRnZxcK0HtV69erf79++v48eMKCAhQjx491LZtW/N8wzA0ZMgQzZkzR7du3VLZsmU1Y8YMvfHG/zqo3LhxQ507d9aqVavk5OSkhg0batq0afL29ja3+ffff9WpUyft3r1bqVOnVpcuXdS3b8LuB2H3Q3b06NGaM2eOvvzyS+XIkUOSdOLECbVv317t2rVTmTJl1LRpU3Xv3l3Ll1sPUbFVIPLuI37Vvygrf1iuvPny20wOXr1yRe3bfKC8efNryIjRJAfx0jx8+FBOTpZXQk5OToqycYXv5Z1cknT+3BkdO3JILdo97m316OEDSZIpxnHr5Owsw4h6EWEDcTIMQ2NGjdDmXzZq7vxvbCYH7969q47tWsvNzU1Tp88kOYhXRomSJbX8h1UW0wYP7K+AgOxq1bqtHv7/OdfJFOOc6+Rs89wNvCqioqLMtY1jMiTJMBQWy3zgVVK7bj2ViFEftmO71qpdp57qv93ATlEBr5/atWurdu3Y/2hkMpk0fPhwDR8e+x9HU6ZMqcWLbY8kilaoUCHt2LHjmeOUXoEE4cCBA7VixQpzclCScubMqYkTJ6phw4Y6efKkxo8fr4YN474hBp7P/fv3dO7/C2VK0sUL53X0yGH5+PoqQ4bH3Vbv3r2rTRvW27wr8dUrj3sOZsiQUd169tXNmzfM82LeARlIbCXLltfi+V8obboMypY9h04cPaIVS79R9dr1zW22/bJBKfz8lDZdBp3677hmfDpOpctVVLESj38YZfEPUMbMWTV13HC169xTPr4p9Nv2zfp7106NmDjdTmsGRzZ6xDCt/Xm1pnw2Q17JvHQtJESS5J08uTw8PHT37l11aPuhHj58oNFjJ+je3bu6d/euJMkvZcpYS3MAL4OXl7dyxqiX6emZTL4pUihnrjcUHh6uLFmzaeTwwereq69S+KbQls2b9MfO3zTt89l2ihqwNPXTSSobVE7pM2TQ/Xv39POa1fpr9y7NnDNX58+d0/p1P6tU6TLy80upK1cu66sv58jd3UNly8V911jgZbl/7575ZgiSdOH8eR05fFi+vr7KkDGjUqSwrE3m6uKq1KlTyz8g+8sOFcArwO4JwkuXLikiIsJqekREhC5fvixJypgxo+78/90b8WIcOnhA7Vv/7zbbkyeMlSTVrltfw0Y+/v+GdWtkyFD1msFWr//jj9907uwZnTt7RjWrWv4o2vPvkRcYOSB17tFf8+dM17SJo3Trxg2lSpNGwfUb6b0PO5jb3LgeotnTJujmjetKmTqNqtaoo3c/bG+e7+LiqlGTP9fcGVM0qHcXPXxwXxkzZ1XvQSNVonSQPVYLDu67b5dIklq3fN9i+vCRY1Tv7QY6fOig9v+7T5JUu2ZVizY/b/hFmTJlfjmBAs/A1dVV02fO0bRPJ+njTh10/8F9Zc2SVSNGjVUQyRW8Im7cuK6B/fsqJOSqvJMn1xtv5NbMOXNVqnQZXb16RX/v+UsLv1mg26G3lSp1KgUGFtPXi5YoVapU9g4dkCQdPHhAbVr97wYkE8ePkSTVrfe2Rowea6+w4GAcuQZhUmP3GoTBwcG6fPmyvvzySxUtWlSS9M8//6ht27ZKnz69Vq9erVWrVumTTz7R/v3747VMhhgjqaMGIZI6ahAiqWOUK5I6rscAwL6oQfhYjp5r7R1CovpvUk17h/DC2L1I3Ny5c5UyZUoFBgaa6wkWK1ZMKVOm1Ny5cyVJ3t7emjRpkp0jBQAAAAAAAF4/ds9pp0+fXhs3btTRo0d19OhRSVLu3LmVO3duc5uKFSvaKzwAAAAAAADgtWb3BGG06KRgZGSk9u/fr5s3b8rPz+/pLwQAAAAAAMArh5IXSYfdhxh369bNPJQ4MjJS5cuX15tvvqksWbJo69at9g0OAAAAAAAAeM3ZPUG4fPlyFS5cWJK0atUqnTx5UkeOHFH37t01YMAAO0cHAAAAAAAAvN7sniC8du2a0qdPL0n6+eef1aRJE73xxhv68MMP433XYgAAAAAAAADPxu4JwnTp0unQoUOKjIzUunXrVLVqVUnS/fv35ezsbOfoAAAAAAAA8CxMJtNr9Xid2f0mJa1atVKTJk2UIUMGmUwmValSRZL0559/Kk+ePHaODgAAAAAAAHi92T1BOHToUBUoUEDnzp1T48aN5e7uLklydnZWv3797BwdAAAAAAAA8Hqze4JQkho1amQ1rUWLFnaIBAAAAAAAAHAsdkkQTps2Te3atZOHh4emTZsWZ9uuXbu+pKgAAAAAAAAAx2MyDMN42W8aEBCgv/76S6lSpVJAQECs7Uwmk06ePJng5d999NJXCUhUN+6F2TsE4Lmk9XG3dwjAc3n5v46AxPWa11EHgFeexysxXtP+3uizzt4hJKpj42vYO4QXxi6H7KlTp2z+HwAAAAAAAMDLZZcEYY8ePeLVzmQyadKkSS84GgAAAAAAAMBx2SVB+M8//1g8//vvvxUREaHcuXNLko4dOyZnZ2cFBgbaIzwAAAAAAADAYdglQbhlyxbz/ydPnqzkyZNrwYIF8vPzkyTdvHlTrVq1UlBQkD3CAwAAAAAAwHMyURQ3ybDLTUqelClTJm3YsEH58+e3mH7gwAFVq1ZNFy9eTPAyuUkJkjpuUoKkjpuUIKnjJiVI6rgeAwD74iYlj+Xuu97eISSqo+Oq2zuEF8bJ3gHcvn1bISEhVtNDQkJ0584dO0QEAAAAAAAAOA67JwjffvtttWrVSt9//73Onz+v8+fPa8WKFWrdurUaNGhg7/AAAAAAAACA15rdO73OmjVLvXr1UvPmzRUeHi5JcnFxUevWrTVhwgQ7RwcAAAAAAIBnQcmLpMPuNQij3bt3T//9958kKUeOHPLy8nrmZVGDEEkdNQiR1FGDEEndq/HrCHh2XJABgH1Rg/CxPP1erxqER8a+vjUIX5lD1svLS4UKFbJ3GAAAAAAAAIBDsXsNQgAAAAAAAAD288r0IAQAAAAAAMDrw8mJmhdJBT0IAQAAAAAAAAdGghAAAAAAAABwYCQIAQAAAAAAAAdGDUIAAAAAAAAkOhMlCJMMehACAAAAAAAADowEIQAAAAAAAODASBACAAAAAAAADowahAAAAAAAAEh0JooQJhn0IAQAAAAAAAAcGAlCAAAAAAAAwIGRIAQAAAAAAAAcGDUIAQAAAAAAkOgoQZh00IMQAAAAAAAAcGAkCAEAAAAAAAAHRoIQAAAAAAAAcGDUIAQAAAAAAECiM1GEMMmgByEAAAAAAADgwEgQAgAAAAAAAA6MBCEAAAAAAADgwKhBCAAAAAAAgERHDcKkgx6EAAAAAAAAgAMjQQgAAAAAAAA4MBKEAAAAAAAAgAOjBiEAAAAAAAASHSUIkw56EAIAAAAAAAAOjAQhAAAAAAAA4MBIEAIAAAAAAAAOjBqEAAAAAAAASHQmihAmGfQgBAAAAAAAABwYCUIAAAAAAADAgZEgBAAAAAAAABwYCUIAAAAAAADAgXGTEgAAAAAAACQ67lGSdNCDEAAAAAAAAHBgJAgBAAAAAAAAB0aCEAAAAAAAAHBg1CAEAAAAAABAojNRhDDJoAchAAAAAAAA4MBIEAIAAAAAAAAOjAQhAAAAAAAA4MCoQQgAAAAAAIBERwnCpIMehAAAAACA/2PvzsNjOvswjt+TSEISSSyJ2GKtJXbVktpVRatF6UJb1FbUHltpKaootStqL62ilKq1qnSzU7WrPZYk1gSRRCTz/uE17ZSWNJMck/P9vNdcl3nOMye/83auzMk9z/kdAICJERACAAAAAAAAJkZACAAAAAAAAJgYPQgBAAAAAADgcBaaEDoNVhACAAAAAAAAJkZACAAAAAAAAJgYASEAAAAAAABgYvQgBAAAAAAAgMPRgtB5sIIQAAAAAAAAMDECQgAAAAAAAMDECAgBAAAAAAAAE6MHIQAAAAAAABzOQhNCp8EKQgAAAAAAAMDECAgBAAAAAAAAEyMgBAAAAAAAAEyMHoQAAAAAAABwOFoQOo8MGRC6uvAOhHML8PEwugQgVaJiEowuAUgVfx93o0sAUsfK+TCcG6ECAKQvLjEGAAAAAAAATIyAEAAAAAAAADCxDHmJMQAAAAAAAIxloV+A02AFIQAAAAAAAGBiBIQAAAAAAACAiREQAgAAAAAAACZGD0IAAAAAAAA4HC0InQcrCAEAAAAAAAATIyAEAAAAAAAATIyAEAAAAAAAADAxehACAAAAAADA4Sw0IXQarCAEAAAAAAAATIyAEAAAAAAAADAxAkIAAAAAAADAxOhBCAAAAAAAAIejBaHzYAUhAAAAAAAAYGIEhAAAAAAAAICJERACAAAAAAAAJkZACAAAAAAAAJgYNykBAAAAAACAw1m4S4nTYAUhAAAAAAAAYGIEhAAAAAAAAICJERACAAAAAAAAJkYPQgAAAAAAADgcPQidBysIAQAAAAAAABMjIAQAAAAAAABMjIAQAAAAAAAAMDF6EAIAAAAAAMDhaEHoPFhBCAAAAAAAAJgYASEAAAAAAABgYgSEAAAAAAAAgInRgxAAAAAAAAAOZ6EJodNgBSEAAAAAAABgYgSEAAAAAAAAgIkREAIAAAAAAAAmRg9CAAAAAAAAOBwtCJ0HKwgBAAAAAAAABxo8eLAsFovdo0SJErbt8fHx6ty5s3LkyCFvb281bdpUUVFRdvsIDw9XgwYN5OnpqYCAAPXp00e3b9+2m7Np0yZVrFhRHh4eKlq0qObOnfuf6iUgBAAAAAAAABysVKlSioiIsD1++eUX27aePXvq22+/1VdffaUff/xR58+fV5MmTWzbk5KS1KBBA926dUubN2/WZ599prlz52rQoEG2OSdPnlSDBg1Uu3Zt7dmzRz169FC7du20bt26FNdqsVqt1tQd7qMnLtHoCoDUYRk2nF1UTILRJQCp4u/jbnQJQKpYxMkEnBvnw3B2mWnoJkmqPWGz0SU41NqOjyshwf5vHQ8PD3l4eNwzd/DgwVq+fLn27Nlzz7aYmBj5+/trwYIFeumllyRJhw8fVsmSJbVlyxZVqVJFa9as0fPPP6/z588rV65ckqRp06apX79+unjxotzd3dWvXz+tWrVK+/fvt+27WbNmio6O1tq1a1N0bKwgBAAAAAAAgMP9/RJbZ3+MGDFCvr6+do8RI0b84/EfPXpUefLkUeHChfX6668rPDxckrRr1y4lJiaqbt26trklSpRQUFCQtmzZIknasmWLypQpYwsHJSk0NFTXrl3TgQMHbHP+uo+7c+7uIyXItAEAAAAAAIAH6N+/v8LCwuzG7rd6UJIqV66suXPnqnjx4oqIiNCQIUNUvXp17d+/X5GRkXJ3d5efn5/da3LlyqXIyEhJUmRkpF04eHf73W3/NufatWuKi4tTlixZHvrYCAgBAAAAAACAB/iny4nv59lnn7X9u2zZsqpcubIKFCigxYsXpyi4Sy9cYgwAAAAAAACkIT8/PxUrVkzHjh1TYGCgbt26pejoaLs5UVFRCgwMlCQFBgbec1fju88fNMfHxyfFISQBIQAAAAAAABzOYslYj9S4ceOGjh8/rty5c+vxxx+Xm5ubNmzYYNt+5MgRhYeHKyQkRJIUEhKiffv26cKFC7Y569evl4+Pj4KDg21z/rqPu3Pu7iMlCAgBAAAAAAAAB+rdu7d+/PFHnTp1Sps3b9aLL74oV1dXNW/eXL6+vmrbtq3CwsK0ceNG7dq1S61bt1ZISIiqVKkiSapXr56Cg4PVokUL/f7771q3bp3ee+89de7c2XaZc8eOHXXixAn17dtXhw8f1pQpU7R48WL17NkzxfXSgxAAAAAAAABwoLNnz6p58+a6fPmy/P39Va1aNW3dulX+/v6SpHHjxsnFxUVNmzZVQkKCQkNDNWXKFNvrXV1dtXLlSnXq1EkhISHy8vJSq1atNHToUNucQoUKadWqVerZs6cmTJigfPnyaebMmQoNDU1xvRar1WpN/WE/WuISja4ASJ3ULl0GjBYVk2B0CUCq+Pu4G10CkCoWcTIB58b5MJxdZpZjSZKenrTF6BIcakPXlF+66yx4ywIAAAAAAMDhXEj7nQY9CAEAAAAAAAATIyAEAAAAAAAATIyAEAAAAAAAADAxehACAAAAAADA4WhB6DxYQQgAAAAAAACYGAEhAAAAAAAAYGIEhAAAAAAAAICJ0YMQAAAAAAAADmehCaHTYAUhAAAAAAAAYGIEhAAAAAAAAICJERACAAAAAAAAJkZACAAAAAAAAJgYNykBAAAAAACAw7lwjxKnwQpCAAAAAAAAwMQICAEAAAAAAAATIyAEAAAAAAAATIwehAAAAAAAAHA4i4UmhM6CFYQAAAAAAACAiREQAgAAAAAAACZGQAgAAAAAAACYGD0IAQAAAAAA4HC0IHQerCAEAAAAAAAATIyAEAAAAAAAADAxAkIAAAAAAADAxOhBCAAAAAAAAIeziCaEzoIVhAAAAAAAAICJERACAAAAAAAAJkZACAAAAAAAAJiYoQFhYmKiihQpokOHDhlZBgAAAAAAABzMxZKxHhmZoQGhm5ub4uPjjSwBAAAAAAAAMDXDLzHu3LmzPvroI92+fdvoUgAAAAAAAADTyWR0ATt27NCGDRv03XffqUyZMvLy8rLb/vXXXxtUGQAAAAAAAJDxGR4Q+vn5qWnTpkaXAQAAAAAAAAeyWDJ4474MxPCAcM6cOUaXAAAAAAAAAJiW4QEhHl1RUVGaMHa0fv3lZ8XHxyl/UAEN+WC4SpUuI0m6fOmSxo/7WFs3/6Lr16+r4uOV1G/AQBUoUNDYwgFJu3bu0NzZs3To4H5dvHhR4yZ+ojpP17Vtn/rJJK1ds0qRkZFyc3NTcHApdeneU2XLljOwapjZzdhYfTZjsn798QdFX72iosVKqFOPfioeXFq3bydq7qeTtX3Lz4o4f1Ze3llVsVJlte3UQzn8A2z7OHrkoGZOGa8/Dh2Qi4uLqtWqq47d+iiLp6eBRwazSkpK0rQpk7V65QpdvnRJ/v4BeqHxi2rfoZNtNcHlS5c0YdzH2rL5V934/7lE3wHvcS6BR8LUTybp06mT7cYKFiqk5d+ulSQt+WqR1qxaqcOHDig2NlY/bd4hHx8fI0oF7rF44QItXvSlzp87J0kqUvQxdej0tqpVr2mb8/ue3zRpwjjt27dXri4uKl6ipKZOn6XMmTMbVTYAAz0SAeGSJUu0ePFihYeH69atW3bbdu/ebVBV5nYtJkZvtmiuJ56srMnTZih7tmw6ffq0fHx8JUlWq1U9u3dWpkyZNG7iFHl7e2v+vLnq2K61vv5mFX+MwnBxcTdVvHhxNW7SVGHdu9yzvUCBgur/7iDly5df8Qnx+nzeXHVq30bfrlmv7NmzG1AxzG7cyME6deKY+g76UDn8A7Rh7Ur16/6WZi5YpixZPHX0j0N6vXUHFS5aTDeuX9OU8R9pUL9u+mT2QknS5YsX9E63t1Szbqi6hPXXzdhYTZ0wSqOHvadBw8cafHQwo7mzZmjJoi819MORKlK0qA4c2K/B7w2Qt7e3Xnuj5V/OJdw0fuIUeXl76fN5c9WxXRt9/c1KziXwSChS9DF9OvPPK55cXV1t/46Pj1PVatVVtVp1TRw/xojygH8UkCtQ3Xv2VlCBArJarfr2m+Xq3qWzFi1dpqJFH9Pve37T2x3aqU27Dnrn3YHK5OqqI0cOy8XF8PuYAjCI4QHhxIkT9e677+rNN9/UN998o9atW+v48ePasWOHOnfubHR5pjVn9gwFBgZq6LARtrG8+fLb/h1++pT2/r5HS5avVNGij0mS3h04WE/Xqqo1q1epyUsvp3vNwF9Vq17T7hvSv3vu+Rfsnvfu21/Lli7R0T+OqHKVkLQuD7CTkBCvnzd9ryEjJ6hshUqSpJbt3tbWX3/Ut18vVusOXfXRhOl2r+kSNkBd272mC5ERCgjMra2//iTXTJnUpde7tpP77n3fU4cWL+nc2XDlzReU7scFc/t9z2+qWftpVa9ZS5KUJ28+rV29Sgf27ZN051xi3++/a8nyb1Xk/+cSAwYOVt1a1TiXwCPD1dVVOXP633fbGy3elCTt2L4tHSsCHk6t2nXsnnft3lOLF36pvb/vUdGij2n0RyPU/PUWatv+LducgoUKp3eZMAFaEDoPw78emDJliqZPn65JkybJ3d1dffv21fr169WtWzfFxMQYXZ5p/bjxBwWXKq3eYd1Uu0aIXn2psZYuWWzbfnelp4e7h23MxcVF7m7u+u23XeleL5AaibduaelXi5Q1a1YVK17c6HJgQkm3k5SclCR3D3e7cQ+PzDqw97f7viY29oYsFou8smaVJCUm3lImNze7b/7dPe5cInTg9/vvA0hL5cpX0PZtW3T61ElJ0pHDh7Vn925VrV5D0p/nEu73OZfYw7kEHhHh4af1TO1qalD/afXv10sREeeNLglIsaSkJK1ZvUpxcTdVrlwFXb58Wfv2/q7sOXKo5evNVLvGU2rT6g3t3rXT6FIBGMjwgDA8PFxPPfWUJClLliy6fv26JKlFixb68ssvH/j6hIQEXbt2ze6RkJCQpjWbwdmzZ/TVoi8VFFRQUz+dpZdfba5RI4ZpxTfLJN35dil37jyaOGGMrsXEKDHxlubMmq6oqEhdunjR4OqBh/Pjpo2qUqmCnqhYVvPnzdW0GbOVLRuXFyP9eXp5Kbh0OX0xZ7ouX7ygpKQkfb92pQ7t/11XLt/7O/VWQoJmThmnWs88Ky8vb0lS+cef1NXLl7X4izlKTEzU9WvXNGvKeEnS5fvsA0hrrdu9pdBnG+jFF57TE+VLq/nLL+q1Fi1tK7gLFiqswNx5NGnC2L+cS8zgXAKPjDJly2rosBH6ZNpMvTtwsM6dPac2LV9XbOwNo0sDHsrRP47cOdetUEYfDn1f4yZ+oiJFi+rc2TOSpGmfTFaTl17WlE9nqmTJYL3V9k2dPn3K2KIBGMbwgDAwMFBXrlyRJAUFBWnr1q2SpJMnT8pqtT7w9SNGjJCvr6/dY/RHIx74Ovy75GSrSpQspW49wlSiZLBeevlVNWn6ipYsvtPrys3NTWPGT9LpU6dUo+qTqlKpvHZs36aq1WvIxYU1xHAOTzxZWYuXLte8LxaqarXq6tOrhy5fvmx0WTCpvoOGy2q1qnmjumpQq5K++WqBatV9VhaL/Uf17duJGjawt2S1qluf92zjBQsXVZ+BH2jpl/P0Qp0n1eyF2grMk1fZsueQi8Xwj3uY0Hdr12jNym81/KOPtWDxUg39cKTmz51t+7LxzrnERJ0+dUo1q1ZWSKUK2vn/cwkLPbDwCKhWvabqhT6rYsVL6Kmq1TV56nRdv35N361dY3RpwEMpWLCQFi9drs+/XKyXX22ugQP66fixY0pOTpYkvfTKq2r8YlOVLBmsPu8MuHMTnq+XGlw1AKMY3oOwTp06WrFihSpUqKDWrVurZ8+eWrJkiXbu3KkmTZo88PX9+/dXWFiY3Viyi8c/zMbD8vf3V5EiRezGChUurO+/X2d7HlyqtBYv/UbXr19XYmKismfPrjeav6zgUqXTu1zgP/H09FRQgQIKKlBAZcuV1wvP1tPyr5eobfsORpcGE8qTL7/GTJmjuLibuhkbqxw5/fXhwD7KnSefbc7t24ka9l4fXYiM0KhJM22rB++qU6+B6tRroKtXLitz5iySRfp64Xzlzpvv7z8OSHPjx4xW63btVf+5BpKkx4oVV0TEec2ZOV0NG70o6c65xKKly+3OJVo0f4VzCTySfHx8FFSgoM6EhxtdCvBQ3NzdFVSggKQ7v28P7N+nLz6fpzbt2kuSCt/z914RRXIZPRzMhSaETsPwgHD69Om2bzA6d+6sHDlyaPPmzWrYsKE6dHjwH+keHh7y8LAPBOMS06RUUylXoaJO/b9n0F2nT59S7tx575mb9f/9r06fPqWDB/br7S7d06VGwNGSrcn33EkdSG9ZsngqSxZPXb92TTu3bVa7t3tK+jMcPHfmtEZPniUfX79/3Ee27DkkSWtXLpObu7sqPlElPUoH7MTHx92zAtbFxcV23vdX955LdEuXGoGUuHkzVmfPnFHOF+5/0xLgUZecnKzEW7eUN28++QcE6NTJv/29d+qUqv2/TywA8zE8IHRxcbFrqN6sWTM1a9bMwIogSW+0aKU3WzTXzOnTVK/+s9q/b6+WLlmsge8Ptc35bt0aZcuWXblz59HRo0c0auRw1a5TV09VrWZg5cAdN2NjFf6Xb/jPnT2rw4cO3WlF4OenmdOnqVbtOsrp76/oq1e18MsvdCEqSs+E1jewapjZzq2/yiqr8gUV1PmzZzTjk7HKX6CgQp9vpNu3E/XBgF46+schfTB6spKTk3Xl8iVJUlYfX7m5uUmSvlnypYLLlFOWLJ7avWOrZkweqzaduss7q4+RhwaTqlGrtmbNmKbcuXOrSNGiOnzokD6fN1eNX2xqm7N+3Vply5ZNgbnz6OjRPzR65IeqVedphXAugUfA2NEfqUat2sqdJ48uXrigqZ9Mkquri+o/97wk6dKli7p06ZJtReGxo3/I08tLuXPnlu+/fIkDpIcJ48aoWvUaCsydWzdjY7V61Urt3LFdU6fPksVi0Zut22rqJ5NUvHgJFS9RUiu+WaZTJ09ozLiJRpcOwCAW68M0+ktjP//8sz799FMdP35cS5YsUd68eTV//nwVKlRI1aql/ASRFYSO8dOmjZo4YazCT59S3rz59Ear1mr60iu27Qs+n6fP5szS5cuX5e/vr+cbNtJbHd+Wm5v7v+wVD4NV2Km3Y/s2tWvd8p7xho1e1HvvD9E7fXtp397fFX31qvz8/FSqdBm179BJpcuUNaDajCcqhptFpdSPG9Zp9tQJunQxSll9fFWtVl217tBVXt5ZFRlxTi2bPnvf142ePEvlKj4hSRo1dIC2bf5Z8XE3lb9AIb3UvJXqPvtCeh5GhuHvw2dZasXG3tCUSRP1w4bvdfXKZfn7B6j+cw30Vqc/zxUWfD5P8+bM1uXLl5XTdi7RiXMJB7CIk4nU6te7p3bv2qHo6Ghly55dFSo8ri7deip/UJAkaeonk/Tp1Mn3vG7IsBFq1PjBrZLw7zgfTp33Bw7Q9q1bdfHiBXlnzapixYqrddv2Cnmqqm3OrBnTtWjhF4qJiVHx4iXUI6y3Kj5eycCqM5bMhi/HejQ0mbXL6BIc6uu2jxtdQpoxPCBcunSpWrRooddff13z58/XwYMHVbhwYU2ePFmrV6/W6tWrU7xPAkI4O06I4OwICOHsCAjh7AgI4ew4H4azIyC8o+nsjBUQLm2TcQNCw28RN2zYME2bNk0zZsywXSIlSVWrVtXu3bsNrAwAAAAAAADI+AwPCI8cOaIaNe5thOrr66vo6Oj0LwgAAAAAAAAwEcMDwsDAQB07duye8V9++UWFCxc2oCIAAAAAAADAPAy/Kr59+/bq3r27Zs+eLYvFovPnz2vLli3q3bu3Bg4caHR5AAAAAAAA+A8sNBR1GoYEhHv37lXp0qXl4uKi/v37Kzk5WU8//bRu3rypGjVqyMPDQ71791bXrl2NKA8AAAAAAAAwDUMCwgoVKigiIkIBAQEqXLiwduzYoT59+ujYsWO6ceOGgoOD5e3tbURpAAAAAAAAgKkYEhD6+fnp5MmTCggI0KlTp5ScnCx3d3cFBwcbUQ4AAAAAAABgWoYEhE2bNlXNmjWVO3duWSwWVapUSa6urvede+LEiXSuDgAAAAAAAKlFC0LnYUhAOH36dDVp0kTHjh1Tt27d1L59e2XNmtWIUgAAAAAAAABTM+wuxvXr15ck7dq1S927dycgBAAAAAAAAAxgWEB415w5c4wuAQAAAAAAADAtF6MLAAAAAAAAAGAcw1cQAgAAAAAAIONx4S4lToMVhAAAAAAAAICJERACAAAAAAAAJkZACAAAAAAAAJgYPQgBAAAAAADgcHQgdB6sIAQAAAAAAABMjIAQAAAAAAAAMDECQgAAAAAAAMDE6EEIAAAAAAAAh7NY6ELoLFhBCAAAAAAAAJgYASEAAAAAAABgYgSEAAAAAAAAgInRgxAAAAAAAAAO50ILQqfBCkIAAAAAAADAxAgIAQAAAAAAABMjIAQAAAAAAABMjB6EAAAAAAAAcDiLhSaEzoIVhAAAAAAAAICJERACAAAAAAAAJkZACAAAAAAAAJgYPQgBAAAAAADgcLQgdB6sIAQAAAAAAABMjIAQAAAAAAAAMDECQgAAAAAAAMDE6EEIAAAAAAAAh7PQhNBpsIIQAAAAAAAAMDECQgAAAAAAAMDECAgBAAAAAAAAE6MHIQAAAAAAABzOhRaEToMVhAAAAAAAAICJERACAAAAAAAAJkZACAAAAAAAAJgYPQgBAAAAAADgcBYLTQidBSsIAQAAAAAAABMjIAQAAAAAAABMjIAQAAAAAAAAMLGH6kG4d+/eh95h2bJl/3MxAAAAAAAAyBjoQOg8HiogLF++vCwWi6xW6323391msViUlJTk0AIBAAAAAAAApJ2HCghPnjyZ1nUAAAAAAAAAMMBDBYQFChRI6zoAAAAAAAAAGOA/3aRk/vz5qlq1qvLkyaPTp09LksaPH69vvvnGocUBAAAAAADAOblYLBnqkZGlOCCcOnWqwsLC9Nxzzyk6OtrWc9DPz0/jx493dH0AAAAAAAAA0lCKA8JJkyZpxowZevfdd+Xq6mobr1Spkvbt2+fQ4gAAAAAAAACkrRQHhCdPnlSFChXuGffw8FBsbKxDigIAAAAAAACQPlIcEBYqVEh79uy5Z3zt2rUqWbKkI2oCAAAAAAAAkE4e6i7GfxUWFqbOnTsrPj5eVqtV27dv15dffqkRI0Zo5syZaVEjAAAAAAAAnEwGv69HhpLigLBdu3bKkiWL3nvvPd28eVOvvfaa8uTJowkTJqhZs2ZpUSMAAAAAAACANJLigFCSXn/9db3++uu6efOmbty4oYCAAEfXBQAAAAAAACAd/KeAUJIuXLigI0eOSJIsFov8/f0dVhQAAAAAAACA9JHigPD69et6++239eWXXyo5OVmS5OrqqldffVWffPKJfH19HV4kAAAAAAAAnIuFJoROI8V3MW7Xrp22bdumVatWKTo6WtHR0Vq5cqV27typDh06pEWNAAAAAAAAANJIilcQrly5UuvWrVO1atVsY6GhoZoxY4bq16/v0OIAAAAAAAAApK0UryDMkSPHfS8j9vX1VbZs2RxSFAAAAAAAAID0keKA8L333lNYWJgiIyNtY5GRkerTp48GDhzo0OIAAAAAAADgnCyWjPXIyB7qEuMKFSrYNZY8evSogoKCFBQUJEkKDw+Xh4eHLl68SB9CAAAAAAAAwIk8VEDYuHHjNC4DAAAAAAAAgBEeKiB8//3307oOAAAAAAAAAAZI8V2MAQAAAAAAgAdxyeiN+zKQFAeESUlJGjdunBYvXqzw8HDdunXLbvuVK1ccVhwAAAAAAACAtJXiuxgPGTJEY8eO1auvvqqYmBiFhYWpSZMmcnFx0eDBg9OgRAAAAAAAAABpJcUB4RdffKEZM2aoV69eypQpk5o3b66ZM2dq0KBB2rp1a1rUCAAAAAAAACCNpDggjIyMVJkyZSRJ3t7eiomJkSQ9//zzWrVqlWOrAwAAAAAAgFOyWDLWIyNLcUCYL18+RURESJKKFCmi7777TpK0Y8cOeXh4OLY6AAAAAAAAAGkqxQHhiy++qA0bNkiSunbtqoEDB+qxxx5Ty5Yt1aZNG4cXCAAAAAAAADizkSNHymKxqEePHrax+Ph4de7cWTly5JC3t7eaNm2qqKgou9eFh4erQYMG8vT0VEBAgPr06aPbt2/bzdm0aZMqVqwoDw8PFS1aVHPnzk1xfSm+i/HIkSNt/3711VdVoEABbd68WY899pheeOGFFBcAAAAAAAAAZFQ7duzQp59+qrJly9qN9+zZU6tWrdJXX30lX19fdenSRU2aNNGvv/4qSUpKSlKDBg0UGBiozZs3KyIiQi1btpSbm5uGDx8uSTp58qQaNGigjh076osvvtCGDRvUrl075c6dW6GhoQ9do8VqtVodcbAXLlzQzJkzNWDAAEfsLlXiEo2uAEidjN7bABlfVEyC0SUAqeLv4250CUCqWMTJBJwb58NwdplTvBwrY+q87JDRJTjU2OcKKyHB/m8dDw+Pf225d+PGDVWsWFFTpkzRsGHDVL58eY0fP14xMTHy9/fXggUL9NJLL0mSDh8+rJIlS2rLli2qUqWK1qxZo+eff17nz59Xrly5JEnTpk1Tv379dPHiRbm7u6tfv35atWqV9u/fb/uZzZo1U3R0tNauXfvQx5biS4z/SUREhAYOHOio3QEAAAAAAACPjBEjRsjX19fuMWLEiH99TefOndWgQQPVrVvXbnzXrl1KTEy0Gy9RooSCgoK0ZcsWSdKWLVtUpkwZWzgoSaGhobp27ZoOHDhgm/P3fYeGhtr28bDItAEAAAAAAIAH6N+/v8LCwuzG/m314MKFC7V7927t2LHjnm2RkZFyd3eXn5+f3XiuXLkUGRlpm/PXcPDu9rvb/m3OtWvXFBcXpyxZsjzUsREQAgAAAAAAAA/woMuJ/+rMmTPq3r271q9fr8yZM6dxZamXIQPCmJs0IYRz8/V0M7oEIFX8s9K/Dc4tx5NdjS4BSJWoLRONLgFIlcSkZKNLAFIlc6YMGbekmMP62jmhXbt26cKFC6pYsaJtLCkpST/99JMmT56sdevW6datW4qOjrZbRRgVFaXAwEBJUmBgoLZv326337t3Of7rnL/f+TgqKko+Pj4PvXpQSkFA+PcllH938eLFh/6hAAAAAAAAQEb19NNPa9++fXZjrVu3VokSJdSvXz/lz59fbm5u2rBhg5o2bSpJOnLkiMLDwxUSEiJJCgkJ0YcffqgLFy4oICBAkrR+/Xr5+PgoODjYNmf16tV2P2f9+vW2fTyshw4If/vttwfOqVGjRop+OAAAAAAAAJDRZM2aVaVLl7Yb8/LyUo4cOWzjbdu2VVhYmLJnzy4fHx917dpVISEhqlKliiSpXr16Cg4OVosWLTRq1ChFRkbqvffeU+fOnW2XOnfs2FGTJ09W37591aZNG/3www9avHixVq1alaJ6Hzog3LhxY4p2DAAAAAAAAOD+xo0bJxcXFzVt2lQJCQkKDQ3VlClTbNtdXV21cuVKderUSSEhIfLy8lKrVq00dOhQ25xChQpp1apV6tmzpyZMmKB8+fJp5syZCg0NTVEtFqvVanXYkT0iImPoQQjnRg9COLsM+NECk8lRmR6EcG70IISzowchnF0OL3oQSlK35YeNLsGhJjYuYXQJacbM/SIBAAAAAAAA0yMgBAAAAAAAAEyMgBAAAAAAAAAwMS6KBwAAAAAAgMO5WIyuAA/rP60g/Pnnn/XGG28oJCRE586dkyTNnz9fv/zyi0OLAwAAAAAAAJC2UhwQLl26VKGhocqSJYt+++03JSQkSJJiYmI0fPhwhxcIAAAAAAAAIO2kOCAcNmyYpk2bphkzZsjNzc02XrVqVe3evduhxQEAAAAAAABIWynuQXjkyBHVqFHjnnFfX19FR0c7oiYAAAAAAAA4OXoQOo8UryAMDAzUsWPH7hn/5ZdfVLhwYYcUBQAAAAAAACB9pDggbN++vbp3765t27bJYrHo/Pnz+uKLL9S7d2916tQpLWoEAAAAAAAAkEZSfInxO++8o+TkZD399NO6efOmatSoIQ8PD/Xu3Vtdu3ZNixoBAAAAAAAApJEUB4QWi0Xvvvuu+vTpo2PHjunGjRsKDg6Wt7d3WtQHAAAAAAAAIA2lOCC8y93dXcHBwY6sBQAAAAAAABmExcJdSpxFigPC2rVr/+t/4B9++CFVBQEAAAAAAABIPykOCMuXL2/3PDExUXv27NH+/fvVqlUrR9UFAAAAAAAAIB2kOCAcN27cfccHDx6sGzdupLogAAAAAAAAAOnHxVE7euONNzR79mxH7Q4AAAAAAABOzMWSsR4ZmcMCwi1btihz5syO2h0AAAAAAACAdJDiS4ybNGli99xqtSoiIkI7d+7UwIEDHVYYAAAAAAAAgLSX4oDQ19fX7rmLi4uKFy+uoUOHql69eg4rDAAAAAAAAEDaS1FAmJSUpNatW6tMmTLKli1bWtUEAAAAAAAAJ2fJ4H37MpIU9SB0dXVVvXr1FB0dnUblAAAAAAAAAEhPKb5JSenSpXXixIm0qAUAAAAAAABAOktxQDhs2DD17t1bK1euVEREhK5du2b3AAAAAAAAAOA8HroH4dChQ9WrVy8999xzkqSGDRvK8peLya1WqywWi5KSkhxfJQAAAAAAAJyKC00IncZDB4RDhgxRx44dtXHjxrSsBwAAAAAAAEA6euiA0Gq1SpJq1qyZZsUAAAAAAAAASF8p6kFoYWkoAAAAAAAAkKE89ApCSSpWrNgDQ8IrV66kqiAAAAAAAAA4vxTfGReGSVFAOGTIEPn6+qZVLQAAAAAAAADSWYoCwmbNmikgICCtagEAAAAAAACQzh56tSf9BwEAAAAAAICMJ8V3MQYAAAAAAAAehLVmzuOhA8Lk5OS0rAMAAAAAAACAAbihDAAAAAAAAGBiBIQAAAAAAACAiaXoLsYAAAAAAADAw3ChCaHTYAUhAAAAAAAAYGIEhAAAAAAAAICJERACAAAAAAAAJkYPQgAAAAAAADgcLQidBysIAQAAAAAAABMjIAQAAAAAAABMjIAQAAAAAAAAMDF6EAIAAAAAAMDhXOhB6DRYQQgAAAAAAACYGAEhAAAAAAAAYGIEhAAAAAAAAICJ0YMQAAAAAAAADudioQmhs2AFIQAAAAAAAGBiBIQAAAAAAACAiREQAgAAAAAAACZGD0IAAAAAAAA4HC0InQcrCAEAAAAAAAATIyAEAAAAAAAATIyAEAAAAAAAADAxAkIAAAAAAADAxLhJCQAAAAAAABzOhZuUOA1WEAIAAAAAAAAmRkAIAAAAAAAAmBgBIQAAAAAAAGBi9CAEAAAAAACAw1lEE0JnwQpCAAAAAAAAwMQICAEAAAAAAAATIyAEAAAAAAAATIwehAAAAAAAAHA4F1oQOg1WEAIAAAAAAAAmRkAIAAAAAAAAmBgBIQAAAAAAAGBi9CAEAAAAAACAw9GD0HmwghAAAAAAAAAwMQJCAAAAAAAAwMQICAEAAAAAAAATowchAAAAAAAAHM5ioQmhszB0BeGJEyeM/PEAAAAAAACA6RkaEBYtWlS1a9fW559/rvj4eCNLAQAAAAAAAEzJ0IBw9+7dKlu2rMLCwhQYGKgOHTpo+/btRpYEAAAAAAAAmIqhPQjLly+vCRMmaMyYMVqxYoXmzp2ratWqqVixYmrTpo1atGghf39/I0s0jYsXovTp5LHatvkXxSfEK2++IL0z8AOVCC4tSbp586amfzJOv/z4g2JiopU7T141feV1NWr6qm0fH48Yol3bt+jSpYvKksVTpcuWV4cuPVWgYGGjDguwmT1zuiaOH6PX3mipvu+8a7fNarWqS6f2+vWXnzV2wieq83Rdg6qEme3auUPz5s7SwYMHdOniRY0dP1m1//JenDZlktatWa3IqEi5ZXJTyeBS6tKth8qULWebM3P6NP380yb9ceSwMrm56efNO4w4FJjA4VVDVCBPjnvGpy36ST1HLlahfDk1sueLCqlQWB5umbR+8yGFffSVLly5fs9r3N0y6af5vVWueD5VfnWE9v5xTpIUlDu7jqwees/8mi0/1vZ9pxx+TDC3ObOma+OG9Tp98oQ8PDKrbPkK6tKjlwoWLGQ3b+/vv2nqpAnav2+vXF1dVKx4CU2cOlOZM2eWJIV1e1t/HDmsq1cuK6uPj56sHKKuPXrLPyDAiMOCic2bM0PTJo3XK83fUI8+/SVJndu/qd922Z8bNG76ivq++74kKSY6WoPf7avjR/9QTEy0smXPoeo1a6tjlx7y8vZO92NAxuBCC0Kn8UjcpCRTpkxq0qSJGjRooClTpqh///7q3bu3BgwYoFdeeUUfffSRcufObXSZGdb1azHq0r6Fyj/+pEZNmCY/v2w6e+a0svr42OZ8Mn6Uftu5Te8OGaHA3Hm1Y9tmjR81TDn9A1S1Rm1JUrESwXomtIECAnPr+rUYzZkxRb27vqWFy9fJ1dXVqMMDtH/fXi35aqGKFSt+3+2fz/9MonkuDBYXF6dixUqo0YtN1atH13u2FyhQUP0GDFS+fPmVkBCvz+d/prc7tNU3q75T9uzZJUmJibf0TL36KluuvJYvW5rehwATqfbGaLn+5Yw/uGgerZ7WVV+v/02emd21ckpn7fvjnJ59a5Ik6f23G2jphA6q0XKMrFar3b6G92ikiIsxKlc8331/1rMdJurQ8Qjb88sxsWlwRDC73Tt36OVXX1NwqdJKSkrSlEnj1LVjWy3+eqWyeHpKuhMOdnv7Lb3Z5i31fudduWbKpKNHDsvF5c+Lsio98aRat3tLOXP668KFC5owdpT69e6u2fO+NOrQYEIHD+zTN0u/UtHHit2zreGLL6l9py6255kzZ7H92+JiUfVadfRW527y88uuc2fC9fFHw3Rt+BANGT46XWoHYJxHIiDcuXOnZs+erYULF8rLy0u9e/dW27ZtdfbsWQ0ZMkSNGjXi0uM0tGDebPkHBKr/oGG2sdx57U/SD+zdo9AGjVTh8SclSQ1ffFnfLvtKhw7sswWEDV98+c/X58mrdh27qs3rTRUZcU558wWlw5EA97p5M1YD3umjQYOHacanU+/ZfvjwIc3/bLYWLFqqurWqGVAhcEe16jVUrXqNf9z+bIMX7J736vOOln+9REf/OKLKVUIkSZ06d5MkrVj+ddoVCki6dPWG3fPerUvrePhF/bzrqJ6uUkIF8uRQleYf6XrsnR7T7QbNV8SPo1TryWLauO2I7XX1qgbr6Sol1bzPTNWvVuq+P+tKdKyiLt+78hBwpElTZ9g9f3/oCNWrXVWHDh1QxcefkCSNGz1SrzZ/Q2+2bW+b9/cVhq+1eNP279x58qpVm/bq06OLbicmKpObW9odAPB/N2/Gasi7/fTOwCGaO/PTe7ZnzpxZOXLe/yo9Hx9fNXm5me157jx51OTlZlowb06a1Qvg0WFoD8KxY8eqTJkyeuqpp3T+/HnNmzdPp0+f1rBhw1SoUCFVr15dc+fO1e7du40sM8P79eeNKlGylAa9E6ZGoTXU9o2X9O3yJXZzSpUtr19/2qiLF6JktVq1e+d2nQk/pScqP3XffcbF3dSab5crd558CsjF6k8YZ/iwoapeo6aqhNz7Xo2Li9OAvr3U/91ByvkPJ0rAoygx8Za+XrJI3lmzqljxEkaXA5Nzy+SqZs89oc++2SJJ8nDPJKvVqoRbt21z4hNuKznZqqfKF7GNBWTPqikDm6vtwHm6GXfrH/e/ZHwHnd4wQhtm91SDmmXS7kCAv7hx404o7ePjK0m6cvmy9u/bq+zZc6hNy+YKrV1Nb7VpoT27d/3jPmJiorV21bcqW64C4SDSzZiRw/RUtRp6onLIfbd/t2aVnq1TVa+/3EhTJ41TfFzcP+7r4sUL+vGH71W+YqW0KhfAI8TQFYRTp05VmzZt9Oabb/7jJcQBAQGaNWvWP+4jISFBCQkJfxtzkYeHh0Nrzcgizp3VN18v0suvtdQbrdvr8MH9mjhmhNwyuan+840kSd17D9DHwwfrpeeflqtrJrm4WNR7wGCV+9uHxbIlC/XppDGKi4tTUIFCGjN5utw4IYJB1q5epcOHDuqLhUvuu/3jUSNUrnwF1a5Dz0E4h59+3Kh3+vRSfHyccvr7a9r02cqWLZvRZcHkGtYuK7+sWfT5t9skSdv3nVJs3C192L2RBk1eIYssGta9kTJlclVgzj/bl0wf+oZmLPlFuw+GKyh39nv2GxuXoH5jvtaWPceVnGxV47rltXhse70SNkOrftyXbscH80lOTtbYUSNUrnxF2yWa586dkSTNmDZZ3cL6qnjxElq18hu9/VZrLVy6QkEFCtpeP2ncx1q8cIHi4+NUpmw5jZ107xUMQFpYv261jhw+pFnzF913+zP1n1Ng7jzy9w/QsaN/aMrEsQo/dUojxkywmzeof2/9/ONGJcTHq1qNWuo/6N5+sMDDopOT8zA0IDx69OgD57i7u6tVq1b/uH3EiBEaMmSI3Vivfu+pd/9Bqa7PLJKTk1W8ZCm99XYPSVKx4iV18vhRffP1YltA+PXiL3Rw/14NHzNZgYG59ftvuzR+9IfK6R+gSk/++e3UM/Ub6IknQ3T50kUt/GKuBg/orckz5hPYIt1FRkRo1MgPNW3G7Pu+/zZt3KDt27Zq0ZJlBlQH/DdPPFFZC5csU/TVq/p66Vfq27uH5n+xWNlz3HuzCCC9tGr8lNb9elARF2Mk3bn8+PW+szRxwKt6u3lNJSdbtXjtLu0+GK7k//cffLt5TWX1zKzRs7/7x/1ejo7VxM9/sD3fdTBcuf191bPl0wSESFOjhg/V8eNHNWPuF7ax5OQ7790XX3pVDRs3kSQVLxmsHdu2asXyr9Wle5htbos326rhi00VGXFeM6ZN0eD33tG4SdNk4a9kpKGoyAiNHz1SE6bM+Me/vRo3fcX27yKPFVOOnDnVrWNbnT0Trnz5/2wJ1b1XP7V5622dCT+laZPGa+LYj9SHv6+BDM/wHoTR0dGaNWuWDh06JEkqVaqU2rRpI19f34d6ff/+/RUWFmY3djXe0CunnU6OnP4qWKiI3ViBgoX108bvJUkJ8fGaMWWCho2aoJBqNSVJRR4rrmN/HNaiz+faBYTe3lnl7Z1V+YIKKLhMOT3/9FP6edMG1Q19Lv0OCJB08OABXblyWc1faWIbS0pK0u5dO7Toyy/08qvNdfZMuKqHPGH3ut49u6pCxUqaNXd+epcMPFAWT08FBRVQUFABlS1XXg0bhGrZsiVq266D0aXBpIJyZ1OdysXVrLd9/7YNWw+rVMMhyuHnpdu3kxVzI04n1w/XqXV3Lses9UQxVS5bSDHbxtu97tcv+mrhmp1qP+j+v4N37DutOpW5rB5pZ9TwD/TzTz9q+uz5ypUr0DZ+txVJocL258wFCxVWZGSE3Zhftmzyy5ZNBQoWUsHCRfR8vdrat3ePyparkPYHANM6fOigrl65rNav/9kXPikpSXt279TSxV9q09bf7rlxZKkyZSXpnoAwR07///+NWFg+Pr7q1LalWrfrpJz+tOQBMjJDA8KdO3cqNDRUWbJk0ZNP3rn5xdixY/Xhhx/qu+++U8WKFR+4Dw8Pj3u+IblpTUyTejOq0mUrKPz0Kbuxs+GnlSvwzmXft2/f1u3bt2VxsQ9eXVxdlWxN/sf9Wq1WWa1WJSb+c18hIK1UrlJFS5Z9azc26L3+KlSosFq3bS+/bNn00suv2m1/6cUX1Ltvf9WsVTs9SwX+M2tyshJv8TsWxmnRMEQXrlzXmp8P3Hf75eg7dxyu+UQxBWT31sr/r/zrNWqJBn+y0jYvt7+vVk7tohbvzNGOfaf+8eeVLZ5XkZeuOe4AgP+zWq0aPWKYNv3wvabN+kx589nfsC9P3rzy9w/Q6VMn7cbDT5/WU9Wq//N+k++cKyfe4u8TpK1KT1bR/MXL7cY+HPyuChQsrDfebHtPOChJR48clqR/7cV9d/Usf9MBGZ+hAWHPnj3VsGFDzZgxQ5ky3Snl9u3bateunXr06KGffvrJyPJM4+XXWqhz2xaaP2e6atetr0MH9unb5UvUe8D7kiQvb2+Vr1hJ0yaOkYeHhwID82jPbzu1bvUKde7eR5J0/twZ/bB+rZ6o/JT8smXXxQuR+uKzWfLw8FCVp/75pAlIK15e3ra+QXdlyeIpXz8/2/j9ToYCc+dR3nz506VG4K9u3ozVmfBw2/Nz587qyOFD8vH1lZ+vn2bOmKaateoop7+/oq9e1eKFC3ThQpSeqVff9pqIiPO6FhOjiIgIJScl6cjhO6vz8wcFydPTK92PCRmbxWJRy0ZV9MXKbUpKsv/CsEXDKjpyMlIXr95Q5bKF9HGflzTpi406evqCJOlM5FW7+Tdu3uknfeLMRZ27EC1Jev2FykpMvK09h89KkhrVKadWjULUaeiCND4ymNFHw4dq3ZpV+nj8ZHl6eenSpYuS7lwdkzlzZlksFr3xZhtNnzpZxYqXULHiJbRyxXKdPnVCH40ZL0nav/d3HTywX+UqVJSPj4/OnjmjaVMmKl/+IJUpV964g4MpeHl5qUjRx+zGsmTxlK+vr4oUfUxnz4Rr/dpVCqlaQ75+fjp29IgmjBml8hUrqWix4pKkzb/8pCuXL6tkqdLy9PTUiePH9Mn4j1W2fAXlzpPXiMNCBuBCewWnYfgKwr+Gg5KUKVMm9e3bV5Uqcaek9FIyuIyGjRqv6VMmaN6saQrMk1ddwvrpmfrP2+YMGvaxpk8Zr2GD3tG1azEKDMyjdh27qVHTOyuw3N09tHfPbi1ZOF/Xr11Ttuw5VK5CJX0y63Nly05vLAB4kIMH9qt9mz977o4ZPVKS9ELDxnp30BCdOnlS367opuirV+Xr56dSpcpo9mdf2P0xMHXyRH27YrntebOXX5QkzZj9mSo9UTl9DgSmUadycQXlzq7Plm+9Z1uxggEa2rWhsvt66vT5Kxo1a51dP8GH9U77+grKnV23byfrj1NRavHObC37fo8DqgfsLV28UJLUsa197/NBQ4frhUZ3fpe+9kYr3Uq4pbGjR+paTIweK15ck6fNsl2amTlLFm3csF7Tp05SXFyccub0V0jVamozqpPc3d3T94CAv3Fzc9OObVu1aMF8xcfFKSBXoGrXqas323W0zfHw8NCKZUs0ccxHupV4S7lyBapmnbpq0bqdgZUDSC8Wq/X/3aINkCtXLs2fP1/16tWzG1+3bp1atmypqKio/7TfyBiW8MO5+Xpy52c4NwM/WgCHyFG5q9ElAKkStWWi0SUAqZKY9M+tjABnkMPL8Fs+PBLG/3zywZOcSI/qhYwuIc0YejePV199VW3bttWiRYt05swZnTlzRgsXLlS7du3UvHlzI0sDAAAAAAAATMHQSPvjjz++07+mZUvdvn1bVqtV7u7u6tSpk0aOHGlkaQAAAAAAAEgFF1oQOg1DA0J3d3dNmDBBI0aM0PHjxyVJRYoUkaenp5FlAQAAAAAAAKaR7gFhkyZNNHfuXPn4+KhJkyb/Otfb21ulSpVSx44d5evrm04VAgAAAAAAAOaR7gGhr6+vLP+/zfWDQr+EhARNmzZNv/76q1asWJEe5QEAAAAAAACmku4B4Zw5c+77739y8OBBPfHEE2lZEgAAAAAAABzMQg9Cp2HoXYwfRvHixbV582ajywAAAAAAAAAypEc+IHR1dVW5cuWMLgMAAAAAAADIkB75gBAAAAAAAABA2kn3HoQAAAAAAADI+FxEE0JnwQpCAAAAAAAAwMQICAEAAAAAAAATIyAEAAAAAAAATIyAEAAAAAAAADAxblICAAAAAAAAh7NwjxKnwQpCAAAAAAAAwMQICAEAAAAAAAATIyAEAAAAAAAATIwehAAAAAAAAHA4F3oQOg1WEAIAAAAAAAAmRkAIAAAAAAAAmBgBIQAAAAAAAGBi9CAEAAAAAACAw7lYaELoLFhBCAAAAAAAAJgYASEAAAAAAABgYgSEAAAAAAAAgInRgxAAAAAAAAAORwtC58EKQgAAAAAAAMDECAgBAAAAAAAAEyMgBAAAAAAAAEyMHoQAAAAAAABwOBeaEDoNVhACAAAAAAAAJkZACAAAAAAAAJgYASEAAAAAAADgQFOnTlXZsmXl4+MjHx8fhYSEaM2aNbbt8fHx6ty5s3LkyCFvb281bdpUUVFRdvsIDw9XgwYN5OnpqYCAAPXp00e3b9+2m7Np0yZVrFhRHh4eKlq0qObOnfuf6iUgBAAAAAAAgMNZLBnrkRL58uXTyJEjtWvXLu3cuVN16tRRo0aNdODAAUlSz5499e233+qrr77Sjz/+qPPnz6tJkya21yclJalBgwa6deuWNm/erM8++0xz587VoEGDbHNOnjypBg0aqHbt2tqzZ4969Oihdu3aad26dSn/b2W1Wq0pftUjLjIm0egSgFTx9XQzugQgVTLgRwtMJkflrkaXAKRK1JaJRpcApEpiUrLRJQCpksOLe8JK0uwd4UaX4FCvl82lhIQEuzEPDw95eHg81OuzZ8+u0aNH66WXXpK/v78WLFigl156SZJ0+PBhlSxZUlu2bFGVKlW0Zs0aPf/88zp//rxy5colSZo2bZr69eunixcvyt3dXf369dOqVau0f/9+289o1qyZoqOjtXbt2hQdGysIAQAAAAAAgAcYMWKEfH197R4jRox44OuSkpK0cOFCxcbGKiQkRLt27VJiYqLq1q1rm1OiRAkFBQVpy5YtkqQtW7aoTJkytnBQkkJDQ3Xt2jXbKsQtW7bY7ePunLv7SAkibQAAAAAAAOAB+vfvr7CwMLuxf1s9uG/fPoWEhCg+Pl7e3t5atmyZgoODtWfPHrm7u8vPz89ufq5cuRQZGSlJioyMtAsH726/u+3f5ly7dk1xcXHKkiXLQx8bASEAAAAAAAAcLqNdtpqSy4klqXjx4tqzZ49iYmK0ZMkStWrVSj/++GMaVvjfERACAAAAAAAADubu7q6iRYtKkh5//HHt2LFDEyZM0Kuvvqpbt24pOjrabhVhVFSUAgMDJUmBgYHavn273f7u3uX4r3P+fufjqKgo+fj4pGj1oJTxwlwAAAAAAADgkZOcnKyEhAQ9/vjjcnNz04YNG2zbjhw5ovDwcIWEhEiSQkJCtG/fPl24cME2Z/369fLx8VFwcLBtzl/3cXfO3X2kBCsIAQAAAAAAAAfq37+/nn32WQUFBen69etasGCBNm3apHXr1snX11dt27ZVWFiYsmfPLh8fH3Xt2lUhISGqUqWKJKlevXoKDg5WixYtNGrUKEVGRuq9995T586dbZc5d+zYUZMnT1bfvn3Vpk0b/fDDD1q8eLFWrVqV4noJCAEAAAAAAOBwFovF6BIMc+HCBbVs2VIRERHy9fVV2bJltW7dOj3zzDOSpHHjxsnFxUVNmzZVQkKCQkNDNWXKFNvrXV1dtXLlSnXq1EkhISHy8vJSq1atNHToUNucQoUKadWqVerZs6cmTJigfPnyaebMmQoNDU1xvRar1WpN/WE/WiJjEo0uAUgVX083o0sAUiUDfrTAZHJU7mp0CUCqRG2ZaHQJQKokJiUbXQKQKjm8WI8lSZ/tPGN0CQ7VqlJ+o0tIM/QgBAAAAAAAAEyMgBAAAAAAAAAwMda8AgAAAAAAwOHM24HQ+bCCEAAAAAAAADAxAkIAAAAAAADAxAgIAQAAAAAAABOjByEAAAAAAAAczsVCF0JnwQpCAAAAAAAAwMQICAEAAAAAAAATIyAEAAAAAAAATIyAEAAAAAAAADAxblICAAAAAAAAh+MWJc6DFYQAAAAAAACAiREQAgAAAAAAACZGQAgAAAAAAACYGD0IAQAAAAAA4HAWmhA6DVYQAgAAAAAAACZGQAgAAAAAAACYGAEhAAAAAAAAYGL0IAQAAAAAAIDDWWhC6DRYQQgAAAAAAACYGAEhAAAAAAAAYGIEhAAAAAAAAICJ0YMQAAAAAAAADseqNOfBfysAAAAAAADAxAgIAQAAAAAAABMjIAQAAAAAAABMjB6EAAAAAAAAcDiLxWJ0CXhIrCAEAAAAAAAATIyAEAAAAAAAADAxAkIAAAAAAADAxOhBCAAAAAAAAIejA6HzYAUhAAAAAAAAYGIEhAAAAAAAAICJERACAAAAAAAAJkYPQgAAAAAAADicxUIXQmfBCkIAAAAAAADAxAgIAQAAAAAAABPLkJcYZ3Yn94RzYxU2nJ3V6AKAVIraMtHoEoBUuRF/2+gSgFTx83IzugQAMJUMGRACAAAAAADAWCzfch78twIAAAAAAABMjIAQAAAAAAAAMDECQgAAAAAAAMDE6EEIAAAAAAAAh7NwB06nwQpCAAAAAAAAwMQICAEAAAAAAAATIyAEAAAAAAAATIwehAAAAAAAAHA4OhA6D1YQAgAAAAAAACZGQAgAAAAAAACYGAEhAAAAAAAAYGL0IAQAAAAAAIDDWWhC6DRYQQgAAAAAAACYGAEhAAAAAAAAYGIEhAAAAAAAAICJERACAAAAAAAAJsZNSgAAAAAAAOBwLuIuJc6CFYQAAAAAAACAiREQAgAAAAAAACZGQAgAAAAAAACYGD0IAQAAAAAA4HAWWhA6DVYQAgAAAAAAACZGQAgAAAAAAACYGAEhAAAAAAAAYGL0IAQAAAAAAIDDWUQTQmfBCkIAAAAAAADAxAgIAQAAAAAAABMjIAQAAAAAAABMjB6EAAAAAAAAcDgLLQidBisIAQAAAAAAABMjIAQAAAAAAABMjIAQAAAAAAAAMDF6EAIAAAAAAMDhXEQTQmfBCkIAAAAAAADAxAgIAQAAAAAAABMjIAQAAAAAAABMjB6EAAAAAAAAcDgLLQidBisIAQAAAAAAABMjIAQAAAAAAABMjIAQAAAAAAAAMDF6EAIAAAAAAMDh6EHoPFhBCAAAAAAAAJgYASEAAAAAAABgYgSEAAAAAAAAgInRgxAAAAAAAAAOZxFNCJ0FKwgBAAAAAAAAEyMgBAAAAAAAAEyMgBAAAAAAAAAwMXoQAgAAAAAAwOFcaEHoNFhBCAAAAAAAAJgYASEAAAAAAABgYgSEAAAAAAAAgInRgxAAAAAAAAAOZxFNCJ0FKwgBAAAAAAAAEyMgBAAAAAAAAEyMgBAAAAAAAAAwMXoQAgAAAAAAwOEstCB0GqwgBAAAAAAAAEyMgBAAAAAAAAAwMQJCAAAAAAAAwMQMDwjj4uJ08+ZN2/PTp09r/Pjx+u677wysCgAAAAAAADAHwwPCRo0aad68eZKk6OhoVa5cWWPGjFGjRo00depUg6sDAAAAAADAf2HJYP/LyAwPCHfv3q3q1atLkpYsWaJcuXLp9OnTmjdvniZOnGhwdQAAAAAAAEDGZnhAePPmTWXNmlWS9N1336lJkyZycXFRlSpVdPr0aYOrAwAAAAAAADI2wwPCokWLavny5Tpz5ozWrVunevXqSZIuXLggHx8fg6sDAAAAAAAAMjbDA8JBgwapd+/eKliwoCpXrqyQkBBJd1YTVqhQweDqAAAAAAAA8F+4WDLWIyOzWK1Wq9FFREZGKiIiQuXKlZOLy53Mcvv27fLx8VGJEiVSvL/ouCRHlwikq8xurkaXAKRKsvEfLUCq3E7iPQzndiP+ttElAKni5+VmdAlAqni6ZfA06SH99McVo0twqBrFshtdQprJZHQBkhQYGKjAwEBJ0rVr1/TDDz+oePHi/ykcBAAAAAAAAPDwDL/E+JVXXtHkyZMlSXFxcapUqZJeeeUVlS1bVkuXLjW4OgAAAAAAACBjMzwg/Omnn1S9enVJ0rJly2S1WhUdHa2JEydq2LBhBlcHAAAAAACA/8KSwf6XkRkeEMbExCh79jvXcK9du1ZNmzaVp6enGjRooKNHjxpcHQAAAAAAAJCxGR4Q5s+fX1u2bFFsbKzWrl2revXqSZKuXr2qzJkzG1wdAAAAAAAAkLEZfpOSHj166PXXX5e3t7eCgoJUq1YtSXcuPS5TpoyxxQEAAAAAAAAZnOEB4dtvv60nn3xSZ86c0TPPPCMXlzuLGgsXLkwPQgAAAAAAACdlydht+zIUi9VqtRpdhCTdunVLJ0+eVJEiRZQpU+pyy+i4JAdVBRgjs5ur0SUAqZL8aHy0AP/Z7STew3BuN+JvG10CkCp+Xm5GlwCkiqcbyZgk/XL0qtElOFS1x7IZXUKaMbwH4c2bN9W2bVt5enqqVKlSCg8PlyR17dpVI0eONLg6AAAAAAAAIGMzPCDs37+/fv/9d23atMnupiR169bVokWLDKwMAAAAAAAAyPgM70G4fPlyLVq0SFWqVJHlLxenlypVSsePHzewMgAAAAAAAPxXXGjtPAxfQXjx4kUFBATcMx4bG2sXGAIAAAAAAABwPMMDwkqVKmnVqlW253dDwZkzZyokJMSosgAAAAAAAABTMPwS4+HDh+vZZ5/VwYMHdfv2bU2YMEEHDx7U5s2b9eOPPxpdnmksXbxQX3+1UOfPn5MkFS5SVG3f6qSnqtVQTEy0ZkydrG1bNisqMkJ+2bKpZu2n1eHtbvLOmtVuPyu/WaYvP/9M4adPycvLW3WeCVXfAQONOCSY3OKFC7R40Zc6f+7Oe7pI0cfUodPbqla9ps6dO6vn6j1939eNHjte9UKfTc9Sgft6rl4dRZw/f8/4K81eU//3Bqndmy20a+cOu21NX35V770/JL1KBGzmzJqujRvW6/TJE/LwyKyy5SuoS49eKliwkG3OpUsXNXHsaG3bukU3Y2NVoGBBtWnfUXXq1rPNCev2tv44clhXr1xWVh8fPVk5RF179Jb/fa42ARypWeNQRUXc+zu3UdNX1aPve+rRqbV+373TbtsLL76ssHcGSZJiYqL14aB3dOLYH7oWEy2/bNlVtUZttevUXV7e3ulyDMDfxcbe0JRJE/XDhu919cplFS9RUn3feVelypSxzTlx/LgmjPtYu3fu0O2kJBUuXEQfj5+o3LnzGFg5ACNYrFar1egijh8/rpEjR+r333/XjRs3VLFiRfXr109l/vKLKyWi45IcXGHG9/OPG+Xi4qL8QQUkSatWLNfnn83W/IVLZZU0fepkPd+wsQoVLqLIiPMaOWyIihYrrpEfj7ftY8H8uVowb6669uytUmXKKi4uThHnz6lGrTrGHJQTy+zmanQJTm/Txh/k6uqqoAIFZLVa9e03yzV39iwtWrpMhQoV1tUrV+zmL/lqkT6bM0sbNv0iTy8vg6rOOJKN/2hxeleuXFFy8p+fZ8eOHlWn9m00Y/ZnqvRkZbV7s4UKFCyoTl262eZkzpxF3vwh6hC3k3gPp0TXTu1Vr/5zCi5VWklJSZoyaZyOHzuqxV+vVBZPT0lSlw5tdf36dfXt/558s2XTutUrNX3qZM1b8JWKlwyWdOdcoky58sqZ018XLlzQhLGjJEmz531p2LE5qxvxt40uwalEX72i5ORk2/OTx4+qd9e3NG7KbJV//An16NRa+fIXUJsOXWxzPDwy28K/69di9MP6tSoRXFq+ftl07my4Joz+UI8VL6mBH4xK9+PJCPy83Iwuwen169VTx44d1YCB78s/IECrv12hL+Z/pqXfrFJArlw6Ex6uFs1fVuMmL6n+cw3k5eWt48ePqWzZcsqeI4fR5Ts9TzdapknSlmPRRpfgUCFF/R567ogRI/T111/r8OHDypIli5566il99NFHKl68uG1OfHy8evXqpYULFyohIUGhoaGaMmWKcuXKZZsTHh6uTp06aePGjfL29larVq00YsQIZcr055q/TZs2KSwsTAcOHFD+/Pn13nvv6c0330zRsT0SAaGjERA6xjM1qqhrzz5q+GLTe7Zt+G6t3n+3nzZt2aVMmTLp2rUYPV+vtsZM+ERPVObS8NQiIEwb1UOeVM/efdSk6cv3bHulaWOVDA7WkA+GG1BZxkNA6HijRw7Xzz9u0jer18lisajdmy1UvERJ9XlngNGlZUgEhKlz9coV1atdVZ/OnqeKjz8hSapR5XG98+4gPfdCI9u8ujWqqEuPXmrc5N7fy5L046Yf1KdHF23e8bsyuREWpAQBYepMHvuRtvz6oz5fskoWi0U9OrVW0cdKqEtYv4fex9JFX2jR53O0+Nvv07DSjIuAMHXi4+NVrfLjGjfxE1WvWcs2/torTVS1Wg117tZD/XqHyS1TJg0bSYidFggI7zBzQFi/fn01a9ZMTzzxhG7fvq0BAwZo//79OnjwoLz+vyilU6dOWrVqlebOnStfX1916dJFLi4u+vXXXyVJSUlJKl++vAIDAzV69GhFRESoZcuWat++vYYPv/O368mTJ1W6dGl17NhR7dq104YNG9SjRw+tWrVKoaGhD12v4ZcYS1JycrKOHTumCxcu2H1zJ0k1atQwqCrzSkpK0ob16xQXF6fSZcvdd86NGzfk5e1tS6y3b9ksa3KyLl64oFdffF6xsbEqW668uvfqq1yBudOzfOAeSUlJ+m7dWsXF3VS5chXu2X7wwH4dOXxIA94bZEB1wIMlJt7S6pUr9EbLN+1u4LV61bdavXKFcuT0V42atdS+49vKkiWLgZUCd9y4cV2S5OPjaxsrW6681q9bo6o1aiprVh99v26NEhJu6fFKT953HzEx0Vq76luVLVeBcBDpKjExUevXrtTLr7W0+537/bpVWr92pbLnyKmnqtVUi7YdlDnz/X/nXrp4QT9v+l7lKlZKr7IBO0lJt5WUlCR3Dw+7cQ+PzPpt9y4lJyfrl582qVWbdnr7rbY6fPiQ8ubNpzbt3lLtp+saVDWQsaxdu9bu+dy5cxUQEKBdu3apRo0aiomJ0axZs7RgwQLVqXPnyss5c+aoZMmS2rp1q6pUqaLvvvtOBw8e1Pfff69cuXKpfPny+uCDD9SvXz8NHjxY7u7umjZtmgoVKqQxY8ZIkkqWLKlffvlF48aNc66AcOvWrXrttdd0+vRp/X0xo8ViUVLSv68GTEhIUEJCgv1YciZ5/O0XIR7s2NE/1K5lc926dUtZsnjqo7ETVbhI0XvmRV+9qtkzptp923/u3FklJydr7qzpCuvbX17eWfXpJxPUtWM7ffHVMrm5uafnoQCSpKN/HFGL15rp1q0EeXp6atzET1Sk6L3v6WVLl6hw4SIqX6GiAVUCD7ZxwwZdv35dLzR+0Tb2bIPnlTtPHvn7B+joH39owriPdfrUKY2ZMMnASoE7X/yOHTVC5cpXVNHHitnGR4wepwF9w1S3RohcM2VS5syZNXrcJFt7k7smjftYixcuUHx8nMqULaexk6am9yHA5H75cYNu3Liu+g3+XO36dL3nlCt3HuXM6a/jx/7Q9MnjdCb8lIZ+NN7utR+811e//rRRCQnxeqp6LfUZQF9YGMPLy1tly5XXjGlTVKhwYeXIkVNrV6/S3t/3KH9QkK5cuaybN29qzqwZ6ty1u7qH9davv/ysXj26avrsz1Tpift/eQOY3f0yKA8Pj4fKoGJiYiRJ2bNnlyTt2rVLiYmJqlv3z1C+RIkSCgoK0pYtW1SlShVt2bJFZcqUsbvkODQ0VJ06ddKBAwdUoUIFbdmyxW4fd+f06NEjRcdm+F2MO3bsqEqVKmn//v26cuWKrl69antc+VuPsPsZMWKEfH197R7jRo9Mh8ozngIFC2r+oq81a/5CNXnlVQ0dNEAnjh+zm3Pjxg2Fde2oQoWLqH3HzrZxa3Kybt++rbC+A1TlqWoqU7acPhjxsc6En9auHdvT+1AASVLBgoW0eOlyff7lYr38anMNHNBPx4/Zv6fj4+O1ZvVKNW76kkFVAg+2/OslqlqtugIC/jwxaPryq3qqanU9Vqy4nnv+BX0w/CP9sGG9zoSHG1gpII0aPlTHjx/Vh6PG2I1P+2Sirl+/rk+mz9a8BV/p9RZvqn/fnjp29A+7eS3ebKvPFy3V5Gkz5eLiqsHvvXPPl8hAWlq9Ypkqh1RTTv8/b47zwosv68kqVVW4aDE9U/959R88XD9v2qBzZ8/YvbZzz76aPm+Rho2eqHNnz+iTCaPTu3zAZtiIUbLKqtA6NVW5Yll9+cV81X+2gVwsLrYr92rVrqM3Wr6p4iVKqk27t1S9Zi0tWbzQ4MqRkVgy2ON+GdSIESMe+P9DcnKyevTooapVq6p06dKSpMjISLm7u8vPz89ubq5cuRQZGWmb89dw8O72u9v+bc61a9cUFxf3wNruMnwF4dGjR7VkyRIVvc+qnofRv39/hYWF2Y3FJRt+WE7Jzc3d9i1+yeBSOnRgvxYtmK/+A+988xkbG6seb78lTy8vfTR2kt3lPjly+kuSChUpYhvLlj27fP2yKTIiIh2PAviTm7u7ggrceU8HlyqtA/v36YvP52nQ4KG2Oeu/W6u4uHi90LCxQVUC/+78+XPatnWLPh7/7ysDy5QpK0k6c+a08gcFpUdpwD1GDf9AP//0o6bPnq9cuQJt42fPhGvxwi+0cOkKFSn6mCSpWPES+m33Tn21cIH6Dxxsm+uXLZv8smVTgYKFVLBwET1fr7b27d2jsvdpEQE4WmTEee3esVVDRo7713klS925meK5s+HKmy+/bTx7jpzKniOnggoWlo+Pr7p1aKWWbTrYzpWB9JQ/KEiz5n6uuJs3dSP2hvz9A9SvV0/lzZdf2bJlU6ZMme65Yqxw4SL6bfcugyoGHn33y6AeZvVg586dtX//fv3yyy9pVVqqGb6CsHLlyjr2txU9KeHh4SEfHx+7B5cXO0ZyslWJtxIl3Vk52K1TO7m5uenj8Z/c8/9xuf9fmhl+6qRtLCYmWjHRVxWYO0/6FQ38i+TkZCXeumU3tvzrpapVu45tmTfwqFmx7Gtlz55D1WvU/Nd5Rw4fliTlzBnwr/OAtGC1WjVq+Afa9MP3mjpjjvLmy2e3PT4+XpLk4mJ/6unq4qpkq33/abv9/n+Fy93zESCtrV25XH7Zsiuk6r/3QT/2xxFJUo4cOf9xzt339t/PPYD0lsXTU/7+AboWE6PNm39RrTp15ObmruBSpXX65Em7uadPnVLuPPz9BvyT/5JBdenSRStXrtTGjRuV7y/nSIGBgbp165aio6Pt5kdFRSkwMNA2Jyoq6p7td7f92xwfH58U9Sc3fKld165d1atXL0VGRqpMmTJy+1sT6rJlyxpUmbl8MnGsnqpaQ7kCc+vmzVitW7NSu3du14QpM2zhYEJ8vIZ8+JFiY28oNvaGJMkvW3a5uroqqEBB1ahVR2NHjVD/gUPk5e2tKRPHqUDBQvSvgCEmjBujatVrKDB3bt2MjdXqVSu1c8d2TZ0+yzYn/PRp7dq5Q59MnW5gpcA/S05O1jfLl+n5Ro1tN4WSpDPh4VqzeqWqVa8hPz8//fHHHxrz0QhVrFRJxYoXN7BimNVHw4dq3ZpV+nj8ZHl6eenSpYuSJG/vrMqcObMKFiyk/EFBGvHB++oe1le+fn7a9MMGbdu6WeP+32Nw/97fdfDAfpWrUFE+Pj46e+aMpk2ZqHz5g1SmXHkDjw5mkZycrLUrlyu0QUO5/uV37rmzZ7Rh3SpVfqq6fH39dPzYH5oyfpTKVnhcRR678zt3668/6eqVyyoRXFpZsnjq5Inj+nTSGJUuW0GBefIadUgwuc2//iyr9U7bnTPhpzVuzGgVKlRYDRs3kSS1at1W/XqHqWKlSqr0ZGVt/uVn/fTjRs2YM8/gyoGMwWq1qmvXrlq2bJk2bdqkQoUK2W1//PHH5ebmpg0bNqhp06aSpCNHjig8PFwhISGSpJCQEH344Ye6cOGCAgLuLARYv369fHx8FBwcbJuzevVqu32vX7/eto+HZbEa3NTl798kS3duTmK1Wh/qJiX3Ex2X8teY3bDB72nntq26dOmivL2zqmixYmrxZjtVDnlKu3Zs19vt37zv65atWq88ee+c9Ny4cUPjPx6pTRu+l8XFooqPP6Gwvv25i/F/kNnN1egSnN77Awdo+9atunjxgryzZlWxYsXVum17hTxV1TZn4vixWvXtCq1Z/8N9fxfhv0umX5hDbPn1F73doZ2Wr1yjAgX/PKGIjIjQu/376PjRo4qLi1OuwNyq83RdtevQSd7e3gZWnHHcTuI9nBJPlCt53/FBQ4frhUZ3bq4TfvqUJk8Yq99/262bN28qf1CQ3mjZWs+9cOdGEMeO/qExHw3X0T8OKy4uTjlz+iukajW1ad9JAX/rq4MHuxF/2+gSnM6OrZvVt3sHzfvqW+UPKmgbvxAVqQ/ff0enjh9TXHycAgICVa3W02rR+i15/f937m87t2vWtIk6dfKEEhNvKSAgUNVrP63XWraVd1Yfg47Iufl5cffy1Ppu7RpNGj9WUVGR8vX109PPPKPO3Xoqa9astjnLv16q2TOn60JUpAoULKSOnbuqdp2nDaw64/B0szx4kglsPR5tdAkOVaWI30PPffvtt7VgwQJ98803Kv6XL/F9fX1tK/s6deqk1atXa+7cufLx8VHXrl0lSZs3b5YkJSUlqXz58sqTJ49GjRqlyMhItWjRQu3atdPw4cMlSSdPnlTp0qXVuXNntWnTRj/88IO6deumVatWpeguxoYHhKdPn/7X7QUKFPjX7fdDQAhnR0AIZ0dACGdHQAhnR0AIZ0dACGdHQHiHmQNCi+X+74E5c+bozTfflHSnDUuvXr305ZdfKiEhQaGhoZoyZYrt8mHpTm7WqVMnbdq0SV5eXmrVqpVGjhxpd4XRpk2b1LNnTx08eFD58uXTwIEDbT/joes1OiBMCwSEcHYEhHB2BIRwdgSEcHYEhHB2BIRwdgSEd5g5IHQ2hvQgXLFixUPPbdiwYRpWAgAAAAAAAJibIQFh48aN7Z7f7Tn41+d3/ZcehAAAAAAAADCWRaykdBaGdOVPTk62Pb777juVL19ea9asUXR0tKKjo7V69WpVrFhRa9euNaI8AAAAAAAAwDQMWUH4Vz169NC0adNUrVo121hoaKg8PT311ltv6dChQwZWBwAAAAAAAGRshqwg/Kvjx4/Lz8/vnnFfX1+dOnUq3esBAAAAAAAAzMTwgPCJJ55QWFiYoqKibGNRUVHq06ePnnzySQMrAwAAAAAAwH9lsWSsR0ZmeEA4e/ZsRUREKCgoSEWLFlXRokUVFBSkc+fOadasWUaXBwAAAAAAAGRohvcgLFq0qPbu3av169fr8OHDkqSSJUuqbt26dnczBgAAAAAAAOB4FqvVajW6CEeLjksyugQgVTK7uRpdApAqyRnvowUmczuJ9zCc243420aXAKSKn5eb0SUAqeLpxoInSdp+IsboEhzqycK+RpeQZgxfQShJsbGx+vHHHxUeHq5bt27ZbevWrZtBVQEAAAAAAAAZn+EB4W+//abnnntON2/eVGxsrLJnz65Lly7J09NTAQEBBIQAAAAAAABOiHWUzsPwm5T07NlTL7zwgq5evaosWbJo69atOn36tB5//HF9/PHHRpcHAAAAAAAAZGiGB4R79uxRr1695OLiIldXVyUkJCh//vwaNWqUBgwYYHR5AAAAAAAAQIZmeEDo5uYmF5c7ZQQEBCg8PFyS5OvrqzNnzhhZGgAAAAAAAJDhGd6DsEKFCtqxY4cee+wx1axZU4MGDdKlS5c0f/58lS5d2ujyAAAAAAAA8F/QhNBpGL6CcPjw4cqdO7ck6cMPP1S2bNnUqVMnXbp0SZ9++qnB1QEAAAAAAAAZm+ErCEuVKiWr1SrpziXG06ZN07JlyxQcHKzy5csbWxwAAAAAAACQwRm+grBRo0aaN2+eJCk6OlpVqlTR2LFj1bhxY02dOtXg6gAAAAAAAICMzfCAcPfu3apevbokacmSJcqVK5dOnz6tefPmaeLEiQZXBwAAAAAAgP/CksH+l5EZHhDevHlTWbNmlSR99913atKkiVxcXFSlShWdPn3a4OoAAAAAAACAjM3wgLBo0aJavny5zpw5o3Xr1qlevXqSpAsXLsjHx8fg6gAAAAAAAICMzfCAcNCgQerdu7cKFiyoypUrKyQkRNKd1YQVKlQwuDoAAAAAAAAgY7NY795C2ECRkZGKiIhQuXLl5OJyJ7Pcvn27fHx8VKJEiRTvLzouydElAukqs5ur0SUAqZJs/EcLkCq3k3gPw7ndiL9tdAlAqvh5uRldApAqnm4Zu1/dw9p16prRJTjU4wUz7pWumYwuQJICAwMVGBhoN/bkk08aVA0AAAAAAABgHoZfYgwAAAAAAADAOASEAAAAAAAAgIk9EpcYAwAAAAAAIGOhE6PzYAUhAAAAAAAAYGIEhAAAAAAAAICJERACAAAAAAAAJkYPQgAAAAAAADgeTQidBisIAQAAAAAAABMjIAQAAAAAAABMjIAQAAAAAAAAMDF6EAIAAAAAAMDhLDQhdBqsIAQAAAAAAABMjIAQAAAAAAAAMDECQgAAAAAAAMDE6EEIAAAAAAAAh7PQgtBpsIIQAAAAAAAAMDECQgAAAAAAAMDECAgBAAAAAAAAE6MHIQAAAAAAAByOFoTOgxWEAAAAAAAAgIkREAIAAAAAAAAmRkAIAAAAAAAAmBg9CAEAAAAAAOB4NCF0GqwgBAAAAAAAAEyMgBAAAAAAAAAwMQJCAAAAAAAAwMToQQgAAAAAAACHs9CE0GmwghAAAAAAAAAwMQJCAAAAAAAAwMQICAEAAAAAAAATIyAEAAAAAAAATIyblAAAAAAAAMDhLNyjxGmwghAAAAAAAAAwMQJCAAAAAAAAwMQICAEAAAAAAAATowchAAAAAAAAHI4WhM6DFYQAAAAAAACAiREQAgAAAAAAACZGQAgAAAAAAACYGD0IAQAAAAAA4Hg0IXQarCAEAAAAAAAATIyAEAAAAAAAADAxAkIAAAAAAADAxOhBCAAAAAAAAIez0ITQabCCEAAAAAAAADAxAkIAAAAAAADAxAgIAQAAAAAAABOjByEAAAAAAAAczkILQqfBCkIAAAAAAADAxAgIAQAAAAAAABMjIAQAAAAAAABMjB6EAAAAAAAAcDhaEDoPVhACAAAAAAAAJkZACAAAAAAAAJgYASEAAAAAAABgYvQgBAAAAAAAgOPRhNBpZMiA0MXCOxAAjGThTABOLiExyegSgFTx83IzugQgVU5ExRpdApAqpfN5G10CkCJcYgwAAAAAAACYGAEhAAAAAAAAYGIZ8hJjAAAAAAAAGIvWQ86DFYQAAAAAAACAiREQAgAAAAAAACZGQAgAAAAAAACYGD0IAQAAAAAA4HAWWhA6DVYQAgAAAAAAACZGQAgAAAAAAACYGAEhAAAAAAAAYGL0IAQAAAAAAIDD0YLQebCCEAAAAAAAADAxAkIAAAAAAADAxAgIAQAAAAAAABOjByEAAAAAAAAcjyaEToMVhAAAAAAAAICJERACAAAAAAAAJkZACAAAAAAAAJgYASEAAAAAAABgYtykBAAAAAAAAA5n4S4lToMVhAAAAAAAAICJERACAAAAAAAAJkZACAAAAAAAAJgYPQgBAAAAAADgcBZaEDoNVhACAAAAAAAAJkZACAAAAAAAAJgYASEAAAAAAABgYvQgBAAAAAAAgMPRgtB5sIIQAAAAAAAAMDECQgAAAAAAAMDECAgBAAAAAAAAE6MHIQAAAAAAAByPJoROgxWEAAAAAAAAgIkREAIAAAAAAAAmRkAIAAAAAAAAmBg9CAEAAAAAAOBwFpoQOg1WEAIAAAAAAAAmRkAIAAAAAAAAmBgBIQAAAAAAAGBi9CAEAAAAAACAw1loQeg0WEEIAAAAAAAAONhPP/2kF154QXny5JHFYtHy5cvttlutVg0aNEi5c+dWlixZVLduXR09etRuzpUrV/T666/Lx8dHfn5+atu2rW7cuGE3Z+/evapevboyZ86s/Pnza9SoUSmulYAQAAAAAAAAcLDY2FiVK1dOn3zyyX23jxo1ShMnTtS0adO0bds2eXl5KTQ0VPHx8bY5r7/+ug4cOKD169dr5cqV+umnn/TWW2/Ztl+7dk316tVTgQIFtGvXLo0ePVqDBw/W9OnTU1SrxWq1Wv/bYT66rsUnG10CkCrumcju4dwy3icLzOZG/G2jSwBSxSuzq9ElAKlyIirW6BKAVCmdz9voEh4JJy/FP3iSEymUM/N/fq3FYtGyZcvUuHFjSXdWD+bJk0e9evVS7969JUkxMTHKlSuX5s6dq2bNmunQoUMKDg7Wjh07VKlSJUnS2rVr9dxzz+ns2bPKkyePpk6dqnfffVeRkZFyd3eXJL3zzjtavny5Dh8+/ND1kUIAAAAAAADA4SwZ7JGQkKBr167ZPRISEv7T/zcnT55UZGSk6tataxvz9fVV5cqVtWXLFknSli1b5OfnZwsHJalu3bpycXHRtm3bbHNq1KhhCwclKTQ0VEeOHNHVq1cfuh4CQgAAAAAAAOABRowYIV9fX7vHiBEj/tO+IiMjJUm5cuWyG8+VK5dtW2RkpAICAuy2Z8qUSdmzZ7ebc799/PVnPAzuYgwAAAAAAAA8QP/+/RUWFmY35uHhYVA1jkVACAAAAAAAADyAh4eHwwLBwMBASVJUVJRy585tG4+KilL58uVtcy5cuGD3utu3b+vKlSu21wcGBioqKspuzt3nd+c8DC4xBgAAAAAAgOMZ3TTQ0Q8HKlSokAIDA7Vhwwbb2LVr17Rt2zaFhIRIkkJCQhQdHa1du3bZ5vzwww9KTk5W5cqVbXN++uknJSYm2uasX79exYsXV7Zs2R66HgJCAAAAAAAAwMFu3LihPXv2aM+ePZLu3Jhkz549Cg8Pl8ViUY8ePTRs2DCtWLFC+/btU8uWLZUnTx7bnY5Lliyp+vXrq3379tq+fbt+/fVXdenSRc2aNVOePHkkSa+99prc3d3Vtm1bHThwQIsWLdKECRPuuRT6QSxWq9XqyIN/FFyLTza6BCBV3DOR3cO5ZbxPFpjNjfjbRpcApIpXZlejSwBS5URUrNElAKlSOp+30SU8Ek5djje6BIcqmCNziuZv2rRJtWvXvme8VatWmjt3rqxWq95//31Nnz5d0dHRqlatmqZMmaJixYrZ5l65ckVdunTRt99+KxcXFzVt2lQTJ06Ut/ef77G9e/eqc+fO2rFjh3LmzKmuXbuqX79+KaqVgBB4BBEQwtllvE8WmA0BIZwdASGcHQEhnB0B4R1mDwidCTcpAQAAAAAAgMNZHN24D2mGZUoAAAAAAACAiREQAgAAAAAAACZGQAgAAAAAAACYGD0IAQAAAAAA4HAWWhA6DVYQAgAAAAAAACZGQAgAAAAAAACYGAEhAAAAAAAAYGIEhAAAAAAAAICJcZMSAAAAAAAAOBz3KHEerCAEAAAAAAAATOyRCgjj4+ONLgEAAAAAAAAwFcMDwuTkZH3wwQfKmzevvL29deLECUnSwIEDNWvWLIOrAwAAAAAAADI2wwPCYcOGae7cuRo1apTc3d1t46VLl9bMmTMNrAwAAAAAAAD/lcWSsR4ZmeEB4bx58zR9+nS9/vrrcnV1tY2XK1dOhw8fNrAyAAAAAAAAIOMzPCA8d+6cihYtes94cnKyEhMTDagIAAAAAAAAMA/DA8Lg4GD9/PPP94wvWbJEFSpUMKAiAAAAAAAAwDwyGV3AoEGD1KpVK507d07Jycn6+uuvdeTIEc2bN08rV640ujwAAAAAAAD8Jxm8cV8GYvgKwkaNGunbb7/V999/Ly8vLw0aNEiHDh3St99+q2eeecbo8gAAAAAAAIAMzWK1Wq1GF+Fo1+KTjS4BSBX3TIZn90CqZLxPFpjNjfjbRpcApIpXZtcHTwIeYSeiYo0uAUiV0vm8jS7hkXD26i2jS3CofNncjS4hzRieQpw5c0Znz561Pd++fbt69Oih6dOnG1gVAAAAAAAAYA6GB4SvvfaaNm7cKEmKjIxU3bp1tX37dr377rsaOnSowdUBAAAAAADgv7BYMtYjIzM8INy/f7+efPJJSdLixYtVpkwZbd68WV988YXmzp1rbHEAAAAAAABABmd4QJiYmCgPDw9J0vfff6+GDRtKkkqUKKGIiAgjSwMAAAAAAAAyPMMDwlKlSmnatGn6+eeftX79etWvX1+SdP78eeXIkcPg6gAAAAAAAICMzfCA8KOPPtKnn36qWrVqqXnz5ipXrpwkacWKFbZLjwEAAAAAAOBcLBnskZFZrFar1egikpKSdO3aNWXLls02durUKXl6eiogICDF+7sWn+zI8oB0557J8OweSBXjP1mA1LkRf9voEoBU8crsanQJQKqciIo1ugQgVUrn8za6hEfC+ehbRpfgUHn83I0uIc1kMroASXJ1dbULByWpYMGCxhQDAAAAAAAAmIghAWHFihW1YcMGZcuWTRUqVJDlX+4VvXv37nSsDAAAAAAAADAXQwLCRo0a2e5c3LhxYyNKAAAAAAAAQBr6l/VgeMQY2oMwKSlJv/76q8qWLSs/Pz+H7ZcehHB29CCEs6MHIZwdPQjh7OhBCGdHD0I4O3oQ3hERk7F6EOb2pQdhmnB1dVW9evV06NAhhwaESLk5s6Zr44b1On3yhDw8Mqts+Qrq0qOXChYsZJtz6dJFTRw7Wtu2btHN2FgVKFhQbdp3VJ269WxzGj77tCLOn7fbd+duYXqzbft0OxZAknbt3KG5s2fp0MH9unjxosZN/ER1nq5737kfDBmkJYsXqU+//nqj5ZvpWyjwEGbPnK6J48fotTdaqu877+rcubNqEPr0feeOGjNe9UKfTecKYXazPv1Ec2ZMsRsLKlBIC5auVMT5c3q5Yb37vm7oyLGqUzdUkhQZeV5jRnyg3Tu3K4unp559vpE6dO6hTJkeiZbZMIFdO3do3pxZOnjwgC5dvKixEyar9l/OHaxWq6Z+MknLlnyl69evqVyFihow8H0VKFDQNqd7l0764/BhXblyWT4+vqpcJUTdwnopICCXAUeEjOzA3t36ZtE8nTh6SFcvX1LfIR+rcrXa95376bjh+m7lUrV+u5eeb/qabfzEH4c0f8YkHTtyQC4urqpSo47e7BSmLFk8JUnXY6I1fsR7On3iqK5fi5GvX3Y98VRNvd62szy9CL+AjMbwM67SpUvrxIkTKlSo0IMnI83s3rlDL7/6moJLlVZSUpKmTBqnrh3bavHXK5XF884HxOB339H169c1dsIn8s2WTetWr1T/Pj01b8FXKl4y2LavDm93VeOmL9uee3l6pfvxAHFxN1W8eHE1btJUYd27/OO8Dd+v177ff5f/f7hjOpAe9u/bqyVfLVSxYsVtY4GBufX9pl/s5i39apE+mzNL1arXSO8SAUlSocJFNX7KTNtz1/8HewG5AvXN2k12c1cs+0oL5s9RlaeqSbpzVUnf7m8re46cmjb7c126dEkfvt9fmTJlUofOPdLrEGBycXFxKla8hBq92FS9enS9Z/vc2TP15RfzNfTDkcqbN5+mTJ6gzh3aaek3q2ztk554srLatu+gnP7+uhAVpXEfj1Kfnt312RcL0/twkMElxMWpYJFievrZhhr1fp9/nLftlx/0x6F9yp7D3278yqWLGtL3bT1V6xm169ZXcbGxmj1ljCZ/NFh9Bo+SJFlcXPTEUzXVvPXb8vHLpshzZzRj4kjduB6jnu8OT9PjA5D+DA8Ihw0bpt69e+uDDz7Q448/Li8v+zDJx8fHoMrMZdLUGXbP3x86QvVqV9WhQwdU8fEnJEl7f9+jd94dpFJlykqS2r7VSV9+/pkOHTpgFxB6enkpZ077DyAgvVWrXlPVqtf81zlRUVEaOfwDTZ0+S107dUinyoCHd/NmrAa800eDBg/TjE+n2sZdXV3v+T37w4bvVS/0WXnypQwM4prJVTnu8/nv6nrv+E8bN6hO3fq29+v2rZt16uRxjZ8yU9lz5NRjxaV2Hbtq6qSxavPW23Jzy7iX8+DRUa16jX/8ksVqtWrB/Hlq/1ZH1a5zZwX3B8M/Ut2aVbVxw/eq/1wDSbK7EiFPnrxq3e4thXXrrMTERLm5uaX5McA8KlauqoqVq/7rnMsXL2jmpNEa+NFkDR/Q3W7bzq0/y9U1k9p3e0cuLnfaG3Xo0V9h7Zsp4twZ5c6bX95ZfVS/4Z8LPwJy5Vb9hi/rm8XzHX9AyLAsogmhszC80dlzzz2n33//XQ0bNlS+fPmULVs2ZcuWTX5+fsqWLZvR5ZnWjRvXJUk+Pr62sbLlymv9ujWKiYlWcnKyvluzSgkJt/R4pSftXvvZ7JmqW6OKXn+liebPnaXbt+njhEdPcnKy3n2nj95s3VZFiz5mdDnAfQ0fNlTVa9RUlZCn/nXewQP7deTwITVu8lI6VQbc62x4uBrVr6WXG4VqyHt9FRl5/r7zDh86oKN/HNbzjZrYxg7s26PCRR9T9hw5bWNPhlRVbOwNnTx+PM1rBx7k3NmzunTpoir/5fdx1qxZVbpsWe39fc99XxMTE601K79VufIVCAeR7pKTkzVx5EA1eqWFggoWuWf77cRbyuTmZgsHJcndI7Mk6dC+3+67zyuXLmrbLxtVqmzFtCkagKEMX0G4cePGVL0+ISFBCQkJ9mNWN9syf6RccnKyxo4aoXLlK6roY8Vs4yNGj9OAvmGqWyNErpkyKXPmzBo9bpLyBxWwzXm1eQuVKBksn/+1d99hVdb/H8dfhymiiDhTEXDmxD0yzZ2aExNLDTVHjsSdmXvlINJw4NagXKGguVem5ii35krTcOACFyKb3x/+OEnWN0vzBs/zcV1dV+c+9zm8b6/7Ouc+r/vzeX+yZdOxI4c1M2Cqbt28qf6DPzbiUIC/tGjBPFnb2KhdBx+jSwH+1Mb163T61El9vSzkb/cNXRWiQoUKq1x5LthhjJKly+qT0RNU0M1dkbduatG8QPXu6qPg5auV+Q+zQ9auXil3j0Iq41nevC0y8pZcXHKk2c8lRw7zc4DRbt26Ken38zJVjhw5FXkr7Tn6xeefadnSrxX78KHKeHoqYObsF1YnkCps2WJZW1vrLa93//T50uUra3Hg5wpbHqS3vN5VXOxDfTVvuiTpTlTac/rz8Z/opz07FB8Xp0rVa6nnoBH/ef0AXjzDA8I33vjfUwD/zsSJEzVmzJg02z4eNlJDh496pve1ZFM+Havz53/RvMVfp9k+e2aA7t+/r5lzF8rZObu+/26bhn7UX/MWfWUOEts/Nq2iaLHisrW11afjR6t33wGys2N6ENKHkz+f0NfBQVoWskomE0Pekf5ci4jQlEkTNHvewr+94RUbG6sN69eq+we9XlB1wJOq16hp/v8iRYurZOmyertpA23fslFNW7Y2PxcXG6utG9erY9ceRpQJvBA+nbuopVdrRVy9qjmBMzVi6McKmDWbaw68MOfPntK6VcvkN/vrvzzvCroXVp8hY7Q4cKq+nj9DVtZWatLqHTlnzyGTKe1Ew869Bsjbp5siLofrq/kztDjwc3XvO/RFHAqAF8jwgFCSbt++rQULFujUqVOSpJIlS6pz585ycXH529cOHTpUAwYMSLMtLoUh/P/WlE/HadfO7zV3YbDy5Mlr3n75UrhWLPtay1auUeH/n45ZrPirOnzogL5ZtkRDR4z+0/crVaaskhITdfXqlTQrIgNGOnTwgKKiItWo/u8rvSUlJcnfb7K+Dg7Shi3bDawOkE6e/FlRUZF61/v3KZhJSUk6dPAnLV/6tX48dFzW1taSpK2bNyr2YayaNm9pULXAk7JmdZKrm5suXw5Ps/27bZsVG/tQjd5qnmZ7jhw5dern42m2RUVGmp8DjJba9zUqMlK5cv2+sFlk5C0VL14izb6pLZPc3D3kUaiwGtWvrWNHj8izXHkBL8Kp44d1906UPnj3LfO25OQkfTl7qtauXKLZS9ZKkmrWa6ya9RrrTlSk7B0cZJJJa0O+Vp58+dO8X3aXnMruklMFCnooS1YnDe/XVW06dFX2HPSdx1Pg3kiGYXhAuHPnTjVr1kzZsmVTpUqVJEkBAQEaO3asvv32W9Wq9b9XY7S3t39idMW92OT/rN6XVUpKivwmjteO7Vs1e8GXyl+gQJrnY2NjJSlNjwpJsrayVnLKX/97nz1zWlZWVk8V9gIvStPmLdL0EJKknt27qGmzFmrZyusvXgW8OFWrVVNI6Ldpto0cPlQeHoXUuUs3czgoSaGrVqp2nbp8ziJdiYl5oCuXL+nNJmmDwLWrV+n1WnWUPXva87VUmXIKWjhXt6Milf3/pxr/tH+PHB2zyL3Qk72zgBctf4ECypkzl/bv26virz4KBKOjo3Xi2DG18f7zKZySzNfJCfHxL6ROQJLeqN9EZSuk7RM/bsiHqtWgieo2av7E/s7//7m7bcNq2drZybNitb987+SUFElSQkLCc6wYQHpgeEDYu3dvtW3bVoGBgeYfPElJSerVq5d69+6t48eP/8074HmY/OlYbdqwTp9Nm6HMjo7mPitZsmRVpkyZ5O7uIdeCBTVx3Cj1HfCRsjk7a8f2bdq/b4+mTn+0suaxo4d14vgxVapcVZkdHXX86BFN9Zukxm81S7PYCfAixDx4oPDw30euXLl8WadPnVK2bNn0Sr58cnZOuwiSrY2tcubMKXePQi+6VOAJjo5Z0vSAlSQHh8zK5uycZnt4+G86dPAnzQic+6JLBNKYMc1PNWrWVt5X8unWzRtaMGemrK2sVf/NJuZ9Ll/6TUcPH5DfF4FPvL5Ktdfk7lFY40Z+rJ6+AxUVeUvzAqfLy/tdWpTghYmJeaBLj187XLmsM6dPySlbNr3ySj61e89H8+fOVkE3d+XPn1+zZgQoV+7cqlOvviTp+LGj+vnEcZWvUFFZnZx0+dIlzZr+hVxdC6osowfxnD18GKNrVy6ZH9+4dlUXzp1RlqxOypXnFWXN5pxmf2sbG2V3yan8ru7mbevDluvVkmWVySGzjh7cr6C509Shax85ZskqSTq4f7fu3o5SkeIllckhsy5dPK+gOV/o1dKeyp0334s4TAAvkOEB4blz5xQSEpJmNIS1tbUGDBigoKAgAyuzLCtXLJMk9ejSMc32kWM/VbMWrWRja6tpM+Zoxhefa4BvL8XExMi1YEGNHjdRNWo+6iNpZ2enLRvXa97smUqIj1e+/AX07nsd1f69Ti/6cAD9/PMJde38+wIkn02ZKElq3qKVxn06yaiygOcqbNVK5cmTV9Vfe93oUmDhbl6/rtHDBuve3Ttyzu6isp4VNGfxkjQjBdetCVWu3HlUpVqNJ15vbW2tKdNm6bOJY9Wjc3s5ODioUdMW6vLBhy/yMGDhTp44oW7v/34t7D/l0fVCsxYtNXbCJHV6v6sePnyo8aNH6v79eypXoaJmzp5nns2UKVMmbd+6RbNnTtfDhw+VM1cuvVajprp90JOgG8/d+TMnNWrgB+bHiwM/lyTVbthUfYaM+auXpXHu9M9avniOYmNjlN/VXR/0H6baDX6flmxnZ6+t60K1aJa/EhMSlCNXHlWtWUde73Z+vgcDIF0wpaT8/xhhg9SoUUODBw9Wy5Yt02wPCwvTpEmTtG/fvn/8nkwxRkZnZ2P19zsB6Zix3yzAs4uOTTS6BOCZOGay/vudgHTs1+sPjC4BeCalC2QxuoR04fq9l2s6eh6nl3fNC8NHEPr6+qpv3746d+6cqlV71Otg3759mjlzpiZNmqRjx46Z9y1btqxRZQIAAAAAAAAvJcNHEP5x0Ys/MplMSklJkclkUlJS0lO9JyMIkdExghAZHSMIkdExghAZHSMIkdExghAZHSMIH2EEYcZh+AjCCxcuGF0CAAAAAAAAYLEMDQgTEhI0ZswYjRgxQh4eHkaWAgAAAAAAgOfIZDK6AjwtQ+cx2traauXKlUaWAAAAAAAAAFg0wxudtWzZUmFhYUaXAQAAAAAAAFgkw3sQFi1aVGPHjtUPP/ygihUrytHRMc3zvr6+BlUGAAAAAAAAvPwMX8X4f/UeNJlM+vXXX//xe7KKMTI6VjFGRscqxsjoWMUYGR2rGCOjYxVjZHSsYvzIzfsv1zVVrqyGj7P7zxh+ZKxiDAAAAAAAABiHYUoAAAAAAACABTN8BOH777//P59fuHDhC6oEAAAAAAAAsDyGB4S3b99O8zghIUEnTpzQnTt3VLduXYOqAgAAAAAAACyD4QFhaGjoE9uSk5PVs2dPFS5c2ICKAAAAAAAA8MxMRheAp5UuexBaWVlpwIABmjp1qtGlAAAAAAAAAC+1dBkQStL58+eVmPhyLYcNAAAAAAAApDeGTzEeMGBAmscpKSmKiIjQunXr1LFjR4OqAgAAAAAAACyD4QHh4cOH0zy2srJSrly55O/v/7crHAMAAAAAACB9ogVhxmF4QLhu3TqlpKTI0dFRknTx4kWFhYXJzc1NNjaGlwcAAAAAAAC81AzvQdiyZUsFBwdLku7cuaNq1arJ399fLVu2VGBgoMHVAQAAAAAAAC83wwPCQ4cOqWbNmpKkkJAQ5cmTR7/99puCgoIUEBBgcHUAAAAAAADAy83wObwxMTHKmjWrJGnz5s3y8vKSlZWVqlWrpt9++83g6gAAAAAAAPBvmGhCmGEYPoKwSJEiCgsL06VLl7Rp0yY1bNhQknTjxg05OTkZXB0AAAAAAADwcjM8IBw5cqQGDRokd3d3Va1aVdWrV5f0aDRh+fLlDa4OAAAAAAAAeLmZUlJSUowu4tq1a4qIiJCnp6esrB5llj/++KOcnJz06quv/uP3uxeb/LxLBF4oOxvDs3vgmRj/zQI8m+jYRKNLAJ6JYyZro0sAnsmv1x8YXQLwTEoXyGJ0CelC5IOX65oqh6Phnfr+M+kiIHzeCAiR0REQIqN7+b5ZYGkICJHRERAioyMgREZHQPhI1IMko0t4rlwcX97vV1IIAAAAAAAAwIIREAIAAAAAAAAWjIAQAAAAAAAAsGAvb3dFAAAAAAAAGMZkMroCPC1GEAIAAAAAAAAWjIAQAAAAAAAAsGAEhAAAAAAAAIAFIyAEAAAAAAAALBgBIQAAAAAAAGDBCAgBAAAAAAAAC0ZACAAAAAAAAFgwG6MLAAAAAAAAwMvHZDK6AjwtRhACAAAAAAAAFoyAEAAAAAAAALBgBIQAAAAAAACABaMHIQAAAAAAAJ47k2hCmFEwghAAAAAAAACwYASEAAAAAAAAgAUjIAQAAAAAAAAsGD0IAQAAAAAA8NyZaEGYYTCCEAAAAAAAALBgBIQAAAAAAACABSMgBAAAAAAAACwYPQgBAAAAAADw3NGCMONgBCEAAAAAAABgwQgIAQAAAAAAAAtGQAgAAAAAAABYMHoQAgAAAAAA4PmjCWGGwQhCAAAAAAAAwIIREAIAAAAAAAAWjIAQAAAAAAAAsGAEhAAAAAAAAIAFY5ESAAAAAAAAPHcmVinJMBhBCAAAAAAAAFgwAkIAAAAAAFt5S/AAAC6kSURBVADAghEQAgAAAAAAABaMHoQAAAAAAAB47ky0IMwwGEEIAAAAAAAAWDACQgAAAAAAAMCCERACAAAAAAAAFowehAAAAAAAAHjuaEGYcTCCEAAAAAAAALBgBIQAAAAAAACABSMgBAAAAAAAACwYPQgBAAAAAADw/NGEMMNgBCEAAAAAAABgwQgIAQAAAAAAAAtGQAgAAAAAAABYMHoQAgAAAAAA4Lkz0YQww2AEIQAAAAAAAGDBCAgBAAAAAAAAC0ZACAAAAAAAAFgwehACAAAAAADguTPRgjDDYAQhAAAAAAAAYMEICAEAAAAAAAALRkAIAAAAAAAAWDBTSkpKitFFIGOJi4vTxIkTNXToUNnb2xtdDvCPcQ4jo+McRkbG+YuMjnMYGR3nMIA/Q0CIf+zevXvKli2b7t69KycnJ6PLAf4xzmFkdJzDyMg4f5HRcQ4jo+McBvBnmGIMAAAAAAAAWDACQgAAAAAAAMCCERACAAAAAAAAFoyAEP+Yvb29Ro0aRUNbZFicw8joOIeRkXH+IqPjHEZGxzkM4M+wSAkAAAAAAABgwRhBCAAAAAAAAFgwAkIAAAAAAADAghEQAgAAAAAAABaMgBAAAAAAAACwYASEAAAAAAAAgAUjIATw0nh8UXYWaEdGl5ycbHQJwD/COQsAAJBxERDiCd9//73u379vdBnAP5KcnCyTyWR+/Pj/AxlBaqh9+PBhSZKVFV/RyFhSz9np06crPDxcEjdrkHFx7gIALA2/PpDGsGHDNGDAAF2/ft3oUoCn9v333+vOnTuSHp3DY8eONbYg4F8wmUxav369KlasqO3btxtdDvCvJCQkaMaMGRo3bpwkbtYg40gNBH/++WfduXOHcxcZyl+N4GZkN4B/wsboApB+/Prrrzp69Kj8/f1VpEgRo8sBnsqdO3fUunVrlS9fXoUKFdKyZcu0d+9eo8sC/rHw8HBt375dM2fOVN26dY0uB/hXbG1t1b17d61du1Y3b95Urly5lJKSQtiCdC31HA0LC5Ovr6969OihAQMGKFOmTEaXBvyt5ORk8wjuXbt2KSoqSjY2NnrzzTdlY2OT5nkA+F9MKYyfh6TPP/9c8+bNU86cObV06VIVKFDA6JKAp3br1i25ubnJZDJp7dq1ql27ttElAf/I0aNHNXjwYEVERGj27NmqUaMGoQrSvb/60Xn58mWVKVNGo0ePVt++fQ2oDPjn1q5dK29vb02bNk1vvvmm3NzcjC4J+EeGDBmi1atXy2QyKWfOnLp165b27Nmj7NmzG10agAyCWwmQJDVv3lx37tzRDz/8oLNnzxpdDvC3UqdMpKSk6Pbt20pMTFSmTJk0ZcqUNFPkWbgEGcGdO3eUkpKic+fO6cyZM5IeTc3knEV6lhoOhoaG6ttvvzVvL1CggAYNGqSQkBBdunTJqPKAp/bgwQPNnj1bQ4YMUffu3ZUnTx5duXJFAQEB2rFjB613kO7NnDlTCxcuVHBwsE6dOqW3335bZ86cSTOrhmsKAH+HgBBKSUlRkSJFtHfvXuXIkUPjxo0jJES69violYMHD6pIkSKKi4vT4cOHdezYMfn4+OjGjRuSxMIlyBDeeOMNjR8/XnXr1tX06dO1Zs0aSYSESN9SUlJ07do1ffzxxxoyZIhef/11bd68WTdu3FCbNm10+fJl8/UEfbCQnsXFxenixYuys7PT3bt3NWzYMLVr105jx45V+/btFRISIomABelTSkqKTp48qU8++USVK1dWWFiYRowYoTlz5qhJkyZ68OCBkpKSuA4G8LcICC3YmjVr9MUXX2jWrFk6fPiw3N3dtXfvXh07dkx9+/bVL7/8YnSJwBMeDweHDRumPn36aMWKFYqOjparq6u2bNmin3/+WZ06ddLVq1eVmJioDh066PPPPze4cuCR1B+YEREROn/+vHlkStWqVTVkyBC5u7tr6tSpWrt2rSRCQqQvjwd9JpNJefPm1c6dO7Vq1Splz55do0ePVu3atXXu3DkVKFBAEyZMUHx8PP2vkK6kfqaeOnVK9+7dk4uLi9577z2NHj1a7u7u+vXXX+Xj46Nbt26pdu3a2rRpkyRuNCJ9+OM1gclk0qVLl5SQkKANGzbovffe0+TJk9WtWzclJydr4cKFmjdvnkHVAshI6EFooT766COFhITIw8NDzs7OCg0N1caNG9WwYUP9+uuvqlq1qqpUqaLPPvtMJUqUMLpc4Ampd0a/+uorVatWTU5OTubnTp48qQYNGsjBwUFOTk6KiYnR8ePHZWtra2DFQNpG+BMmTNClS5dUtmxZValSRePHj5ck7dixQ1988YWio6PVs2dPeXl5GVw18MjjN2j279+v27dvK1++fPLw8FDWrFklST/99JPWr1+v4OBgpaSk6PLly9qxY4eqV69Oo3ykC6mfw6tXr9agQYPUvn17DRs2TNbW1tq7d6+ioqLUpEkTSZK1tbV69Oghk8mkgIAAriNguMc/R3/77Te5urrKyspKEyZM0Nq1a3Xy5ElNnDhRvXr1kiTdvHlTnTp1Uu3atTV48GAjSweQAXCVZoGWLl2q4OBgLVu2TNu2bVPLli0lyTwls1ChQtq3b582bNig+fPnG1gp8OeOHz+ub775RitWrFDDhg2VnJysEydOKDAwUNu3b1fJkiV14sQJtW3bVm3bttWJEydka2urxMREo0uHhTOZTNqwYYM6dOigdu3aafv27SpXrpwCAwPVs2dPSVLt2rXVv39/JScna/HixYqOjja4ali6lJQUpaSkmH+UDhkyRF5eXurZs6cqV66s7t27a+PGjZKkypUra9SoUVq7dq2mTp2qfPnyacaMGZJEOIh0wWQyac2aNXrnnXc0aNAgdezYUba2trKyslKNGjXUrFkzWVtbKzw8XMOHD9eyZcv04YcfEg7CcI+Hg6NHj5aPj48OHDggSXrvvfd0//595cmTRxUrVlRMTIzCw8PVsWNHRUZGqn///kaWDiCDYAShBRo3bpyuX7+uGTNmaNWqVerYsaM+//xzdevWTffu3VNUVJTc3d115coV5c2bV9bW1kaXDAv3x1EnFy5cUPPmzTVy5Ei5ublpwYIF2rlzp0wmk86fP6/ly5ebg+9UiYmJsrGxecGVA2ldvXpV7777rry8vNS3b1/dvn1bZcqUkbu7u27evKm6desqMDBQkvTDDz/Izc2NVeVhqMuXL6c5B+fOnavhw4crJCREZcuW1Q8//KDp06fLxsZGQ4YMUc2aNdO8fuvWrerdu7dCQ0NVsmTJF10+8IQ7d+7I29tb9evX10cffaTY2FjduXNHYWFhKl++vEqVKqWTJ0/Kz89Px44d0/Lly1WuXDmjy4aFSx35KklDhw7V4sWLFRAQoNdff12vvPKKJOncuXNq0qSJ7OzsdPPmTRUuXFjJycnatWuXbG1tlZSUxO86AP8Tv5YtxONfKomJiUpKSlJoaKg6duwoPz8/devWTZK0evVqnT59WkOGDFH+/PnN+xOswEip4eDx48dVokQJZc6cWQUKFNCUKVN05MgRffDBB5o8ebKqVq2qt99+WxcvXnziPTiHkR7ky5dPrVq1Ur169XT9+nXVrl1bzZs3l5+fnz744AMtWrRI9+/f11dffaUaNWoYXS4sXO/eveXo6KgpU6aYf1ju379fjRs3Vq1atSRJb731lrJkyaKBAwfq22+/Vc2aNdPc1ClUqJASEhIUGxtr5KEAZiaTSeHh4bK2tlZ8fLxGjhypPXv26OzZs7p//74WL16sRo0aqXPnzipVqpTc3NyMLhkW7OjRo/L09DT/jtu3b5+WLFmiFStWqGbNmoqLi9O1a9d0+PBh1axZU4cOHdKPP/6os2fPqlixYnrjjTdkbW3N7zkAT4W5Hhbi8SXuCxcurO3bt+u9997TxIkT1aNHD0nSvXv3tHTpUiUmJqbp58aXCdKD7777Tp6engoKClKePHk0d+5cTZ48WTt27NCMGTPUvHlz5c6dW/Hx8cqUKZPR5QJ/qV+/fipdurQWL16sYsWKady4cXJ0dFT58uVVrFgx3bx5U1evXjW6TEANGzbUhAkTJD0adZXq/v37kn5fsOSNN97Qu+++qwULFuju3btpRnzv2rVLFy9eVM6cOV9c4cD/kC1bNrVp00bjxo1Tzpw5dfbsWXXo0EE3btxQ06ZNtXz5cmXLlk1NmjQhHIShhg8fbv4MTp30d/fuXdnb26t06dL68ccfNXLkSPNncKtWrRQeHq66deuqR48eqlu3rqytrZWUlMTvOQBPhU8KC3DkyBG9/vrrmj59unr37i0fHx9t3rxZV65ckYuLi86ePav4+HgNGjRIN2/e1Jo1aySlHXUIGK1OnToaOHCgPvzwQ1lZWalTp05ydXWVJMXExOjGjRvq1auXEhMT1bVrV4OrhaVLvZA3mUw6efKkwsPDZWVlpUKFCqlIkSKSpLNnz+rmzZvKkSOHpEfTj729vdWnTx9ly5bNsNqB1O//Fi1aSJKCgoK0ZMkSLVy4UI0bN5a3t7d2796t119/3fwaV1dXFStWLE04mJCQoCxZsujEiRMqWLDgCz8OIPVcPnLkiE6dOqWHDx+qfv36GjdunBo0aKDr16+rZcuW5mmXWbJkkbOzMwvqIF1o3bq1ypQpI0m6dOmSChYsqAoVKujy5ctq2LChzpw5o3feeUfjx49XwYIF9dZbb+nXX399op0D04oBPC0CwpfcrFmzdPr0aWXKlEm+vr56+PChBg0apK+++kotWrTQpEmTdOrUKVWqVEn29vbat2+fbGxs6FEBQ/1VOO3n5ycrKyt1795dVlZWeuedd2RnZ6d58+Zp/fr1evjwIecwDHX//n1lzZrVfP6uWrVKH374oTw8PBQVFaUcOXKoS5cu6ty5s1577TUdOXJE7dq1k6Ojo5YvX66DBw8SDsJwf/z8ffDgge7du6fBgwfLz89Pvr6+atq0qZYsWaJSpUopW7Zsmj9/vnLmzKksWbKYX2draysvLy9uNsIwJpNJK1euVL9+/VSgQAE5ODioe/fu+uabb9SqVSvzfuHh4Zo7d65Wr16t3bt3Ew4iXShfvrwkKTQ0VH379tWiRYtUr149nThxQkuXLlW5cuVUq1YtZc2aVUlJSSpcuLASEhIMrhpARkZA+BIbPny45s2bp6lTp6ps2bLasWOHxowZo4SEBA0dOlSrV6/WiRMnFBERofz58+vVV1+VlZUVPSpguNQfk59//rlKliypRo0amZ+bPHmyJKl79+6ytrZW+/bt1apVK+XOnVve3t70WYFhunfvrqSkJM2dO1fW1tb68ccf1a1bN40bN069evXShg0b1Lx5czVu3FiS1LRpU12/fl3btm2TjY2Ndu/eraJFixp8FMCTevbsqcyZM2vBggXq37+/Bg0aJAcHB7399tvKkSOHnJycZGdnpx9//FEmkynNTR7CQRjp0KFD+uCDDzRx4kR169ZN586dU7FixXTs2DFzQLhjxw7Nnz9f+/bt0/bt21lMB4Z7/DP02LFjsrOzU5UqVfTRRx/J399ftWvX1ieffCKTyaS4uDhFRkaqQ4cOSk5OVvPmzQ2uHkBGxirGL6nr16/rrbfeUp8+fdSxY0dJj1YinDdvnvz8/PTpp5+qX79+T7yOKRUw0h9HDjZt2lQ7duzQt99+qzp16qTZ980339TRo0c1ZswYffDBB+btjByEEZYtWyZfX19t2rTJfMd/wYIFWrlypdavX6+LFy+qTp06atSokXmV4sjISPP04piYGGXOnNmw+oG/8vjn8qJFi/Tll18qb968CgwM1KVLl3T27FlJUqtWrbhBg3QnNDRUX331lVauXKkLFy6oVq1aatasmWbNmiXp0ajvxMREfffdd6pQoYLc3d2NLRgW7/HfYv369dOmTZu0a9cunTp1SgEBAfrll18UEBCgWrVqKT4+XnPmzNGSJUskSTt37mS1YgDPhCToJWVtba3ffvtNt27dMm8rUKCAunbtKk9PTw0YMEBffPGF+bnUnJhwEEZK/RF65coVSdLatWvVqlUreXl5afv27eb9UlJS5O7uLicnJy1ZskSP3+fggghGuHTpknLkyKHy5ctr9erVmjZtmpKTk+Xq6qpr167p9ddf15tvvqmZM2dKkrZs2aKFCxfq9u3bkkQ4iHQrdUSgJHXu3FkdO3bUlStX1LNnT2XNmlVvv/22WrduTSN8pEsRERG6evWqfvnlF9WuXVtNmjTRjBkzJD26xhgyZIjs7e3l5eVFOIh0IfW32O3bt3X79m3NmDFDOXPmVM2aNdW3b18VK1ZMvr6+2rVrl+zs7FSrVi1zX1hbW1slJiZyLQzgXyMNeklly5ZNzZo10/79+/XLL7+Yt7u6uqpChQqqV6+e/P39tXTpUklMAYKxUlfClKQ5c+aoe/fu2rNnjyQpODhYjRs31ttvv61t27bp/v37MplMunv3rkJCQrRjx440P2ABI9SuXVspKSmqV6+eWrVqJTc3N+XMmVNBQUEqXbq0vLy8NHv2bPOFf0hIiI4fPy47OzuDKwf+3h9Dwvfff19Xr17V0KFDdeHCBfM1BD9Kkd5Uq1ZNdnZ2qlq1qurWras5c+aYn9u+fbtu3LihxMREAysEnjRnzhwVLlxYp0+floeHh3n766+/Ll9fXxUrVkz9+vXTtm3b5Onpqf79+3OTBsBzQUD4Ejl79qxOnjwp6VFj8EaNGunYsWOaN2+ezpw5I+nRVIqIiAh5e3urevXqWrduneLi4ghXYJjHp1L88MMPOnPmjLZu3Sp/f38dOHBAkrRkyRI1a9ZMTZo0UYsWLVSuXDn9/PPPKlWqlEwmk5KTkwm5YajKlSurXr16+u6771StWjW1atVKrVq1Uvfu3XX79m01b95cd+/eVWRkpD7++GOFhoZq6NChcnR0NLp04Kn8MSTs0qWLIiIiNGfOHK4jYLjU8+/o0aPavHmzdu7cKUkqV66cypYtK1tbW5UrV053797VlStXNHToUAUFBWnMmDFycnIysnTgCRUrVlTJkiX1888/KzY2VpLMi4+8/vrr6tu3r5ydnRUcHJzmddykAfCs6EH4kki90ElKSpKHh4eCg4NVpEgRzZ8/X1988YXs7e1VoEABXb58WYmJiTpy5IgGDx6snTt3as+ePXyhwHCDBw/WsmXL1KlTJ924cUPBwcGqX7++hg8fripVqkiSpk+frkuXLkmSPv30U1YrRrrx8OFDNW3aVIUKFdKePXtUtmxZLV26VDExMXr//fcVFhYmV1dX5cyZUxEREQoNDTX3KgQyksd7Eg4ePFj79u3Ttm3bGA0Lw4WGhqpDhw5ydXXV2bNn1adPH33++eeSpE6dOuno0aM6d+6cPD09devWLa1YsYLPYRjuz/q/JyUl6cSJE2rfvr3s7Oy0e/duZc6cOU2P12PHjql06dK0hwLwXBEQvgRCQ0M1cOBATZ06VXZ2dho3bpwiIiK0cuVKVahQQbt27dLBgwe1d+9eFS5cWKNGjZK9vb06duwoKysrzZkzhwt7GOqnn37SW2+9pZCQENWqVUuStG/fPnl5eal8+fIaOXKkqlat+sTraIaP9CR1oZGFCxdqypQpqlKlioKCgiRJa9asUVRUlFxcXFShQgUVKFDA4GqBfy81JBwzZoyCgoJ06NAhZcuWzeiyYGFSf8KYTCZFRkbqrbfeUo8ePVS7dm0dO3ZMbdu2VZs2bbRo0SJZWVnp9OnTOnTokIoUKSJXV1fly5fP4COApXs8HNy2bZtu374tNzc3FS9eXE5OTjpx4oRat26tbNmy6fvvv5eDg4MSEhJka2v7p+8BAM+KgDCDW7ZsmaKiopSUlKQ+ffpIejQEvV69egoPD9eqVatUoUKFNK+5fPmyZs2apcDAQO3evVulSpUyonTA7PDhw2rWrJnWrFmjChUqmIO/PXv2qFatWmrTpo369u2ratWqGV0q8Leio6P1zTffaPLkyapQoYJ5dUHgZZKSkqKQkBAVK1ZMnp6eRpcDC3L16lXlzZvXHIps2rRJmzZtUlRUlKZNmyZnZ2dJ0o4dO9S4cWN5e3srICCAEBvp1pAhQxQYGKjcuXMrPDxczZs3V7du3fTmm2/q+PHj8vb2lrOzs7Zt28aiZgD+U9xuyMDu37+vAQMG6MMPP9Tly5clPbpgt7W11bZt2+Tm5qa2bdtqz5495rus0dHRmjhxor799lt99913hIN44R5fkCQpKUmSlClTJt27d08nTpyQ9Og8Tk5OVoUKFVS8eHFt375dM2bMUGRkpCE1A/9ElixZ5O3trSFDhuj48eNq3ry50SUBz53JZFKbNm0IB/FCLVy4UOXLl9f+/fvN17YRERGaNm2aNm7cqPv370t6dK1Ru3ZtbdiwQWFhYeratauioqKMLB0we3x8zo8//qjVq1dr/fr1OnbsmDZu3KiYmBhNnTpV33//vcqUKaPly5fr7Nmz8vX1NbBqAJaAEYQZ3KVLl+Tt7a179+5p7dq18vDwME/9SUxMVJkyZVSmTBmtWLHC/JrIyEjFx8frlVdeMbByWKLHp0EEBgbq5s2bGjhwoBwdHTV69GhNnDhRa9euVYMGDSRJDx480MCBA1WvXj21a9dOgYGB6tq1q5GHADy1Bw8eKCgoSIsXL1ZoaCjT2QDgGaWkpMjT01MpKSmaN2+eKleuLGtra4WEhOjdd9/VoEGDNG7cONnY2Jivh7ds2aKOHTvq4MGDXPsiXZkyZYquXbummJgYzZ4927z9hx9+0MCBA1WlShUFBAQoOTlZv/76qzw8POi7DeA/RUCYAW3dulXR0dGysrJS8+bNdfnyZTVu3FgODg5auXKlXF1dzRdFqSO0Ur9MHm8uDrxIf2xsv2TJEg0fPlyNGjWSh4eHrl27ppEjR2r+/Pn66KOP5OLiok2bNunu3bs6cOCA6tatKw8PDy1YsMDgIwGeXkxMjBISEpjaBgDPKD4+3twzu2LFioqPj9fs2bNVrVo1WVtbKygoSO+//74++eQTjRo1StbW1uZrj4cPH8rBwcHgI4Cle/xG+e3btzVp0iT5+fmpUqVK2rJlS5prhdmzZ2vgwIH69ddflSdPHvN2FucD8F+iu38GM3ToUAUHByt37tw6deqU2rZtq/Hjx2v9+vVq3Lix3n77ba1cudLcAD/1CyT1y4RwEC9aXFyc7O3tzefeggULFBwcrG+//VaVK1c275cjRw7NmjVLFSpU0Ny5c2Vvb688efJow4YNkh4tSOLh4WHIMQD/Fr2CAOD5SF2Y4eLFi/r000/VuHFjDRkyRH5+fqpSpYp8fHwkSe+//76srKw0fPhw80JmhINID1LDwU8++URRUVH67LPP5OjoqDFjxmjVqlXy8fEx/3Zzc3NToUKF9MexPISDAP5L9CDMQKZMmaIvv/xSq1at0qFDh+Tn56egoCD17dtXJpNJGzduVGxsrGrWrKkbN26keS1fJjBCu3bttHXrVkm/91s5fPiwmjZtqsqVK+vUqVOaN2+eKlasqHLlymnTpk3q0aOHvvvuO+3du1dhYWGys7PTJ598ovPnz6tt27ZGHg4AADCIyWRSWFiYSpQood27d6tt27a6evWqunTpoh9//FFJSUny8fHR4sWLNXbsWE2ZMsXokgFJaXsObtq0SaGhoeratauyZMmikSNHql+/furRo4dmzpypI0eOKDw83LzgzuOjBwHgv8YIwgzi6tWrOnnypKZOnaoqVapo1apVGjlypIYPH66AgAD17dtX/v7+Wr16tUaMGKEcOXIYXTKgIkWKqF69epIejQC0tbVV/vz5FRAQoE8++USbN29WwYIF1aRJE4WHh8vHx0fnz583r0B44sQJLVy4UMuWLdO6detUtGhRA48GAAAY5datWxo6dKiGDx+uYcOGSZKioqJUt25ddenSRQsWLFDlypXVoUMH2draqmzZsgZXDDySOotm+fLl2rdvn5o2bapKlSopMTFRNjY28vf3l5WVlfr166fMmTPr3XffVVJSkrZv3y6TyZRmajIA/JcICDMIFxcXtWjRQnXq1NGBAwc0cOBAjR49Wr6+vnJ2dtagQYN0+/ZtLVu2TMHBwZLoUQHjfPzxx3r11Vc1duxYSdKsWbNka2urjh07qk2bNrp7965Wr16tbt26qWHDhipZsqS2b9+u3377zdw3U5JcXV3VrFkz9e3bV25ubkYdDgAAMFjqwiOpNwsTEhLk4uKirVu3qkKFCho2bJhGjhypmjVrMuMA6UJqD8zk5GQlJyfrs88+08GDB/Xmm29KenROp4Z/fn5+cnJy0qhRo1SvXj298847kmQOEQHgReDTJoPIlCmTmjZtKltbW23dulWlSpVSx44dJUl2dnZq3769bt26pZw5c5pfQzgII9y5c0f79+/X3r17lZSUpC5dumjz5s06fvy4smTJojZt2mjSpEkaNmyYsmbNKulRmO3n56ds2bLJxcXF/F7ZsmVTnTp1jDoUAACQTjg7O8vKykrbtm2Tt7e3bG1tlZiYKBcXF5UpU0YbNmzQw4cP9d1333ENjHQhdeTgjRs3lDdvXu3cuVPt27fXTz/9pK+//lpt2rSRnZ2dOSQcMWKEoqKi1KlTJ9na2qp169aEgwBeKMYqZyCpXxBnz57V3bt3ZTKZFBsbq02bNqlp06basGGDrKyslJycbHClsFQpKSlydnbW8uXLlTt3bgUHByskJERhYWGqVauWRo8eraVLlyomJkZZs2bV/fv3FRYWpoYNGyoiIkIhISEymUxPNGQGAACW46+uA4YPH65169Zp4sSJkh5dG1tZWenVV1/V7t27tXTpUmXKlOlFlgr8T8HBwerSpYt++uknOTg46Ouvv1aJEiU0depUrV27VgkJCWl+v02dOlV9+vRRmzZttHr1aoOrB2BpuCWRgaTeherevbtq1aqlGjVqKC4uTpkyZVLr1q3N+9GjAkZJTk6WtbW1cufOrQEDBmjo0KGaNGmS7OzstGjRIvn4+GjChAmSpDZt2ujmzZs6dOiQPDw8tGnTJtnY2DCVAgAAC5Y6LXPnzp3as2ePwsPD1bVrV5UuXVpNmzbVuXPnFBAQoNOnT+u1117T4cOH9fXXX2vAgAHKnz+/0eUDaSQmJioqKkpffPGF+vXrp0qVKiksLEzNmzfXpEmTZDKZzLPEUvn5+cnOzk7Fixc3sHIAlsiUwlCdDOnQoUNatWqVnJycNGDAAIIVpCsDBw7U+fPnFRERoVOnTilXrlzy8/OTl5eXfHx8dODAAY0YMULe3t6KiYlRlixZZDKZ6JsJAAAUGhqq999/XzVq1FBsbKyOHTumjz/+WF27dpW1tbU2btyo8ePHy9raWjY2Npo9e7bKlStndNmwcH+1mMiyZcs0c+ZMFShQQAMHDlSlSpUUExOjVq1a6fTp0woKCtIbb7xhQMUAkBYB4UuCcBDpRVBQkPr166etW7fKzc1NcXFx6tSpk27fvq3hw4erRYsW6tSpk8LCwrRixQo1bNhQ0u8jBgAAgOXat2+fWrdurfHjx6tz585KTEyUg4ODcufOrV69eqlnz57mfsUPHz5UcnKyHB0dDa4a+N2WLVtUqFAhFS5c2LxtyZIlCgwMVP78+TV06FB5enrqwYMHGjZsmPz9/blBDiBdIFF6SRAOIr04f/68SpYsqXLlyslkMslkMmnRokXy8vJS//79JUmLFy/W+PHjVa9ePfPrCAcBAMD58+f13nvvqXPnzrpw4YLq1q2rXr16ydHRUaNGjZKNjY3eeecdubm5ycHBwehygTQjB48cOaIuXbqoRYsWGjhwoNzd3SVJ7dq1U3x8vHx9fWVlZaUPP/xQr732mqZNmyZJzKIBkC4wghDAc5E6AnDSpElauXKldu7cKQcHByUkJMjW1lbbtm1TixYtVKBAAc2aNUt169aVxAURAACWLPX64ejRo8qVK5dSUlJ09+5dFSpUSM2bN1fBggU1f/58SVKBAgX04MEDjRw5Ur6+vlw/wHCPh4Nr1qxRrVq1FBQUpODgYL322mvq37+/OSSUpHLlyikyMlJdu3bVqFGjmEEDIF1hNQsAz0XqxU2zZs105MgRTZkyRZLMTZfj4uJUr149tW7dWrVr1za/jot7AAAsU2o4EhYWpsaNG2v27NnKnj27SpYsqYiICF27ds28EN+VK1dUp04ddevWTc2aNeP6AYZLSUkxh4OffPKJunfvrmXLlsnX11fvvvuudu7cqWnTpunixYuSpGvXrqly5coaP368RowYIYkZNADSF+alAniuSpUqpXnz5ql79+6Kjo6Wt7e3XFxcNHPmTJUtW9a8ijEjBwEAsGwmk0nr1q1Tu3btFBAQoCZNmihz5sySpOjoaEVGRurmzZv67bfftHjxYoWHh2vu3LlMLUa6kBrujRs3TvPmzdP69etVtGhRSdKAAQPk4OCg4OBg9e7dW3Xr1tXmzZslST4+PjKZTH+5qAkAGIUpxgD+EytXrlSvXr1kZ2cnScqVK5f2798vW1tbplMAAADFxsbKx8dHRYsW1YQJExQTE6Nr167pm2++UeXKlTVx4kQdPnxY2bNn1927d7Vx40ZVqFDB6LIBs6ioKLVt21adOnVS+/btdeXKFZ09e1bLli1T/fr19csvv+jkyZM6evSoihQpohUrVnAtDCDdYgQhgP9E69atVb16dV25ckUPHjxQzZo1ZW1tzYrbAABA0qMpmhcuXFDevHkVFRWlUaNG6fjx4zpz5owyZcqkgQMHytfXVykpKSpbtmyaXm5AemAymXTy5EmdOnVKO3fu1KxZs3ThwgUlJydrzZo1GjFihL788kvdvXtX2bNnl8lk4loYQLrFCEIALwzTigEAwOOCgoLUo0cP2draql69emrZsqV8fHzUp08fnTlzRhs3bmQaJtK1BQsWaPDgwUpKSlKPHj3UoEED1a9fXx06dJC1tbW+/PJL875MKwaQnnHrAsALQzgIAAAe5+Pjo0qVKunKlStq0KCBkpOTJT0aXZg3b14lJCTI3t7e4CqBv9alSxc1aNBAcXFx5h6EycnJunbtmqpVq5ZmX8JBAOkZIwgBAAAApAunT59WcHCwZs6cqd27d6t06dJGlwQ8tejoaB05ckSTJ0/Wb7/9pkOHDjGdGECGwacVAAAAAMMdPHhQ/v7+OnLkiL7//nvCQWQoKSkpOnDggPz9/ZWQkKCDBw/KxsaGFjsAMgxGEAIAAAAw3MOHD3XgwAG5u7vL1dXV6HKAfywuLk4nT56Up6enrKysWJAEQIZCQAgAAAAAwHPEgiQAMhoCQgAAAAAAAMCCcUsDAAAAAAAAsGAEhAAAAAAAAIAFIyAEAAAAAAAALBgBIQAAAAAAAGDBCAgBAAAAAAAAC0ZACAAAAAAAAFgwAkIAAJBhdOrUSS1btjQ/rl27tvr16/fC69ixY4dMJpPu3Lnzn/2NPx7rv/Ei6gQAAEDGR0AIAACeSadOnWQymWQymWRnZ6ciRYpo7NixSkxM/M//9qpVqzRu3Lin2vdFh2Xu7u6aNm3aC/lbAAAAwLOwMboAAACQ8TVq1EiLFi1SXFyc1q9fr969e8vW1lZDhw59Yt/4+HjZ2dk9l7/r4uLyXN4HAAAAsGSMIAQAAM/M3t5eefPmlZubm3r27Kn69etrzZo1kn6fKjthwgTly5dPxYsXlyRdunRJ3t7ecnZ2louLi1q0aKGLFy+a3zMpKUkDBgyQs7OzcuTIoY8++kgpKSlp/u4fpxjHxcVpyJAhcnV1lb29vYoUKaIFCxbo4sWLqlOnjiQpe/bsMplM6tSpkyQpOTlZEydOlIeHhxwcHOTp6amQkJA0f2f9+vUqVqyYHBwcVKdOnTR1/htJSUnq0qWL+W8WL15cX3zxxZ/uO2bMGOXKlUtOTk7q0aOH4uPjzc89Te0AAADA32EEIQAAeO4cHBwUGRlpfrxt2zY5OTlpy5YtkqSEhAS9+eabql69unbt2iUbGxuNHz9ejRo10rFjx2RnZyd/f38tXrxYCxcuVIkSJeTv76/Q0FDVrVv3L/+uj4+P9u7dq4CAAHl6eurChQu6deuWXF1dtXLlSrVu3VpnzpyRk5OTHBwcJEkTJ07UV199pdmzZ6to0aLauXOnOnTooFy5cumNN97QpUuX5OXlpd69e6t79+46cOCABg4c+Ez/PsnJySpQoIC++eYb5ciRQ3v27FH37t31yiuvyNvbO82/W6ZMmbRjxw5dvHhRnTt3Vo4cOTRhwoSnqh0AAAB4GgSEAADguUlJSdG2bdu0adMm9enTx7zd0dFR8+fPN08t/uqrr5ScnKz58+fLZDJJkhYtWiRnZ2ft2LFDDRs21LRp0zR06FB5eXlJkmbPnq1Nmzb95d8+e/asVqxYoS1btqh+/fqSpEKFCpmfT52OnDt3bjk7O0t6NOLw008/1datW1W9enXza3bv3q05c+bojTfeUGBgoAoXLix/f39JUvHixXX8+HFNnjz5X/872draasyYMebHHh4e2rt3r1asWJEmILSzs9PChQuVOXNmlSpVSmPHjtXgwYM1btw4JSQk/G3tAAAAwNMgIAQAAM9s7dq1ypIlixISEpScnKx27dpp9OjR5ufLlCmTpu/g0aNHde7cOWXNmjXN+8TGxur8+fO6e/euIiIiVLVqVfNzNjY2qlSp0hPTjFMdOXJE1tbW/ygYO3funGJiYtSgQYM02+Pj41W+fHlJ0qlTp9LUIckcyD2LmTNnauHChQoPD9fDhw8VHx+vcuXKpdnH09NTmTNnTvN3o6OjdenSJUVHR/9t7QAAAMDTICAEAADPrE6dOgoMDJSdnZ3y5csnG5u0lxiOjo5pHkdHR6tixYr6+uuvn3ivXLly/asaUqcM/xPR0dGSpHXr1il//vxpnrO3t/9XdTyNZcuWadCgQfL391f16tWVNWtW+fn5af/+/U/9HkbVDgAAgJcPASEAAHhmjo6OKlKkyFPvX6FCBS1fvly5c+eWk5PTn+7zyiuvaP/+/apVq5YkKTExUQcPHlSFChX+dP8yZcooOTlZ33//vXmK8eNSRzAmJSWZt5UsWVL29vYKDw//y5GHJUqUMC+4kmrfvn1/f5D/ww8//KDXXntNvXr1Mm87f/78E/sdPXpUDx8+NIef+/btU5YsWeTq6ioXF5e/rR0AAAB4GqxiDAAAXrj27dsrZ86catGihXbt2qULFy5ox44d8vX11eXLlyVJffv21aRJkxQWFqbTp0+rV69eunPnzl++p7u7uzp27Kj3339fYWFh5vdcsWKFJMnNzU0mk0lr167VzZs3FR0draxZs2rQoEHq37+/vvzyS50/f16HDh3S9OnT9eWXX0qSevTooV9++UWDBw/WmTNntGTJEi1evPipjvPKlSs6cuRImv9u376tokWL6sCBA9q0aZPOnj2rESNG6Keffnri9fHx8erSpYtOnjyp9evXa9SoUfrwww9lZWX1VLUDAAAAT4OAEAAAvHCZM2fWzp07VbBgQXl5ealEiRLq0qWLYmNjzSMKBw4cqPfee08dO3Y0T8Nt1arV/3zfwMBAvf322+rVq5deffVVdevWTQ8ePJAk5c+fX2PGjNHHH3+sPHny6MMPP5QkjRs3TiNGjNDEiRNVokQJNWrUSOvWrZOHh4ckqWDBglq5cqXCwsLk6emp2bNn69NPP32q4/zss89Uvnz5NP+tW7dOH3zwgby8vNS2bVtVrVpVkZGRaUYTpqpXr56KFi2qWrVqqW3btmrevHma3o5/VzsAAADwNEwpf9XpGwAAAAAAAMBLjxGEAAAAAAAAgAUjIAQAAAAAAAAsGAEhAAAAAAAAYMEICAEAAAAAAAALRkAIAAAAAAAAWDACQgAAAAAAAMCCERACAAAAAAAAFoyAEAAAAAAAALBgBIQAAAAAAACABSMgBAAAAAAAACwYASEAAAAAAABgwf4PT36NI+KIbNIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1400x1200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger     0.6486    0.6622    0.6553      4278\n",
      "     disgust     0.8032    0.7565    0.7792      1187\n",
      "        fear     0.6995    0.7826    0.7388      1187\n",
      "         joy     0.8243    0.8346    0.8295      9519\n",
      "     sadness     0.5295    0.4796    0.5033      1570\n",
      "    surprise     0.6276    0.5943    0.6105      2512\n",
      "\n",
      "    accuracy                         0.7333     20253\n",
      "   macro avg     0.6888    0.6850    0.6861     20253\n",
      "weighted avg     0.7314    0.7333    0.7320     20253\n",
      "\n",
      "\n",
      "=== Step 4 Complete! Analysis saved. ===\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# ==========================================\n",
    "# CONFIGURATION\n",
    "# ==========================================\n",
    "print(\"\\n=== Step 4: 7-Model Ensemble Visualization & Confusion Matrix =========\\n\")\n",
    "\n",
    "# Defined 7 Models\n",
    "MODEL_MAP = [\n",
    "    # 1. BERT Original\n",
    "    {\n",
    "        \"name\": \"BERT Original\",\n",
    "        \"path\": \"./results_bert\", \n",
    "        \"tokenizer_id\": \"monologg/bert-base-cased-goemotions-original\", \n",
    "        \"weight\": 0.3\n",
    "    },\n",
    "    # 2. RoBERTa\n",
    "    {\n",
    "        \"name\": \"RoBERTa Go\",\n",
    "        \"path\": \"./results_roberta\", \n",
    "        \"tokenizer_id\": \"SamLowe/roberta-base-go_emotions\", \n",
    "        \"weight\": 0\n",
    "    },\n",
    "    # 3. Twitter RoBERTa \n",
    "    {\n",
    "        \"name\": \"Twitter RoBERTa\",\n",
    "        \"path\": \"./results_twitter_roberta\", \n",
    "        \"tokenizer_id\": \"cardiffnlp/twitter-roberta-base-emotion\", \n",
    "        \"weight\": 0.1\n",
    "    },\n",
    "    # 4. DistilBERT Student \n",
    "    {\n",
    "        \"name\": \"DistilBERT Student\",\n",
    "        \"path\": \"./results_distilbert_student\", \n",
    "        \"tokenizer_id\": \"joeddav/distilbert-base-uncased-go-emotions-student\", \n",
    "        \"weight\": 0.2\n",
    "    },\n",
    "    # 5. DistilEmotion \n",
    "    {\n",
    "        \"name\": \"DistilEmotion\",\n",
    "        \"path\": \"./results_distil_emotion\", \n",
    "        \"tokenizer_id\": \"j-hartmann/emotion-english-distilroberta-base\", \n",
    "        \"weight\": 0.1\n",
    "    },\n",
    "    # 6. BERT Group \n",
    "    {\n",
    "        \"name\": \"BERT Group\",\n",
    "        \"path\": \"./results_bert_group\", \n",
    "        \"tokenizer_id\": \"monologg/bert-base-cased-goemotions-group\", \n",
    "        \"weight\": 0.2\n",
    "    },\n",
    "    # 7. BERT Ekman \n",
    "    {\n",
    "        \"name\": \"BERT Ekman\",\n",
    "        \"path\": \"./results_bert_ekman\", \n",
    "        \"tokenizer_id\": \"monologg/bert-base-cased-goemotions-ekman\", \n",
    "        \"weight\": 0.1\n",
    "    }\n",
    "]\n",
    "\n",
    "MAX_LENGTH = 64\n",
    "BATCH_SIZE = 32\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ==========================================\n",
    "# 1. LOAD VALIDATION DATA & RESTORE TEXT\n",
    "# ==========================================\n",
    "print(\"--- Loading Validation Data ---\")\n",
    "\n",
    "try:\n",
    "    pt_file = \"preprocessed_bert.pt\" \n",
    "    base_tokenizer_id = \"monologg/bert-base-cased-goemotions-original\"\n",
    "\n",
    "    if not os.path.exists(pt_file):\n",
    "        files = [f for f in os.listdir(\".\") if f.endswith(\".pt\") and \"preprocessed\" in f]\n",
    "        if not files:\n",
    "            raise FileNotFoundError(\"No preprocessed .pt file found!\")\n",
    "        pt_file = files[0]\n",
    "        print(f\"Default file not found, falling back to: {pt_file}\")\n",
    "\n",
    "    print(f\"Loading data from: {pt_file}\")\n",
    "    data = torch.load(pt_file, weights_only=False)\n",
    "    \n",
    "    y_val_true = data['y_val'].numpy()\n",
    "    label_encoder = data['label_encoder']\n",
    "    class_names = label_encoder.classes_\n",
    "    \n",
    "    print(f\"Validation samples: {len(y_val_true)}\")\n",
    "    print(f\"Classes ({len(class_names)}): {class_names}\")\n",
    "\n",
    "    # 2. Restore Text from Tensor IDs\n",
    "    print(f\"Restoring raw text using: {base_tokenizer_id}...\")\n",
    "    base_tokenizer = AutoTokenizer.from_pretrained(base_tokenizer_id)\n",
    "    \n",
    "    val_input_ids = data['val_encodings']['input_ids']\n",
    "    val_texts = []\n",
    "    \n",
    "    # Batch decode for speed\n",
    "    for ids in tqdm(val_input_ids, desc=\"Decoding Text\"):\n",
    "        text = base_tokenizer.decode(ids, skip_special_tokens=True)\n",
    "        val_texts.append(text)\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"[Critical Error] Data loading failed: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# ==========================================\n",
    "# 2. ENSEMBLE INFERENCE LOOP\n",
    "# ==========================================\n",
    "print(\"\\n--- Running Ensemble Inference on Validation Set ---\")\n",
    "\n",
    "all_model_probs = []\n",
    "used_weights = []\n",
    "valid_models = []\n",
    "\n",
    "for entry in MODEL_MAP:\n",
    "    name = entry[\"name\"]\n",
    "    model_path = entry[\"path\"]\n",
    "    tokenizer_id = entry[\"tokenizer_id\"]\n",
    "    weight = entry[\"weight\"]\n",
    "    \n",
    "    print(f\"\\nProcessing: {name}\")\n",
    "    \n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"  [Skip] Model path not found: {model_path}\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # Load Tokenizer & Model\n",
    "        tokenizer = AutoTokenizer.from_pretrained(tokenizer_id) \n",
    "        model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "        model.to(DEVICE)\n",
    "        model.eval()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  [Error] Failed to load {name}: {e}\")\n",
    "        continue\n",
    "\n",
    "    model_probs = []\n",
    "    \n",
    "    # Batch Prediction\n",
    "    for i in tqdm(range(0, len(val_texts), BATCH_SIZE), desc=f\"  Predicting {name}\"):\n",
    "        batch_texts = val_texts[i : i + BATCH_SIZE]\n",
    "        \n",
    "        inputs = tokenizer(\n",
    "            batch_texts, \n",
    "            padding=True, \n",
    "            truncation=True, \n",
    "            max_length=MAX_LENGTH, \n",
    "            return_tensors=\"pt\"\n",
    "        ).to(DEVICE)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            # Softmax to get probabilities (sum to 1)\n",
    "            probs = F.softmax(outputs.logits, dim=-1)\n",
    "            model_probs.append(probs.cpu().numpy())\n",
    "            \n",
    "    full_probs = np.concatenate(model_probs, axis=0)\n",
    "    print(f\"  Output Shape: {full_probs.shape}\")\n",
    "\n",
    "    # Dimension Check\n",
    "    if len(all_model_probs) > 0:\n",
    "        prev_shape = all_model_probs[0].shape\n",
    "        if full_probs.shape[1] != prev_shape[1]:\n",
    "            print(f\"  [CRITICAL] Shape mismatch! This model has {full_probs.shape[1]} classes, ensemble expects {prev_shape[1]}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "    all_model_probs.append(full_probs)\n",
    "    used_weights.append(weight)\n",
    "    valid_models.append(name)\n",
    "    \n",
    "    # Cleanup memory\n",
    "    del model, tokenizer, inputs, outputs\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# ==========================================\n",
    "# 3. AGGREGATION & PLOTTING\n",
    "# ==========================================\n",
    "print(\"\\n--- Generating Visualization ---\")\n",
    "\n",
    "if not all_model_probs:\n",
    "    raise ValueError(\"No models executed successfully!\")\n",
    "\n",
    "# Recalculate weights (Normalization) to ensure they sum to 1\n",
    "total_weight = sum(used_weights)\n",
    "if total_weight == 0:\n",
    "    print(\"[Warning] Total weight is 0. Using equal weights.\")\n",
    "    norm_weights = [1.0/len(used_weights)] * len(used_weights)\n",
    "else:\n",
    "    norm_weights = [w/total_weight for w in used_weights]\n",
    "\n",
    "print(f\"Models Used: {valid_models}\")\n",
    "print(f\"Effective Weights: {np.round(norm_weights, 2)}\")\n",
    "\n",
    "# Weighted Average\n",
    "final_probs = np.zeros_like(all_model_probs[0])\n",
    "for i, probs in enumerate(all_model_probs):\n",
    "    final_probs += probs * norm_weights[i]\n",
    "\n",
    "# Get Predictions\n",
    "y_val_pred = np.argmax(final_probs, axis=1)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_val_true, y_val_pred)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(14, 12))\n",
    "sns.heatmap(\n",
    "    cm, \n",
    "    annot=True, \n",
    "    fmt='d', \n",
    "    cmap='Blues', \n",
    "    xticklabels=class_names, \n",
    "    yticklabels=class_names\n",
    ")\n",
    "plt.title(f'7-Model Ensemble Confusion Matrix\\nModels: {\", \".join(valid_models)}')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save Image\n",
    "save_path = \"confusion_matrix_ensemble_7models.png\"\n",
    "plt.savefig(save_path)\n",
    "print(f\"Confusion matrix saved to: {save_path}\")\n",
    "plt.show()\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\n--- Classification Report ---\")\n",
    "report = classification_report(y_val_true, y_val_pred, target_names=class_names, digits=4)\n",
    "print(report)\n",
    "\n",
    "# Save Report\n",
    "with open(\"classification_report_ensemble.txt\", \"w\") as f:\n",
    "    f.write(report)\n",
    "\n",
    "print(\"\\n=== Step 4 Complete! Analysis saved. ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Step 5: 7-Model Ensemble Inference =========\n",
      "\n",
      "--- Loading Metadata ---\n",
      "Loading metadata from: preprocessed_bert.pt\n",
      "Test samples: 16281\n",
      "Ensembling 7 models...\n",
      "\n",
      "------------------------------------------------------\n",
      "Processing: ./results_bert\n",
      "Tokenizer:  monologg/bert-base-cased-goemotions-original\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 509/509 [00:11<00:00, 44.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------\n",
      "Processing: ./results_roberta\n",
      "Tokenizer:  SamLowe/roberta-base-go_emotions\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 509/509 [00:10<00:00, 46.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------\n",
      "Processing: ./results_twitter_roberta\n",
      "Tokenizer:  cardiffnlp/twitter-roberta-base-emotion\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 509/509 [00:10<00:00, 46.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------\n",
      "Processing: ./results_distilbert_student\n",
      "Tokenizer:  joeddav/distilbert-base-uncased-go-emotions-student\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 509/509 [00:06<00:00, 84.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------\n",
      "Processing: ./results_distil_emotion\n",
      "Tokenizer:  j-hartmann/emotion-english-distilroberta-base\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 509/509 [00:06<00:00, 84.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------\n",
      "Processing: ./results_bert_group\n",
      "Tokenizer:  monologg/bert-base-cased-goemotions-group\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 509/509 [00:11<00:00, 44.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------\n",
      "Processing: ./results_bert_ekman\n",
      "Tokenizer:  monologg/bert-base-cased-goemotions-ekman\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 509/509 [00:11<00:00, 44.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating Weighted Average...\n",
      "Normalized Weights: [0.3 0.  0.1 0.2 0.1 0.2 0.1]\n",
      "\n",
      "Ensemble submission saved to: submission_ensemble_7models.csv\n",
      "=== Step 5 Complete! ==================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# --- Configuration ---\n",
    "print(\"\\n=== Step 5: 7-Model Ensemble Inference =========\\n\")\n",
    "\n",
    "MODEL_MAP = [\n",
    "    # 1. BERT Original \n",
    "    {\n",
    "        \"path\": \"./results_bert\", \n",
    "        \"tokenizer_id\": \"monologg/bert-base-cased-goemotions-original\", \n",
    "        \"weight\": 0.3\n",
    "    },\n",
    "    # 2. RoBERTa \n",
    "    {\n",
    "        \"path\": \"./results_roberta\", \n",
    "        \"tokenizer_id\": \"SamLowe/roberta-base-go_emotions\", \n",
    "        \"weight\": 0\n",
    "    },\n",
    "    # 3. Twitter RoBERTa \n",
    "    {\n",
    "        \"path\": \"./results_twitter_roberta\", \n",
    "        \"tokenizer_id\": \"cardiffnlp/twitter-roberta-base-emotion\", \n",
    "        \"weight\": 0.1\n",
    "    },\n",
    "    # 4. DistilBERT Student \n",
    "    {\n",
    "        \"path\": \"./results_distilbert_student\", \n",
    "        \"tokenizer_id\": \"joeddav/distilbert-base-uncased-go-emotions-student\", \n",
    "        \"weight\": 0.2\n",
    "    },\n",
    "    # 5. DistilEmotion \n",
    "    {\n",
    "        \"path\": \"./results_distil_emotion\", \n",
    "        \"tokenizer_id\": \"j-hartmann/emotion-english-distilroberta-base\", \n",
    "        \"weight\": 0.1\n",
    "    },\n",
    "    # 6. BERT Group \n",
    "    {\n",
    "        \"path\": \"./results_bert_group\", \n",
    "        \"tokenizer_id\": \"monologg/bert-base-cased-goemotions-group\", \n",
    "        \"weight\": 0.2\n",
    "    },\n",
    "    # 7. BERT Ekman \n",
    "    {\n",
    "        \"path\": \"./results_bert_ekman\", \n",
    "        \"tokenizer_id\": \"monologg/bert-base-cased-goemotions-ekman\", \n",
    "        \"weight\": 0.1\n",
    "    }\n",
    "]\n",
    "\n",
    "MAX_LENGTH = 64\n",
    "BATCH_SIZE = 32\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- Load Raw Test Data ---\n",
    "print(\"--- Loading Metadata ---\")\n",
    "try:\n",
    "    if os.path.exists(\"preprocessed_bert.pt\"):\n",
    "        meta_file = \"preprocessed_bert.pt\"\n",
    "    else:\n",
    "        # Fallback\n",
    "        pt_files = [f for f in os.listdir(\".\") if f.startswith(\"preprocessed\") and f.endswith(\".pt\")]\n",
    "        if not pt_files:\n",
    "            raise FileNotFoundError(\"No preprocessed metadata found!\")\n",
    "        meta_file = pt_files[0]\n",
    "        \n",
    "    print(f\"Loading metadata from: {meta_file}\")\n",
    "    meta_data = torch.load(meta_file, weights_only=False)\n",
    "    \n",
    "    test_ids = meta_data['test_ids']\n",
    "    label_encoder = meta_data['label_encoder']\n",
    "    \n",
    "    if 'test_texts' not in locals():\n",
    "        print(\"[Info] 'test_texts' variable not found in memory.\")\n",
    "        if os.path.exists(\"test.csv\"):\n",
    "             print(\"Loading from test.csv...\")\n",
    "             df_test_raw = pd.read_csv(\"test.csv\")\n",
    "             if 'text_cleaned' in df_test_raw.columns:\n",
    "                 test_texts = df_test_raw['text_cleaned'].tolist()\n",
    "             elif 'text' in df_test_raw.columns:\n",
    "                 test_texts = df_test_raw['text'].tolist()\n",
    "             else:\n",
    "                 raise ValueError(\"Could not find 'text' or 'text_cleaned' column in test.csv\")\n",
    "        else:\n",
    "             print(\"[Warning] Could not find test.csv. Assuming 'test_texts' exists from previous cells.\")\n",
    "             \n",
    "except Exception as e:\n",
    "    print(f\"[Error] Metadata load failed: {e}\")\n",
    "    raise e\n",
    "\n",
    "print(f\"Test samples: {len(test_texts)}\")\n",
    "print(f\"Ensembling {len(MODEL_MAP)} models...\")\n",
    "\n",
    "all_model_probs = []\n",
    "used_weights = []\n",
    "\n",
    "# --- Loop Through Models ---\n",
    "for entry in MODEL_MAP:\n",
    "    model_path = entry[\"path\"]\n",
    "    tokenizer_id = entry[\"tokenizer_id\"]\n",
    "    weight = entry[\"weight\"]\n",
    "    \n",
    "    print(f\"\\n------------------------------------------------------\")\n",
    "    print(f\"Processing: {model_path}\")\n",
    "    print(f\"Tokenizer:  {tokenizer_id}\")\n",
    "    print(f\"------------------------------------------------------\")\n",
    "    \n",
    "    try:\n",
    "        # 1. Load Tokenizer\n",
    "        tokenizer = AutoTokenizer.from_pretrained(tokenizer_id)\n",
    "        \n",
    "        # 2. Load Model (Local Weights)\n",
    "        if not os.path.exists(model_path):\n",
    "             print(f\"  [Skip] Path not found: {model_path}\")\n",
    "             continue\n",
    "             \n",
    "        model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "        model.to(DEVICE)\n",
    "        model.eval()\n",
    "        \n",
    "        used_weights.append(weight)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  [Error] Failed to load {model_path}. Details: {e}\")\n",
    "        continue\n",
    "\n",
    "    model_probs = []\n",
    "    \n",
    "    # Batch Inference\n",
    "    for i in tqdm(range(0, len(test_texts), BATCH_SIZE), desc=\"Predicting\"):\n",
    "        batch_texts = test_texts[i : i + BATCH_SIZE]\n",
    "        \n",
    "        inputs = tokenizer(\n",
    "            batch_texts, \n",
    "            padding=True, \n",
    "            truncation=True, \n",
    "            max_length=MAX_LENGTH, \n",
    "            return_tensors=\"pt\"\n",
    "        ).to(DEVICE)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            probs = F.softmax(outputs.logits, dim=-1)\n",
    "            model_probs.append(probs.cpu().numpy())\n",
    "            \n",
    "    # Concatenate batches for this model\n",
    "    full_probs_for_model = np.concatenate(model_probs, axis=0)\n",
    "    \n",
    "    # Safety Check: Dimensions\n",
    "    if len(all_model_probs) > 0:\n",
    "        if full_probs_for_model.shape[1] != all_model_probs[0].shape[1]:\n",
    "            print(f\"  [CRITICAL] Shape mismatch. Expected {all_model_probs[0].shape[1]} classes, got {full_probs_for_model.shape[1]}. Skipping this model.\")\n",
    "            used_weights.pop()\n",
    "            continue\n",
    "\n",
    "    all_model_probs.append(full_probs_for_model)\n",
    "    \n",
    "    # Clean up\n",
    "    del model, tokenizer, inputs, outputs\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# --- Weighted Averaging ---\n",
    "print(\"\\nCalculating Weighted Average...\")\n",
    "\n",
    "if len(all_model_probs) == 0:\n",
    "    raise ValueError(\"No models loaded successfully!\")\n",
    "\n",
    "# Normalize weights\n",
    "total_weight = sum(used_weights)\n",
    "if total_weight == 0:\n",
    "    print(\"[Info] Total weight is 0. Using equal weights.\")\n",
    "    norm_weights = [1.0/len(used_weights)] * len(used_weights)\n",
    "else:\n",
    "    norm_weights = [w / total_weight for w in used_weights]\n",
    "\n",
    "print(f\"Normalized Weights: {np.round(norm_weights, 2)}\")\n",
    "\n",
    "final_probs = np.zeros_like(all_model_probs[0])\n",
    "\n",
    "for i, probs in enumerate(all_model_probs):\n",
    "    final_probs += probs * norm_weights[i]\n",
    "\n",
    "# --- Generate Submission ---\n",
    "predicted_class_ids = np.argmax(final_probs, axis=1)\n",
    "predicted_labels = label_encoder.inverse_transform(predicted_class_ids)\n",
    "\n",
    "PATH_ENSEMBLE = \"submission_ensemble_7models.csv\"\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'emotion': predicted_labels\n",
    "})\n",
    "\n",
    "submission_df.to_csv(PATH_ENSEMBLE, index=False)\n",
    "print(f\"\\nEnsemble submission saved to: {PATH_ENSEMBLE}\")\n",
    "print(\"=== Step 5 Complete! ==================================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quant_wei",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
